---
title: "NEW"
author: "PO Couture"
format: html
editor: visual
---

##  New

I will use this document to work on my SIMOA code since I am having trouble with it currently in the existing format. In this way I can mess around with this code and not be worried about it impacting my original data and now that I know what I want to do for my clusters it is easier for me to manipulate the variables in a manner that will set me up for success later.

## Loading the Data

The section I will use to load the dataset that I will use for the analysis.

```{r}
#| label: Loading the Data and Libraries
######
# Loading the data
######

library(readr)
SIMOA <- read_csv("SIMOA Report.csv")
#View(SIMOA)
```


## Eligible Participants

The section where I have set out the inclusion criteria to remove people from the dataset that do not meet our criteria.

```{r}
#| label: Eligible Participants
######
# In this section I will filter out those who have indicated they are <65 or that have not answered   
# yes to the question about age category or not answered either question. I will also filter out those 
# who did not select one of the 14 BZRAs listed because we do not want the results to be affected by 
# other sedating medications such as antihistamines or SSRI's.
# Additionally, filter to include only those who answered the scrn_stopped_bzra question.
######

# Original count
n_original <- nrow(SIMOA)

# After age filtering
SIMOA_age_filtered <- SIMOA %>%
  filter(age_cat == 1 | (age_cat == 0 & age >= 65))
n_after_age <- nrow(SIMOA_age_filtered)

# After c_sp filtering
SIMOA_c_sp_filtered <- SIMOA_age_filtered %>%
  filter(rowSums(select(., starts_with("c_sp___"))[, 1:14] == 1, na.rm = TRUE) > 0)
n_after_c_sp <- nrow(SIMOA_c_sp_filtered)

# After prov_terr filtering (remove answer 14)
SIMOA_prov_filtered <- SIMOA_c_sp_filtered %>%
  filter(prov_terr != 14 | is.na(prov_terr))
n_after_prov <- nrow(SIMOA_prov_filtered)

# After scrn_stopped_bzra filtering (only those who answered the question)
SIMOA <- SIMOA_prov_filtered %>%
  filter(!is.na(scrn_stopped_bzra))
n_final <- nrow(SIMOA)

# Report results
cat("Original sample:", n_original, "\n")
cat("After age filtering:", n_after_age, "(removed:", n_original - n_after_age, ")\n")
cat("After c_sp filtering:", n_after_c_sp, "(removed:", n_after_age - n_after_c_sp, ")\n")
cat("After prov_terr filtering:", n_after_prov, "(removed:", n_after_c_sp - n_after_prov, ")\n")
cat("After scrn_stopped_bzra filtering:", n_final, "(removed:", n_after_prov - n_final, ")\n")
cat("Total removed:", n_original - n_final, "\n")
```


## Data Preperation

This section prepare the data for MI and only include those with a complete scrn_stopped_bzra
```{r}
#| label: Data Preparation for Multiple Imputation
######
# Prepare data_personality dataset for multiple imputation
# Combine individual adverse effects items BEFORE imputation
######

library(dplyr)
library(mice)

cat("=== DATA PREPARATION FOR MULTIPLE IMPUTATION ===\n")

# Start with SIMOA dataset (the original full dataset)
# Note: Filtering for valid scrn_stopped_bzra cases was done previously
cat("SIMOA dataset size:", nrow(SIMOA), "\n")

# Verify outcome variable distribution
cat("scrn_stopped_bzra distribution:\n")
print(table(SIMOA$scrn_stopped_bzra, useNA = "ifany"))

######
# COMBINE ADVERSE EFFECTS ITEMS (v1 and v2 versions)
######

cat("\n=== COMBINING ADVERSE EFFECTS ITEMS ===\n")
cat("NOTE: Combining v1 and v2 versions into single variables.\n\n")

# Function to combine v1 and v2 versions (take first non-NA value)
combine_versions <- function(v1, v2) {
  ifelse(!is.na(v1), v1, v2)
}

# Define item pairs to combine
adverse_item_pairs <- list(
  # Side effects
  side_effects_1 = c("side_effects_1", "side_effects_1_v2"),
  side_effects_2 = c("side_effects_2", "side_effects_2_v2"),
  side_effects_3 = c("side_effects_3", "side_effects_3_v2"),
  side_effects_4 = c("side_effects_4", "side_effects_4_v2"),
  # Safety
  safety_1 = c("safety_1", "safety_1_v2"),
  safety_2 = c("safety_2", "safety_2_v2"),
  safety_3 = c("safety_3", "safety_3_v2"),
  safety_4 = c("safety_4", "safety_4_v2"),
  # ADLs
  adls_1 = c("adls_1", "adls_1_v2"),
  adls_2 = c("adls_2", "adls_2_v2"),
  # Dependence
  dependence_1 = c("dependence_1", "dependence_1_v2"),
  dependence_2 = c("dependence_2", "dependence_2_v2"),
  dependence_3 = c("dependence_3", "dependence_3_v2")
)

# Combine v1 and v2 versions
for(item_name in names(adverse_item_pairs)) {
  v1_col <- adverse_item_pairs[[item_name]][1]
  v2_col <- adverse_item_pairs[[item_name]][2]
  
  if(v1_col %in% names(SIMOA) && v2_col %in% names(SIMOA)) {
    SIMOA[[item_name]] <- combine_versions(
      SIMOA[[v1_col]], 
      SIMOA[[v2_col]]
    )
    na_count <- sum(is.na(SIMOA[[item_name]]))
    cat("Combined", v1_col, "and", v2_col, "into", item_name, "- Missing:", na_count, "\n")
  } else if(v1_col %in% names(SIMOA)) {
    SIMOA[[item_name]] <- SIMOA[[v1_col]]
    na_count <- sum(is.na(SIMOA[[item_name]]))
    cat("Only", v1_col, "found, using as", item_name, "- Missing:", na_count, "\n")
  } else if(v2_col %in% names(SIMOA)) {
    SIMOA[[item_name]] <- SIMOA[[v2_col]]
    na_count <- sum(is.na(SIMOA[[item_name]]))
    cat("Only", v2_col, "found, using as", item_name, "- Missing:", na_count, "\n")
  }
}

######
# DEFINE VARIABLES FOR ANALYSIS
######

cat("\n=== SELECTING VARIABLES FOR ANALYSIS ===\n")

# Core variables requested
core_vars <- c(
  "age", "sex", "gender",
  "osss_3_score", "phq2_score",
  "prov_terr", "education", "employment", "driving_freq", "income",
  "med_quant", "med_burden_1", "med_burden2", "medburden_3", "med_burden_4",
  "op_use", "can_use", "caf_use", "nico_use", "alc_sleep", "can_sleep", 
  "melatonin_use", "op_sleep", "quet_use", "traz_use", "otc_use",
  "alc_use_wmn", "alc_use_men"
)

# Combined adverse effects items (individual items, not totals)
adverse_items_combined <- c(
  # Side effects (4 items)
  "side_effects_1", "side_effects_2", "side_effects_3", "side_effects_4",
  # Safety (4 items)
  "safety_1", "safety_2", "safety_3", "safety_4",
  # ADLs (2 items)
  "adls_1", "adls_2",
  # Dependence (3 items)
  "dependence_1", "dependence_2", "dependence_3"
)

# Individual questionnaire items (to be imputed separately)
questionnaire_items <- c(
  # DBAS items (all 16 individual items)
  "dbas1", "dbas_2", "dbas_3", "dbas_4", "dbas_5", "dbas_6", "dbas_7", "dbas_8",
  "dbas_9", "dbas_10", "dbas_11", "dbas_12", "dbas_13", "dbas_14", "dbas_15", "dbas_16",
  # BFI items (all 10 individual items)
  "reserved", "outgoing", "find_fault", "trusting", "lazy", "thorough", 
  "relaxed", "nervous", "few_interests", "imagination",
  # SURPS items (all 23 individual items)
  "surps1", "surps2", "surps3", "surps4", "surps5", "surps6", "surps7", "surps8",
  "surps9", "surps10", "surps11", "surps12", "surps13", "surps14", "surps15", "surps16",
  "surps17", "surps18", "surps19", "surps20", "surps21", "surps22", "surps23",
  # CISS items (all 21 individual items)
  "ciss1", "ciss2", "ciss3", "ciss4", "ciss5", "ciss6", "ciss7", "ciss8", "ciss9",
  "ciss10", "ciss11", "ciss12", "ciss13", "ciss14", "ciss15", "ciss16", "ciss17",
  "ciss18", "ciss19", "ciss20", "ciss21"
)

cat("Specified", length(questionnaire_items), "individual questionnaire items\n")
cat("Found", length(adverse_items_combined), "combined adverse effects items\n")

# All variables for analysis (core + individual questionnaire items + adverse items)
all_analysis_vars <- unique(c(core_vars, questionnaire_items, adverse_items_combined))

cat("Total variables requested:", length(all_analysis_vars), "\n")

######
# CHECK VARIABLE AVAILABILITY AND CREATE SUBSET
######

# Check which variables are available
available_vars <- all_analysis_vars[all_analysis_vars %in% names(SIMOA)]
missing_vars <- all_analysis_vars[!all_analysis_vars %in% names(SIMOA)]

cat("Variables available:", length(available_vars), "\n")
cat("Variables not found:", length(missing_vars), "\n")

if(length(missing_vars) > 0) {
  cat("\nMissing variables:\n")
  for(var in missing_vars) {
    cat("  -", var, "\n")
  }
}

# Create analysis dataset with available variables
final_dataset_imputed <- SIMOA[, available_vars, drop = FALSE]

######
# HANDLE CONDITIONAL SUBSTANCE USE VARIABLES
######

cat("\n=== HANDLING CONDITIONAL SUBSTANCE USE VARIABLES ===\n")

# These variables were only shown to participants who selected them in previous questions
# NA means they never use these substances, so recode NA to 0 ("Never")
conditional_vars <- c("op_use", "can_use", "caf_use", "nico_use", "alc_sleep", 
                      "can_sleep", "melatonin_use", "op_sleep", "quet_use", 
                      "traz_use", "otc_use")

for(var in conditional_vars) {
  if(var %in% names(final_dataset_imputed)) {
    original_na_count <- sum(is.na(final_dataset_imputed[[var]]))
    
    # Recode NA to 0 (Never used)
    final_dataset_imputed[[var]][is.na(final_dataset_imputed[[var]])] <- 0
    
    cat("Recoded", original_na_count, "NA values to 0 ('Never') for", var, "\n")
  }
}

######
# HANDLE SEX-SPECIFIC ALCOHOL USE VARIABLES - ENFORCE MUTUAL EXCLUSIVITY
######

cat("\n=== HANDLING SEX-SPECIFIC ALCOHOL USE VARIABLES ===\n")

# CRITICAL: alc_use_wmn should ONLY have values for women (sex = 1)
#           alc_use_men should ONLY have values for men (sex = 2)
#           This ensures mutual exclusivity

if("alc_use_wmn" %in% names(final_dataset_imputed) && "sex" %in% names(final_dataset_imputed)) {
  # For women (sex = 1): Keep their actual values as-is (including true missing data)
  # For men (sex = 2): Set ALL values to NA (they should never have answered this)
  
  men_with_wmn_data <- sum(!is.na(final_dataset_imputed$alc_use_wmn) & final_dataset_imputed$sex == 2, na.rm = TRUE)
  if(men_with_wmn_data > 0) {
    cat("⚠ WARNING: Found", men_with_wmn_data, "men with alc_use_wmn data - setting to NA\n")
  }
  
  final_dataset_imputed$alc_use_wmn[final_dataset_imputed$sex == 2] <- NA
  
  # Report missing data in women (true missing that needs imputation)
  women_na_count <- sum(is.na(final_dataset_imputed$alc_use_wmn) & final_dataset_imputed$sex == 1, na.rm = TRUE)
  women_total <- sum(final_dataset_imputed$sex == 1, na.rm = TRUE)
  cat("alc_use_wmn - Women (sex=1): ", women_na_count, " missing out of ", women_total, 
      " (", round(100*women_na_count/women_total, 1), "%)\n", sep="")
  cat("alc_use_wmn - Men (sex=2): All set to NA (mutually exclusive)\n")
}

if("alc_use_men" %in% names(final_dataset_imputed) && "sex" %in% names(final_dataset_imputed)) {
  # For men (sex = 2): Keep their actual values as-is (including true missing data)
  # For women (sex = 1): Set ALL values to NA (they should never have answered this)
  
  women_with_men_data <- sum(!is.na(final_dataset_imputed$alc_use_men) & final_dataset_imputed$sex == 1, na.rm = TRUE)
  if(women_with_men_data > 0) {
    cat("⚠ WARNING: Found", women_with_men_data, "women with alc_use_men data - setting to NA\n")
  }
  
  final_dataset_imputed$alc_use_men[final_dataset_imputed$sex == 1] <- NA
  
  # Report missing data in men (true missing that needs imputation)
  men_na_count <- sum(is.na(final_dataset_imputed$alc_use_men) & final_dataset_imputed$sex == 2, na.rm = TRUE)
  men_total <- sum(final_dataset_imputed$sex == 2, na.rm = TRUE)
  cat("alc_use_men - Men (sex=2): ", men_na_count, " missing out of ", men_total, 
      " (", round(100*men_na_count/men_total, 1), "%)\n", sep="")
  cat("alc_use_men - Women (sex=1): All set to NA (mutually exclusive)\n")
}

# Verify mutual exclusivity
if("alc_use_wmn" %in% names(final_dataset_imputed) && "alc_use_men" %in% names(final_dataset_imputed)) {
  both_present <- sum(!is.na(final_dataset_imputed$alc_use_wmn) & !is.na(final_dataset_imputed$alc_use_men))
  cat("\n✓ VERIFICATION: Cases with both alc_use_wmn AND alc_use_men:", both_present, "\n")
  
  if(both_present > 0) {
    cat("⚠ ERROR: Mutual exclusivity NOT achieved!\n")
  } else {
    cat("✓ SUCCESS: Mutual exclusivity confirmed - no participant has values in both variables\n")
  }
}

######
# FINAL DATASET SUMMARY
######

cat("\n=== FINAL DATASET SUMMARY ===\n")
cat("Final dataset dimensions:", dim(final_dataset_imputed), "\n")
cat("Number of participants:", nrow(final_dataset_imputed), "\n")
cat("Number of variables:", ncol(final_dataset_imputed), "\n")

# Missing data summary
cat("\n=== MISSING DATA SUMMARY ===\n")
missing_summary <- sapply(final_dataset_imputed, function(x) sum(is.na(x)))
variables_with_missing <- missing_summary[missing_summary > 0]

if(length(variables_with_missing) > 0) {
  cat("Variables with missing data:\n")
  for(i in 1:length(variables_with_missing)) {
    var_name <- names(variables_with_missing)[i]
    missing_count <- variables_with_missing[i]
    missing_pct <- round((missing_count / nrow(final_dataset_imputed)) * 100, 1)
    cat(paste("  ", var_name, ":", missing_count, "(", missing_pct, "%)\n"))
  }
  
  # Overall completeness
  complete_cases <- sum(complete.cases(final_dataset_imputed))
  complete_pct <- round((complete_cases / nrow(final_dataset_imputed)) * 100, 1)
  cat("\nComplete cases:", complete_cases, "out of", nrow(final_dataset_imputed), 
      "(", complete_pct, "%)\n")
} else {
  cat("No missing data found in any variables!\n")
}

cat("\n=== DATA PREPARATION COMPLETE ===\n")
cat("Dataset 'final_dataset_imputed' is ready for multiple imputation analysis\n")
cat("IMPORTANT: Individual questionnaire items (DBAS, BFI, SURPS, CISS) are included for imputation.\n")
cat("           Create subscale scores AFTER imputation is complete.\n")
cat("           Adverse effects items (side_effects_1-4, safety_1-4, adls_1-2, dependence_1-3)\n")
cat("           have been combined from v1 and v2 versions and are ready for imputation.\n")
```


## MI Optimization and Pilot

```{r}
#| label: Multiple Imputation with Proper Variable Types

library(mice)
library(dplyr)

cat("\n=== OPTIMIZED MULTIPLE IMPUTATION ===\n")

# ===== DATA PREPARATION =====
impute_data <- as.data.frame(final_dataset_imputed)
impute_data$alc_use_wmn <- NULL
impute_data$alc_use_men <- NULL

cat("Working dimensions:", dim(impute_data), "\n")
cat("Total missing values:", sum(is.na(impute_data)), "\n")

# ===== STEP 1: SET VARIABLE TYPES =====
cat("\n=== STEP 1: SETTING VARIABLE TYPES ===\n")

continuous_vars <- c(
  "age", "med_quant", "osss_3_score", "phq2_score",
  "dbas1", "dbas_2", "dbas_3", "dbas_4", "dbas_5", "dbas_6", "dbas_7", "dbas_8",
  "dbas_9", "dbas_10", "dbas_11", "dbas_12", "dbas_13", "dbas_14", "dbas_15", "dbas_16",
  "reserved", "outgoing", "find_fault", "trusting", "lazy", "thorough", 
  "relaxed", "nervous", "few_interests", "imagination",
  "surps1", "surps2", "surps3", "surps4", "surps5", "surps6", "surps7", "surps8",
  "surps9", "surps10", "surps11", "surps12", "surps13", "surps14", "surps15", "surps16",
  "surps17", "surps18", "surps19", "surps20", "surps21", "surps22", "surps23",
  "ciss1", "ciss2", "ciss3", "ciss4", "ciss5", "ciss6", "ciss7", "ciss8", "ciss9",
  "ciss10", "ciss11", "ciss12", "ciss13", "ciss14", "ciss15", "ciss16", "ciss17",
  "ciss18", "ciss19", "ciss20", "ciss21"
)

binary_vars <- c("sex")

unordered_categorical <- c("prov_terr", "gender")

ordered_vars <- c(
  "education", "income", "driving_freq", "employment",
  "side_effects_1", "side_effects_2", "side_effects_3", "side_effects_4",
  "safety_1", "safety_2", "safety_3", "safety_4",
  "adls_1", "adls_2",
  "dependence_1", "dependence_2", "dependence_3",
  "med_burden_1", "med_burden2", "medburden_3", "med_burden_4",
  "op_use", "can_use", "caf_use", "nico_use", 
  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
  "quet_use", "traz_use", "otc_use"
)

# Format variables
for(var in continuous_vars) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- as.numeric(impute_data[[var]])
  }
}

for(var in binary_vars) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- factor(impute_data[[var]])
  }
}

for(var in unordered_categorical) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- factor(impute_data[[var]], ordered = FALSE)
  }
}

for(var in ordered_vars) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- factor(impute_data[[var]], ordered = TRUE)
  }
}

cat("Continuous:", length(intersect(continuous_vars, names(impute_data))), "\n")
cat("Binary:", length(intersect(binary_vars, names(impute_data))), "\n")
cat("Unordered categorical:", length(intersect(unordered_categorical, names(impute_data))), "\n")
cat("Ordered categorical:", length(intersect(ordered_vars, names(impute_data))), "\n")

# ===== STEP 2: FIND OPTIMAL THRESHOLDS =====
cat("\n=== STEP 2: TESTING PREDICTOR MATRIX THRESHOLDS ===\n")

test_thresholds <- function(data, mincor_vals, minpuc_vals) {
  results <- data.frame()
  
  for(mc in mincor_vals) {
    for(mp in minpuc_vals) {
      pred <- quickpred(data, mincor = mc, minpuc = mp)
      n_vars_with_predictors <- sum(rowSums(pred) > 0)
      
      if(n_vars_with_predictors > 0) {
        avg_preds <- sum(pred) / n_vars_with_predictors
      } else {
        avg_preds <- 0
      }
      
      results <- rbind(results, data.frame(
        mincor = mc,
        minpuc = mp,
        total_predictions = sum(pred),
        avg_predictors = round(avg_preds, 1),
        pct_reduction = round((1 - sum(pred)/prod(dim(pred))) * 100, 1)
      ))
    }
  }
  return(results)
}

threshold_results <- test_thresholds(
  impute_data,
  mincor_vals = c(0.1, 0.2, 0.3, 0.4),
  minpuc_vals = c(0.2, 0.3, 0.4, 0.5)
)

print(threshold_results)

# Select threshold with avg_predictors between 10-25
optimal <- threshold_results[
  threshold_results$avg_predictors >= 10 & 
  threshold_results$avg_predictors <= 25, 
][1,]

if(nrow(optimal) == 0) {
  cat("\nNo optimal threshold found in 10-25 range, using mincor=0.3, minpuc=0.3\n")
  mincor_use <- 0.3
  minpuc_use <- 0.3
} else {
  cat("\nOptimal threshold selected:\n")
  print(optimal)
  mincor_use <- optimal$mincor
  minpuc_use <- optimal$minpuc
}

# ===== STEP 3: CREATE REDUCED PREDICTOR MATRIX =====
cat("\n=== STEP 3: CREATING OPTIMIZED PREDICTOR MATRIX ===\n")

predMatrix <- quickpred(impute_data, mincor = mincor_use, minpuc = minpuc_use)

# Remove problematic predictors (sparse categories causing convergence issues)
predMatrix[, "prov_terr"] <- 0

cat("Original predictor matrix:", prod(dim(impute_data)), "potential predictions\n")
cat("Reduced predictor matrix:", sum(predMatrix), "predictions\n")
cat("Reduction:", round((1 - sum(predMatrix)/prod(dim(predMatrix))) * 100, 1), "%\n")
cat("Note: Removed prov_terr as predictor (sparse categories)\n")

# ===== STEP 4: INITIALIZE AND SET METHODS =====
cat("\n=== STEP 4: INITIALIZING MICE WITH CUSTOM METHODS ===\n")

init <- mice(impute_data, maxit = 0, print = FALSE)
method <- init$method

# Set methods
for(var in continuous_vars) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "pmm"
  }
}

for(var in binary_vars) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "logreg"
  }
}

for(var in unordered_categorical) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "polyreg"
  }
}

for(var in ordered_vars) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "polr"
  }
}

cat("Method assignment:\n")
print(table(method[method != ""]))

# ===== STEP 5: RUN OPTIMIZED PILOT =====
cat("\n=== STEP 5: RUNNING OPTIMIZED PILOT (m=5, maxit=5) ===\n")

start_time <- Sys.time()
pilot <- mice(
  impute_data,
  method = method,
  predictorMatrix = predMatrix,
  m = 5,
  maxit = 5,
  seed = 123,
  printFlag = FALSE
)
end_time <- Sys.time()

pilot_time <- round(difftime(end_time, start_time, units="secs"), 2)
cat("Pilot completed in", pilot_time, "seconds\n")

# ===== STEP 6: VERIFY AND DIAGNOSE =====
cat("\n=== STEP 6: VERIFICATION & DIAGNOSTICS ===\n")

cat("Logged events:", nrow(pilot$loggedEvents), "\n")
completed <- complete(pilot, 1)
remaining_na <- sum(is.na(completed))

if(remaining_na == 0) {
  cat("SUCCESS: All missing values imputed!\n\n")
  
  # Check convergence
  cat("Checking convergence (visual inspection recommended):\n")
  cat("Run: plot(pilot) to inspect trace plots\n\n")
  
  # Estimate full imputation time
  overall_missing_pct <- mean(is.na(impute_data)) * 100
  m_rec <- max(20, min(100, ceiling(overall_missing_pct)))
  maxit_rec <- max(10, ceiling(overall_missing_pct / 2))
  
  estimated_time <- as.numeric(pilot_time) * (m_rec / 5) * (maxit_rec / 5)
  
  cat("=== READY FOR FULL IMPUTATION ===\n")
  cat("Recommended settings:\n")
  cat("  m =", m_rec, "\n")
  cat("  maxit =", maxit_rec, "\n")
  cat("  mincor =", mincor_use, "\n")
  cat("  minpuc =", minpuc_use, "\n\n")
  cat("Estimated time:", round(estimated_time / 60, 1), "minutes\n\n")
  
  cat("To run full imputation:\n")
  cat("final_imp <- mice(\n")
  cat("  impute_data,\n")
  cat("  method = method,\n")
  cat("  predictorMatrix = predMatrix,\n")
  cat("  m =", m_rec, ",\n")
  cat("  maxit =", maxit_rec, ",\n")
  cat("  seed = 123,\n")
  cat("  printFlag = TRUE\n")
  cat(")\n\n")
  
  cat("Save results:\n")
  cat("saveRDS(final_imp, 'imputed_data.rds')\n")
  
} else {
  cat("WARNING:", remaining_na, "values still missing\n")
  na_by_var <- colSums(is.na(completed))
  cat("\nVariables with remaining NAs:\n")
  print(na_by_var[na_by_var > 0])
  cat("\nConsider:\n")
  cat("1. Lowering mincor/minpuc thresholds\n")
  cat("2. Checking variable types and coding\n")
  cat("3. Increasing maxit\n")
}

# Save convergence trace plots
png("IMP_CONV_PLOT.png", width = 1200, height = 800, res = 120)
plot(pilot)
dev.off()

# Get convergence statistics
install.packages("broom")
library(broom)

# Extract mean and SD across iterations for each variable
conv_summary <- pilot$chainMean
print(conv_summary)

# Or get the full chain variance
conv_var <- pilot$chainVar
print(conv_var)

cat("\n=== OPTIMIZATION COMPLETE ===\n")
```


## Multiple Imputation

```{r}
#| label: MI Execution

library(mice)

cat("\n=== RUNNING FULL IMPUTATION ===\n")
cat("Start time:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n\n")

# You should already have these from your optimization:
# - impute_data (prepared data)
# - method (imputation methods)
# - predMatrix (optimized predictor matrix)

cat("Configuration:\n")
cat("  Variables to impute:", sum(method != ""), "\n")
cat("  Predictor relationships:", sum(predMatrix), "\n")
cat("  m = 20 datasets\n")
cat("  maxit = 10 iterations\n")
cat("  Estimated time: ~10-12 minutes\n\n")

# ===== RUN FULL IMPUTATION =====
start_time <- Sys.time()

final_imp <- mice(
  impute_data,
  method = method,
  predictorMatrix = predMatrix,
  m = 20,
  maxit = 10,
  seed = 123,
  printFlag = TRUE
)

end_time <- Sys.time()
imputation_time <- difftime(end_time, start_time, units = "mins")

# ===== VERIFY AND SAVE =====
cat("\n=== IMPUTATION COMPLETE ===\n")
cat("Total time:", round(imputation_time, 2), "minutes\n")
cat("Logged events:", nrow(final_imp$loggedEvents), "\n\n")

# Check completion
completed_data <- complete(final_imp, 1)
remaining_na <- sum(is.na(completed_data))

if(remaining_na == 0) {
  cat("SUCCESS: All missing values imputed\n\n")
} else {
  cat("WARNING:", remaining_na, "values still missing\n\n")
}

# Save results
saveRDS(final_imp, "final_imputation.rds")
cat("Saved: final_imputation.rds\n")

write.csv(completed_data, "imputed_dataset_1.csv", row.names = FALSE)
cat("Saved: imputed_dataset_1.csv\n\n")

# Save diagnostics
png("FULL_IMP_CONV.png", width = 1400, height = 1000, res = 120)
plot(final_imp)
dev.off()
cat("Saved: FULL_IMP_CONV.png\n")

# For continuous variables
png("FULL_IMP_STRIP_CONT.png", width = 1400, height = 1000, res = 120)
stripplot(final_imp, osss_3_score + dbas1 + surps1 + ciss1 ~ .imp, 
          pch = 20, cex = 0.8)
dev.off()

# For categorical variables
png("FULL_IMP_STRIP_CAT.png", width = 1400, height = 1000, res = 120)
stripplot(final_imp, education + income + employment ~ .imp, pch = 20, cex = 1.2)
dev.off()

cat("End time:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
cat("\nTo use imputed data:\n")
cat("fit <- with(final_imp, lm(outcome ~ predictors))\n")
cat("summary(pool(fit))\n")
```



## Calculating Subscale Scores

The section where I go about calculating the subscale scores for all the measures and ensure that this is properly done and that way I can compare the groups in subscales rather than the full measure and it makes it easier to report.

```{r}
#| label: Subscale Scores
######
# In this section I will get the subscale scores for all the measures I # have used. I will also ensure that items are appropriately            # reverse-coded.
# All subscale score coding will be found in this chunk but I have      # divided them to make them easy to find. I would rather have 1 chunk   # that way it cuts down on the amount of space being taken up for this  # step.
######

# ===== CREATE SUBSCALES AFTER IMPUTATION =====
# This must be done AFTER imputation, not before
# We'll use mice::complete() with "long" format to work with all imputed datasets

cat("\n=== CREATING SUBSCALES FOR IMPUTED DATA ===\n")

# Get all imputed datasets in long format
imputed_long <- complete(final_imp, "long", include = TRUE)

# ===== BFI-10 SUBSCALE SCORES =====
cat("Creating BFI-10 subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    # Reverse code items (assuming 1-5 scale, adjust if different)
    reserved_rev = 6 - reserved,
    find_fault_rev = 6 - find_fault,
    lazy_rev = 6 - lazy,
    relaxed_rev = 6 - relaxed,
    few_interests_rev = 6 - few_interests,
    
    # Create subscales
    Extraversion = reserved_rev + outgoing,
    Agreeableness = trusting + find_fault_rev,
    Conscientiousness = lazy_rev + thorough,
    Neuroticism = relaxed_rev + nervous,
    Openness = few_interests_rev + imagination
  )

# ===== SURPS SUBSCALE SCORES =====
cat("Creating SURPS subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    # Reverse code Hopelessness items (1-4 scale)
    surps1_rev = 5 - surps1,
    surps4_rev = 5 - surps4,
    surps7_rev = 5 - surps7,
    surps13_rev = 5 - surps13,
    surps20_rev = 5 - surps20,
    surps23_rev = 5 - surps23,
    
    # Create subscales
    SURPS_Impulsivity = surps2 + surps5 + surps11 + surps15 + surps22,
    SURPS_Sensation_Seeking = surps3 + surps6 + surps9 + surps12 + surps16 + surps19,
    SURPS_Hopelessness = surps1_rev + surps4_rev + surps7_rev + surps13_rev + 
                         surps17 + surps20_rev + surps23_rev,
    SURPS_Anxiety_Sensitivity = surps8 + surps10 + surps14 + surps18 + surps21
  )

# ===== DBAS SUBSCALE SCORES =====
cat("Creating DBAS subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    # Using rowMeans for averaging (0-10 scale, no reverse coding)
    DBAS_Expectations = (dbas1 + dbas_2) / 2,
    DBAS_Medications = (dbas_6 + dbas_13 + dbas_15) / 3,
    DBAS_Worry_Helplessness = (dbas_3 + dbas_4 + dbas_8 + dbas_10 + dbas_11 + dbas_14) / 6,
    DBAS_Consequences = (dbas_5 + dbas_7 + dbas_9 + dbas_12 + dbas_16) / 5,
    
    # Total DBAS score
    dbas_score = DBAS_Expectations + DBAS_Medications + 
                 DBAS_Worry_Helplessness + DBAS_Consequences
  )

# ===== CISS SUBSCALE SCORES =====
cat("Creating CISS subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    CISS_Avoidance_Style = ciss1 + ciss4 + ciss7 + ciss9 + ciss15 + ciss18 + ciss21,
    CISS_Task_Style = ciss2 + ciss6 + ciss8 + ciss11 + ciss13 + ciss16 + ciss19,
    CISS_Emotional_Style = ciss3 + ciss5 + ciss10 + ciss12 + ciss14 + ciss17 + ciss20
  )

# ===== CONVERT BACK TO MIDS OBJECT =====
cat("Converting back to mids object...\n")

final_imp <- as.mids(imputed_long)

# ===== VERIFICATION =====
cat("\n=== SUBSCALE VERIFICATION ===\n")

# Check one imputed dataset
check_data <- complete(final_imp, 1)

cat("\nBFI-10 Subscales:\n")
print(summary(check_data[, c("Extraversion", "Agreeableness", "Conscientiousness", 
                              "Neuroticism", "Openness")]))

cat("\nSURPS Subscales:\n")
print(summary(check_data[, c("SURPS_Impulsivity", "SURPS_Sensation_Seeking", 
                              "SURPS_Hopelessness", "SURPS_Anxiety_Sensitivity")]))

cat("\nDBAS Subscales:\n")
print(summary(check_data[, c("DBAS_Expectations", "DBAS_Medications", 
                              "DBAS_Worry_Helplessness", "DBAS_Consequences", 
                              "dbas_score")]))

cat("\nCISS Subscales:\n")
print(summary(check_data[, c("CISS_Avoidance_Style", "CISS_Task_Style", 
                              "CISS_Emotional_Style")]))

# ===== SAVE UPDATED IMPUTATION OBJECT =====
saveRDS(final_imp, "final_imputation_with_subscales.rds")
cat("\nSaved: final_imputation_with_subscales.rds\n")

# Save first imputed dataset with subscales
write.csv(check_data, "imputed_dataset_1_with_subscales.csv", row.names = FALSE)
cat("Saved: imputed_dataset_1_with_subscales.csv\n")

# ===== NOW YOU CAN CREATE DIAGNOSTIC PLOTS =====
cat("\n=== CREATING DIAGNOSTIC PLOTS WITH SUBSCALES ===\n")

# Density plots for subscale scores
png("FULL_IMP_DENS_SUBSCALES.png", width = 1600, height = 1200, res = 120)
densityplot(final_imp, ~ DBAS_Expectations + SURPS_Impulsivity + 
            CISS_Avoidance_Style + Extraversion)
dev.off()
cat("Saved: FULL_IMP_DENS_SUBSCALES.png\n")

# Strip plot for subscales
png("FULL_IMP_STRIP_SUBSCALES.png", width = 1600, height = 1200, res = 120)
stripplot(final_imp, DBAS_Expectations + SURPS_Impulsivity + 
          CISS_Avoidance_Style + Neuroticism ~ .imp, 
          pch = 20, cex = 0.8)
dev.off()
cat("Saved: FULL_IMP_STRIP_SUBSCALES.png\n")

cat("\n=== COMPLETE ===\n")
cat("You can now use subscales in your analyses:\n")
cat("fit <- with(final_imp, lm(outcome ~ DBAS_Expectations + SURPS_Impulsivity))\n")
cat("summary(pool(fit))\n")
```


## Descriptive Stats

```{r}
#| label: Descriptive Statistics

library(mice)
library(dplyr)
library(tidyr)

cat("\n=== DESCRIPTIVE STATISTICS FOR IMPUTED DATA ===\n")

# Load the imputation object with subscales
final_imp <- readRDS("final_imputation_with_subscales.rds")

# ===== ADD VARIABLES FROM SIMOA =====
cat("Adding variables from SIMOA dataset...\n")

# Get all imputed datasets in long format
imputed_long <- complete(final_imp, "long", include = TRUE)

# Check if SIMOA exists
if (exists("SIMOA")) {
  # Add scrn_stopped_bzra
  if ("scrn_stopped_bzra" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(scrn_stopped_bzra = SIMOA$scrn_stopped_bzra) %>%
      ungroup()
    cat("  - Added scrn_stopped_bzra\n")
  }
  
  # Add alc_use_men
  if ("alc_use_men" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(alc_use_men = SIMOA$alc_use_men) %>%
      ungroup()
    cat("  - Added alc_use_men\n")
  }
  
  # Add alc_use_wmn
  if ("alc_use_wmn" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(alc_use_wmn = SIMOA$alc_use_wmn) %>%
      ungroup()
    cat("  - Added alc_use_wmn\n")
  }
  
  # Convert back to mids object
  final_imp <- as.mids(imputed_long)
  cat("Successfully updated imputation object\n\n")
} else {
  cat("Warning: SIMOA dataset not found in environment\n\n")
}

# ===== DEFINE ALL VARIABLES =====

continuous_vars <- c(
  "age", "med_quant", "osss_3_score", "phq2_score"
)

subscale_vars <- c(
  "Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
  "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
  "SURPS_Anxiety_Sensitivity",
  "DBAS_Expectations", "DBAS_Medications", "DBAS_Worry_Helplessness", 
  "DBAS_Consequences", "dbas_score",
  "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style"
)

binary_vars <- c("sex", "scrn_stopped_bzra")

unordered_categorical <- c("prov_terr", "gender")

ordered_vars <- c(
  "education", "income", "driving_freq", "employment",
  "side_effects_1", "side_effects_2", "side_effects_3", "side_effects_4",
  "safety_1", "safety_2", "safety_3", "safety_4",
  "adls_1", "adls_2",
  "dependence_1", "dependence_2", "dependence_3",
  "med_burden_1", "med_burden2", "medburden_3", "med_burden_4",
  "op_use", "can_use", "caf_use", "nico_use", 
  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
  "quet_use", "traz_use", "otc_use", "alc_use_men", "alc_use_wmn"
)

# ===== FUNCTIONS FOR POOLING STATISTICS =====

pool_descriptives <- function(mids_obj, vars) {
  results <- data.frame(
    Variable = character(),
    M = numeric(),
    SD = numeric(),
    stringsAsFactors = FALSE
  )
  
  for (var in vars) {
    # Check if variable exists
    if (!var %in% names(complete(mids_obj, 1))) {
      cat(paste0("Warning: Variable '", var, "' not found. Skipping.\n"))
      next
    }
    
    # Extract variable across all imputations
    means <- sapply(1:mids_obj$m, function(i) {
      data <- complete(mids_obj, i)
      mean(data[[var]], na.rm = TRUE)
    })
    
    sds <- sapply(1:mids_obj$m, function(i) {
      data <- complete(mids_obj, i)
      sd(data[[var]], na.rm = TRUE)
    })
    
    # Pool using Rubin's rules
    pooled_mean <- mean(means)
    pooled_sd <- sqrt(mean(sds^2))
    
    results <- rbind(results, data.frame(
      Variable = var,
      M = round(pooled_mean, 2),
      SD = round(pooled_sd, 2)
    ))
  }
  
  return(results)
}

pool_frequencies <- function(mids_obj, vars) {
  results <- list()
  
  for (var in vars) {
    # Check if variable exists
    if (!var %in% names(complete(mids_obj, 1))) {
      cat(paste0("Warning: Variable '", var, "' not found. Skipping.\n"))
      next
    }
    
    data <- complete(mids_obj, 1)
    
    freq_table <- table(data[[var]], useNA = "no")
    pct_table <- prop.table(freq_table) * 100
    
    results[[var]] <- data.frame(
      Variable = var,
      Category = names(freq_table),
      N = as.numeric(freq_table),
      Percentage = round(as.numeric(pct_table), 1)
    )
  }
  
  return(results)
}

# ===== CONTINUOUS VARIABLES =====

cat("\n=== CONTINUOUS VARIABLES (M and SD) ===\n\n")

cat("Demographics & Scale Scores:\n")
continuous_stats <- pool_descriptives(final_imp, continuous_vars)
print(continuous_stats, row.names = FALSE)

cat("\n\nSubscale Scores:\n")
subscale_stats <- pool_descriptives(final_imp, subscale_vars)
print(subscale_stats, row.names = FALSE)

# ===== BINARY VARIABLES =====

cat("\n\n=== BINARY VARIABLES (N and %) ===\n\n")

binary_stats <- pool_frequencies(final_imp, binary_vars)

for (var in names(binary_stats)) {
  print(binary_stats[[var]], row.names = FALSE)
  cat("\n")
}

# ===== UNORDERED CATEGORICAL VARIABLES =====

cat("\n=== UNORDERED CATEGORICAL VARIABLES (N and %) ===\n\n")

unordered_stats <- pool_frequencies(final_imp, unordered_categorical)

for (var in names(unordered_stats)) {
  print(unordered_stats[[var]], row.names = FALSE)
  cat("\n")
}

# ===== ORDERED CATEGORICAL VARIABLES =====

cat("\n=== ORDERED CATEGORICAL VARIABLES (N and %) ===\n\n")

ordered_stats <- pool_frequencies(final_imp, ordered_vars)

for (var in names(ordered_stats)) {
  print(ordered_stats[[var]], row.names = FALSE)
  cat("\n")
}

# ===== CREATE MANUSCRIPT-READY FORMATTED TABLES =====

cat("\n\n=== FORMATTED TABLES FOR MANUSCRIPT ===\n\n")

# Combine all continuous variables
all_continuous <- rbind(
  continuous_stats,
  subscale_stats
)

# Continuous variables with M (SD) format
cat("CONTINUOUS VARIABLES:\n")
formatted_continuous <- all_continuous %>%
  mutate(`M (SD)` = paste0(M, " (", SD, ")")) %>%
  select(Variable, `M (SD)`)
print(formatted_continuous, row.names = FALSE)

# Combine all categorical variables
all_categorical_list <- c(binary_stats, unordered_stats, ordered_stats)
cat_combined <- bind_rows(all_categorical_list, .id = "Variable")

# Categorical variables with N (%) format
cat("\n\nCATEGORICAL VARIABLES:\n")
formatted_categorical <- cat_combined %>%
  mutate(`N (%)` = paste0(N, " (", Percentage, "%)")) %>%
  select(Variable, Category, `N (%)`)
print(formatted_categorical, row.names = FALSE)

# ===== SUMMARY STATISTICS =====

cat("\n\n=== SUMMARY ===\n")
cat(paste0("Total continuous variables: ", nrow(all_continuous), "\n"))
cat(paste0("Total categorical variables: ", length(all_categorical_list), "\n"))
cat(paste0("  - Binary: ", length(binary_stats), "\n"))
cat(paste0("  - Unordered: ", length(unordered_stats), "\n"))
cat(paste0("  - Ordered: ", length(ordered_stats), "\n"))

cat("\n=== COMPLETE ===\n")
```


## DS by BZRA STATUS

```{r}
#| label: Descriptive Statistics by BZRA Status

library(mice)
library(dplyr)
library(tidyr)

cat("\n=== DESCRIPTIVE STATISTICS BY BZRA STATUS ===\n")

final_imp <- readRDS("final_imputation_with_subscales.rds")

# ===== ADD AND RECODE VARIABLES FROM SIMOA =====
cat("Adding and recoding variables from SIMOA...\n")

imputed_long <- complete(final_imp, "long", include = TRUE)

if (exists("SIMOA")) {
  SIMOA <- SIMOA %>%
    mutate(
      region = case_when(
        prov_terr %in% c(1, 2, 3, 12) ~ "Prairies",
        prov_terr %in% c(9, 11) ~ "Central Canada",
        prov_terr %in% c(4, 5, 7, 10) ~ "Atlantic",
        TRUE ~ "Territories"
      ),
      education_grouped = case_when(
        education %in% c(1, 2, 3) ~ "High School or Less",
        education %in% c(4, 5) ~ "University/Trade School",
        TRUE ~ NA_character_
      ),
      employment_grouped = case_when(
        employment %in% c(0, 3, 4) ~ "Not in Workforce",
        employment %in% c(1, 2) ~ "Full- or Part-Time Work",
        TRUE ~ NA_character_
      )
    )
  
  for (new_var in c("scrn_stopped_bzra", "alc_use_men", "alc_use_wmn", 
                     "region", "education_grouped", "employment_grouped")) {
    if (new_var %in% names(SIMOA)) {
      imputed_long <- imputed_long %>%
        group_by(.imp) %>%
        mutate(!!new_var := SIMOA[[new_var]]) %>%
        ungroup()
    }
  }
  
  final_imp <- as.mids(imputed_long)
  cat("Successfully added and recoded variables\n\n")
}

# ===== DEFINE VARIABLES =====
continuous_vars <- c("age", "med_quant", "osss_3_score", "phq2_score")
subscale_vars <- c("Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
                   "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
                   "SURPS_Anxiety_Sensitivity", "DBAS_Expectations", "DBAS_Medications", 
                   "DBAS_Worry_Helplessness", "DBAS_Consequences", "dbas_score",
                   "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style")
binary_vars <- c("sex")
unordered_categorical <- c("gender", "region", "education_grouped", "employment_grouped")
ordered_vars <- c("income", "driving_freq", "side_effects_1", "side_effects_2", 
                  "side_effects_3", "side_effects_4", "safety_1", "safety_2", "safety_3", 
                  "safety_4", "adls_1", "adls_2", "dependence_1", "dependence_2", 
                  "dependence_3", "med_burden_1", "med_burden2", "medburden_3", 
                  "med_burden_4", "op_use", "can_use", "caf_use", "nico_use", 
                  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
                  "quet_use", "traz_use", "otc_use", "alc_use_men", "alc_use_wmn")

# ===== POOLING FUNCTIONS =====
pool_desc_by_group <- function(mids_obj, vars, group_var, group_value) {
  do.call(rbind, lapply(vars, function(var) {
    if (!var %in% names(complete(mids_obj, 1))) return(NULL)
    means <- sapply(1:mids_obj$m, function(i) {
      mean(complete(mids_obj, i)[complete(mids_obj, i)[[group_var]] == group_value, var], na.rm = TRUE)
    })
    sds <- sapply(1:mids_obj$m, function(i) {
      sd(complete(mids_obj, i)[complete(mids_obj, i)[[group_var]] == group_value, var], na.rm = TRUE)
    })
    data.frame(Variable = var, M = round(mean(means), 2), SD = round(sqrt(mean(sds^2)), 2))
  }))
}

pool_freq_by_group <- function(mids_obj, vars, group_var, group_value) {
  setNames(lapply(vars, function(var) {
    if (!var %in% names(complete(mids_obj, 1))) return(NULL)
    group_data <- complete(mids_obj, 1)[complete(mids_obj, 1)[[group_var]] == group_value, ]
    freq <- table(group_data[[var]], useNA = "no")
    pct <- round(prop.table(freq) * 100, 1)
    data.frame(Variable = var, 
               Category = names(freq), 
               N = as.numeric(freq), 
               Pct = as.numeric(pct), 
               stringsAsFactors = FALSE)
  }), vars)
}

pool_t_test <- function(mids_obj, var, group_var) {
  t_res <- lapply(1:mids_obj$m, function(i) {
    data <- complete(mids_obj, i)
    g1 <- data[data[[group_var]] == 1, var]
    g0 <- data[data[[group_var]] == 0, var]
    
    # Remove NAs
    g1 <- g1[!is.na(g1)]
    g0 <- g0[!is.na(g0)]
    
    if(length(g1) > 1 && length(g0) > 1 && sd(g1) > 0 && sd(g0) > 0) {
      t_test <- t.test(g1, g0, var.equal = FALSE)
      list(
        mean_diff = mean(g1) - mean(g0),
        se = t_test$stderr,
        df = t_test$parameter,
        ci_lower = t_test$conf.int[1],
        ci_upper = t_test$conf.int[2]
      )
    } else {
      NULL
    }
  })
  
  # Remove NULL results
  t_res <- t_res[!sapply(t_res, is.null)]
  
  if(length(t_res) == 0) {
    return(list(mean_diff = NA, ci_lower = NA, ci_upper = NA, p_value = NA))
  }
  
  mean_diffs <- sapply(t_res, function(x) x$mean_diff)
  ses <- sapply(t_res, function(x) x$se)
  
  pooled_md <- mean(mean_diffs)
  within_var <- mean(ses^2)
  between_var <- var(mean_diffs)
  
  # Handle case where between_var is 0 or very small
  if(is.na(between_var) || between_var < 1e-10) {
    between_var <- 0
  }
  
  total_var <- within_var + between_var + between_var/length(t_res)
  pooled_se <- sqrt(total_var)
  
  # Calculate degrees of freedom
  if(between_var > 1e-10) {
    lambda <- (between_var + between_var/length(t_res)) / total_var
    df_old <- (length(t_res) - 1) / lambda^2
    df_obs <- mean(sapply(t_res, function(x) x$df))
    df_adj <- (df_obs + 1) / (df_obs + 3) * df_obs * (1 - lambda)
    pooled_df <- df_old * df_adj / (df_old + df_adj)
  } else {
    # If no between-imputation variance, use average df from t-tests
    pooled_df <- mean(sapply(t_res, function(x) x$df))
  }
  
  t_stat <- pooled_md / pooled_se
  p_value <- 2 * pt(-abs(t_stat), df = pooled_df)
  
  t_crit <- qt(0.975, df = pooled_df)
  ci_lower <- pooled_md - t_crit * pooled_se
  ci_upper <- pooled_md + t_crit * pooled_se
  
  list(mean_diff = pooled_md, ci_lower = ci_lower, ci_upper = ci_upper, p_value = p_value)
}

calc_cohens_d <- function(mids_obj, var, group_var) {
  mean(sapply(1:mids_obj$m, function(i) {
    data <- complete(mids_obj, i)
    g1 <- data[data[[group_var]] == 1, var]
    g0 <- data[data[[group_var]] == 0, var]
    (mean(g1, na.rm = TRUE) - mean(g0, na.rm = TRUE)) / 
      sqrt(((length(g1) - 1) * var(g1, na.rm = TRUE) + (length(g0) - 1) * var(g0, na.rm = TRUE)) / 
           (length(g1) + length(g0) - 2))
  }))
}

calc_cramers_v <- function(mids_obj, var, group_var) {
  data <- complete(mids_obj, 1)
  chi <- chisq.test(table(data[[group_var]], data[[var]]))
  list(cramers_v = as.numeric(sqrt(chi$statistic / (sum(table(data[[group_var]], data[[var]])) * 
       (min(dim(table(data[[group_var]], data[[var]]))) - 1)))), p_value = chi$p.value)
}

# ===== SAMPLE SIZES =====
first_imp <- complete(final_imp, 1)
n_yes <- sum(first_imp$scrn_stopped_bzra == 1, na.rm = TRUE)
n_no <- sum(first_imp$scrn_stopped_bzra == 0, na.rm = TRUE)

cat("\n=== SAMPLE SIZES ===\n")
cat("No Longer Taking BZRA (Yes = 1):", n_yes, "\n")
cat("Still Using BZRA (No = 0):", n_no, "\n")
cat("Total:", n_yes + n_no, "\n\n")

# ===== CALCULATE STATISTICS FOR BOTH GROUPS =====
cat("Calculating descriptive statistics...\n")

all_cont_vars <- c(continuous_vars, subscale_vars)
all_cat_vars <- c(binary_vars, unordered_categorical, ordered_vars)

cont_yes <- pool_desc_by_group(final_imp, all_cont_vars, "scrn_stopped_bzra", 1)
cont_no <- pool_desc_by_group(final_imp, all_cont_vars, "scrn_stopped_bzra", 0)

cat_yes <- pool_freq_by_group(final_imp, all_cat_vars, "scrn_stopped_bzra", 1)
cat_no <- pool_freq_by_group(final_imp, all_cat_vars, "scrn_stopped_bzra", 0)

# ===== CONTINUOUS VARIABLES COMPARISON =====
cat("\n========================================\n")
cat("CONTINUOUS VARIABLES COMPARISON\n")
cat("========================================\n\n")

effect_cont <- do.call(rbind, lapply(all_cont_vars, function(var) {
  if (var %in% names(complete(final_imp, 1))) {
    t_res <- pool_t_test(final_imp, var, "scrn_stopped_bzra")
    data.frame(Variable = var, Mean_Diff = round(t_res$mean_diff, 2),
               CI_Lower = round(t_res$ci_lower, 2), CI_Upper = round(t_res$ci_upper, 2),
               Cohens_d = round(calc_cohens_d(final_imp, var, "scrn_stopped_bzra"), 2),
               p_value = round(t_res$p_value, 4))
  }
}))

comparison_cont <- cont_yes %>%
  mutate(`No Longer Taking M (SD)` = paste0(M, " (", SD, ")")) %>%
  select(Variable, `No Longer Taking M (SD)`) %>%
  left_join(cont_no %>% mutate(`Still Using M (SD)` = paste0(M, " (", SD, ")")) %>%
            select(Variable, `Still Using M (SD)`), by = "Variable") %>%
  left_join(effect_cont, by = "Variable") %>%
  mutate(`Mean Diff [95% CI]` = paste0(Mean_Diff, " [", CI_Lower, ", ", CI_Upper, "]"),
         p = ifelse(p_value < 0.001, "<.001", as.character(p_value))) %>%
  select(Variable, `No Longer Taking M (SD)`, `Still Using M (SD)`, 
         `Mean Diff [95% CI]`, Cohens_d, p)

print(comparison_cont, row.names = FALSE)

# ===== CATEGORICAL VARIABLES COMPARISON =====
cat("\n========================================\n")
cat("CATEGORICAL VARIABLES COMPARISON\n")
cat("========================================\n\n")

effect_cat <- do.call(rbind, lapply(all_cat_vars, function(var) {
  if (var %in% names(complete(final_imp, 1))) {
    tryCatch({
      cv <- calc_cramers_v(final_imp, var, "scrn_stopped_bzra")
      data.frame(Variable = var, Cramers_V = round(cv$cramers_v, 3), 
                 p_value = round(cv$p_value, 4))
    }, error = function(e) NULL)
  }
}))

for (var in all_cat_vars) {
  if (var %in% names(cat_yes) && var %in% names(cat_no) && 
      !is.null(cat_yes[[var]]) && !is.null(cat_no[[var]])) {
    cat(paste0("\n", var, ":\n"))
    
    if (var %in% effect_cat$Variable) {
      eff <- effect_cat[effect_cat$Variable == var, ]
      cat(paste0("  Cramers V = ", eff$Cramers_V, ", p ", 
                 ifelse(eff$p_value < 0.001, "< .001", paste0("= ", eff$p_value)), "\n\n"))
    }
    
    # Fix: Add Variable column to the table
    yes_data <- cat_yes[[var]]
    yes_data$Variable <- var
    yes_data$`No Longer Taking N (%)` <- paste0(yes_data$N, " (", yes_data$Pct, "%)")
    yes_data <- yes_data[, c("Variable", "Category", "No Longer Taking N (%)")]
    
    no_data <- cat_no[[var]]
    no_data$`Still Using N (%)` <- paste0(no_data$N, " (", no_data$Pct, "%)")
    no_data <- no_data[, c("Category", "Still Using N (%)")]
    
    comp <- full_join(yes_data, no_data, by = "Category")
    
    print(comp, row.names = FALSE)
    cat("\n")
  }
}

cat("\n=== COMPLETE ===\n")
```


## Cluster Analysis

```{r}
#| label: Focused Clustering Analysis - 35 Variables

# ===== LOAD REQUIRED PACKAGES =====
library(mice)
library(cluster)
library(dplyr)
library(ggplot2)
library(tidyr)

# ===== LOAD IMPUTED DATA WITH SUBSCALES =====
cat("\n=== LOADING IMPUTED DATA ===\n")
final_imp <- readRDS("final_imputation_with_subscales.rds")

# ===== DEFINE FOCUSED VARIABLE SET (35 VARIABLES) =====
cat("\n=== DEFINING FOCUSED VARIABLE SET ===\n")

clustering_vars <- c(
  # Demographics (6)
  "age", "sex", "education", "income", "employment", "med_quant",
  
  # Big Five Personality (5)
  "Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
  
  # SURPS Personality (4)
  "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
  "SURPS_Anxiety_Sensitivity",
  
  # DBAS Sleep Beliefs (4)
  "DBAS_Expectations", "DBAS_Medications", "DBAS_Worry_Helplessness", 
  "DBAS_Consequences",
  
  # CISS Coping Styles (3)
  "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style",
  
  # Side Effects (4)
  "side_effects_1", "side_effects_2", 
  "side_effects_3", "side_effects_4",
  
  # Safety Concerns (4)
  "safety_1", "safety_2", 
  "safety_3", "safety_4",
  
  # ADL Impact (2)
  "adls_1", "adls_2",
  
  # Dependence Concerns (3)
  "dependence_1", "dependence_2", "dependence_3"
)

cat("Using", length(clustering_vars), "variables for focused clustering\n")
cat("\nVariable categories:\n")
cat("  Demographics: 6\n")
cat("  Personality (Big Five + SURPS): 9\n")
cat("  Sleep Beliefs (DBAS): 4\n")
cat("  Coping (CISS): 3\n")
cat("  Side Effects: 4\n")
cat("  Safety Concerns: 4\n")
cat("  ADL Impact: 2\n")
cat("  Dependence Concerns: 3\n")

# ===== PREPARE DATA FOR CLUSTERING =====
cat("\n=== PREPARING DATA FOR CLUSTERING ===\n")

# Function to prepare clustering data
prepare_clustering_data <- function(imp_data, vars) {
  # Get complete data in long format
  complete_data <- mice::complete(imp_data, "long", include = FALSE)
  
  # Select clustering variables
  cluster_data <- complete_data %>%
    select(.imp, .id, all_of(vars))
  
  return(cluster_data)
}

# Prepare data
cluster_long <- prepare_clustering_data(final_imp, clustering_vars)

cat("Data prepared with", nrow(cluster_long), "rows and", 
    length(clustering_vars), "clustering variables\n")

# Check for any missing variables
missing_vars <- setdiff(clustering_vars, names(cluster_long))
if (length(missing_vars) > 0) {
  cat("\nWARNING: The following variables are missing from the dataset:\n")
  print(missing_vars)
  cat("\nProceeding with available variables only.\n")
  clustering_vars <- intersect(clustering_vars, names(cluster_long))
}

# ===== RUN PAM CLUSTERING ACROSS ALL IMPUTATIONS =====
cat("\n=== RUNNING PAM CLUSTERING ===\n")

# Function to run PAM on single imputation
run_pam_single <- function(data, k, vars) {
  # Recode sex to 0/1 for Gower distance calculation
  if ("sex" %in% vars) {
    data$sex_binary <- as.numeric(data$sex) - 1  # Convert factor to 0/1
  }
  
  # Update vars list to use sex_binary
  vars_for_gower <- vars
  if ("sex" %in% vars) {
    vars_for_gower <- c(setdiff(vars, "sex"), "sex_binary")
  }
  
  # Calculate Gower distance
  # Identify ordered variables
  ordered_vars_list <- c("education", "income", "employment")
  ordered_in_data <- intersect(ordered_vars_list, vars_for_gower)
  
  # Identify clinical rating scales (likely ordinal)
  clinical_vars <- vars_for_gower[grepl("side_effects|safety|adls|dependence", vars_for_gower)]
  all_ordered <- unique(c(ordered_in_data, clinical_vars))
  
  gower_dist <- daisy(data[, vars_for_gower], 
                      metric = "gower",
                      type = list(
                        asymm = "sex_binary",
                        ordratio = all_ordered
                      ))
  
  # Run PAM
  pam_result <- pam(gower_dist, k = k, diss = TRUE)
  
  # Calculate silhouette
  sil <- silhouette(pam_result$clustering, gower_dist)
  
  return(list(
    clustering = pam_result$clustering,
    silhouette = mean(sil[, 3]),
    medoids = pam_result$medoids
  ))
}

# Test multiple k values across all imputations
k_values <- 2:6
n_imp <- max(cluster_long$.imp)

results_list <- list()

cat("\nTesting k = 2 to 6 across", n_imp, "imputations...\n")

for (k in k_values) {
  cat("\nTesting k =", k, "...\n")
  
  silhouettes <- numeric(n_imp)
  all_clusterings <- matrix(NA, nrow = nrow(cluster_long)/n_imp, ncol = n_imp)
  
  for (imp in 1:n_imp) {
    imp_data <- cluster_long %>% filter(.imp == imp)
    
    result <- run_pam_single(imp_data, k, clustering_vars)
    
    silhouettes[imp] <- result$silhouette
    all_clusterings[, imp] <- result$clustering
  }
  
  results_list[[paste0("k", k)]] <- list(
    k = k,
    silhouettes = silhouettes,
    mean_sil = mean(silhouettes),
    sd_sil = sd(silhouettes),
    clusterings = all_clusterings
  )
  
  cat("  Mean silhouette:", round(mean(silhouettes), 3), 
      "±", round(sd(silhouettes), 3), "\n")
}

# ===== DETERMINE OPTIMAL K =====
cat("\n=== DETERMINING OPTIMAL K ===\n")

sil_summary <- data.frame(
  k = k_values,
  mean_silhouette = sapply(results_list, function(x) x$mean_sil),
  sd_silhouette = sapply(results_list, function(x) x$sd_sil)
)

print(sil_summary)

optimal_k <- sil_summary$k[which.max(sil_summary$mean_silhouette)]
cat("\nOptimal k =", optimal_k, "with mean silhouette =", 
    round(max(sil_summary$mean_silhouette), 3), "\n")

# Interpret silhouette width
sil_interpretation <- ifelse(max(sil_summary$mean_silhouette) > 0.50, "Strong structure",
                      ifelse(max(sil_summary$mean_silhouette) > 0.25, "Weak structure",
                      ifelse(max(sil_summary$mean_silhouette) > 0.10, "Very weak structure",
                             "No substantial structure")))

cat("Interpretation:", sil_interpretation, "\n")

# ===== VISUALIZE SILHOUETTE WIDTHS =====
sil_plot <- ggplot(sil_summary, aes(x = k, y = mean_silhouette)) +
  geom_line(size = 1, color = "steelblue") +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbar(aes(ymin = mean_silhouette - sd_silhouette,
                    ymax = mean_silhouette + sd_silhouette),
                width = 0.2) +
  geom_vline(xintercept = optimal_k, linetype = "dashed", color = "red") +
  geom_hline(yintercept = c(0.10, 0.25, 0.50), linetype = "dotted", alpha = 0.5) +
  annotate("text", x = max(k_values), y = 0.10, label = "Weak", hjust = 1, vjust = -0.5, size = 3) +
  annotate("text", x = max(k_values), y = 0.25, label = "Fair", hjust = 1, vjust = -0.5, size = 3) +
  annotate("text", x = max(k_values), y = 0.50, label = "Strong", hjust = 1, vjust = -0.5, size = 3) +
  labs(title = "Focused Clustering: Silhouette Width by Number of Clusters",
       subtitle = paste0("Optimal k = ", optimal_k, " | ", sil_interpretation),
       x = "Number of Clusters (k)",
       y = "Mean Silhouette Width") +
  theme_minimal() +
  theme(text = element_text(size = 12))

print(sil_plot)

# ===== ASSESS CLUSTER STABILITY =====
cat("\n=== ASSESSING CLUSTER STABILITY ===\n")

optimal_clusterings <- results_list[[paste0("k", optimal_k)]]$clusterings

# Calculate stability: % of cases assigned to same cluster across imputations
mode_cluster <- apply(optimal_clusterings, 1, function(x) {
  as.numeric(names(sort(table(x), decreasing = TRUE)[1]))
})

agreement <- apply(optimal_clusterings, 1, function(x) {
  sum(x == mode_cluster[1]) / length(x) * 100
})

stability_summary <- data.frame(
  agreement_percent = agreement,
  modal_cluster = mode_cluster
)

cat("\nCluster Stability Summary:\n")
cat("Mean stability:", round(mean(agreement), 1), "%\n")
cat("Median stability:", round(median(agreement), 1), "%\n")
cat("% with 100% agreement:", round(sum(agreement == 100)/length(agreement) * 100, 1), "%\n")
cat("% with ≥80% agreement:", round(sum(agreement >= 80)/length(agreement) * 100, 1), "%\n")
cat("% with <80% agreement:", round(sum(agreement < 80)/length(agreement) * 100, 1), "%\n")

# Distribution of stability
stability_plot <- ggplot(stability_summary, aes(x = agreement_percent)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
  geom_vline(xintercept = 80, linetype = "dashed", color = "red") +
  labs(title = "Focused Clustering: Stability Across Imputations",
       subtitle = paste0("k = ", optimal_k, " | Mean stability = ", 
                        round(mean(agreement), 1), "%"),
       x = "Agreement Across Imputations (%)",
       y = "Number of Participants") +
  theme_minimal()

print(stability_plot)

# ===== ASSIGN FINAL CLUSTERS =====
cat("\n=== ASSIGNING FINAL CLUSTERS ===\n")

# Add clusters back to imputed data
cluster_long_with_clusters <- cluster_long %>%
  mutate(cluster = rep(mode_cluster, times = n_imp),
         stability = rep(agreement, times = n_imp))

# Get full imputed data with original included
full_imputed_long <- complete(final_imp, "long", include = TRUE)

# Add cluster assignments
cluster_assignments <- cluster_long_with_clusters %>%
  select(.imp, .id, cluster, stability) %>%
  distinct()

# Join with full data (excluding .imp = 0 which is original data without clusters)
final_imp_clustered <- full_imputed_long %>%
  left_join(cluster_assignments, by = c(".imp", ".id"))

# Convert back to mids object
final_imp_clustered_mids <- as.mids(final_imp_clustered)

cat("Cluster assignment complete. Mids object created: final_imp_clustered_mids\n")

# ===== COMPARE CLUSTERS ON CLUSTERING VARIABLES =====
cat("\n=== COMPARING CLUSTERS ON CLUSTERING VARIABLES ===\n")

# Use pooled analyses
compare_results <- list()

for (var in clustering_vars) {
  cat("Testing", var, "...\n")
  
  if (var %in% c("sex", "education", "income", "employment")) {
    # Chi-square or Kruskal-Wallis for categorical
    # Use first imputation for non-poolable tests
    test_data <- complete(final_imp_clustered_mids, 1)
    
    if (var == "sex") {
      test_result <- chisq.test(table(test_data$cluster, test_data[[var]]))
      compare_results[[var]] <- list(
        variable = var,
        test = "Chi-square",
        statistic = test_result$statistic,
        p_value = test_result$p.value
      )
    } else {
      # For ordered categorical
      test_result <- kruskal.test(as.numeric(test_data[[var]]) ~ test_data$cluster)
      compare_results[[var]] <- list(
        variable = var,
        test = "Kruskal-Wallis",
        statistic = test_result$statistic,
        p_value = test_result$p.value
      )
    }
  } else if (grepl("side_effects|safety|adls|dependence", var)) {
    # For ordinal clinical variables, use Kruskal-Wallis
    test_data <- complete(final_imp_clustered_mids, 1)
    test_result <- kruskal.test(as.numeric(test_data[[var]]) ~ test_data$cluster)
    compare_results[[var]] <- list(
      variable = var,
      test = "Kruskal-Wallis",
      statistic = test_result$statistic,
      p_value = test_result$p.value
    )
  } else {
    # ANOVA for continuous variables using pooled analysis
    # Manually pool across imputations
    p_values <- numeric(n_imp)
    
    for (i in 1:n_imp) {
      imp_data <- complete(final_imp_clustered_mids, i)
      fit <- lm(as.formula(paste(var, "~ as.factor(cluster)")), data = imp_data)
      p_values[i] <- anova(fit)$"Pr(>F)"[1]
    }
    
    # Use median p-value as pooled estimate (conservative approach)
    compare_results[[var]] <- list(
      variable = var,
      test = "ANOVA (pooled)",
      p_value = median(p_values)
    )
  }
}

# Create summary table
comparison_df <- do.call(rbind, lapply(compare_results, function(x) {
  data.frame(
    Variable = x$variable,
    Test = x$test,
    P_value = round(x$p_value, 4),
    Significant = ifelse(x$p_value < 0.05, "Yes", "No")
  )
}))

cat("\n=== VARIABLE COMPARISON RESULTS ===\n")
print(comparison_df)

cat("\n=== SIGNIFICANT DIFFERENCES (p < 0.05) ===\n")
sig_vars <- comparison_df %>% filter(Significant == "Yes")
print(sig_vars)
cat("\nNumber of significant variables:", nrow(sig_vars), "out of", nrow(comparison_df), "\n")

# ===== COMPARE CLUSTERS ON OUTCOME =====
cat("\n=== COMPARING CLUSTERS ON OUTCOME (scrn_stopped_bzra) ===\n")

# Chi-square test for outcome
outcome_data <- complete(final_imp_clustered_mids, 1)

if ("scrn_stopped_bzra" %in% names(outcome_data)) {
  outcome_table <- table(outcome_data$cluster, outcome_data$scrn_stopped_bzra)
  outcome_test <- chisq.test(outcome_table)
  
  cat("\nOutcome by Cluster:\n")
  print(outcome_table)
  cat("\nProportions (row percentages):\n")
  print(round(prop.table(outcome_table, 1) * 100, 1))
  
  cat("\nChi-square test: X² =", round(outcome_test$statistic, 2),
      ", p =", round(outcome_test$p.value, 4), "\n")
  
  # Visualize
  outcome_props <- as.data.frame(prop.table(outcome_table, 1))
  names(outcome_props) <- c("Cluster", "Outcome", "Proportion")
  
  outcome_plot <- ggplot(outcome_props, aes(x = Cluster, y = Proportion * 100, fill = Outcome)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(title = "BZRA Cessation by Cluster",
         x = "Cluster",
         y = "Percentage (%)",
         fill = "Stopped BZRA") +
    theme_minimal() +
    theme(text = element_text(size = 12))
  
  print(outcome_plot)
}

# ===== CLUSTER DESCRIPTIONS =====
cat("\n=== CLUSTER DESCRIPTIONS ===\n")

# Get means/frequencies by cluster for key variables
cluster_data_complete <- complete(final_imp_clustered_mids, 1)

# Demographic summary
demo_summary <- cluster_data_complete %>%
  group_by(cluster) %>%
  summarise(
    n = n(),
    mean_age = round(mean(age, na.rm = TRUE), 1),
    pct_female = round(mean(sex == "Female", na.rm = TRUE) * 100, 1),
    mean_med_quant = round(mean(med_quant, na.rm = TRUE), 1),
    .groups = "drop"
  )

cat("\nDemographic Summary by Cluster:\n")
print(demo_summary)

# ===== SUMMARY REPORT =====
cat("\n========================================\n")
cat("     FOCUSED CLUSTERING COMPLETE\n")
cat("========================================\n")
cat("Variables used:", length(clustering_vars), "\n")
cat("  - Demographics: 6\n")
cat("  - Personality: 9\n")
cat("  - Sleep beliefs: 4\n")
cat("  - Coping: 3\n")
cat("  - Medication concerns: 13\n")
cat("\nOptimal k:", optimal_k, "\n")
cat("Mean silhouette width:", round(results_list[[paste0("k", optimal_k)]]$mean_sil, 3), "\n")
cat("Interpretation:", sil_interpretation, "\n")
cat("\nCluster stability:", round(mean(agreement), 1), "%\n")
cat("Cases with ≥80% stability:", round(sum(agreement >= 80)/length(agreement) * 100, 1), "%\n")
cat("\nSignificant variables:", sum(comparison_df$Significant == "Yes"), 
    "out of", nrow(comparison_df), "\n")

if ("scrn_stopped_bzra" %in% names(outcome_data)) {
  cat("\nOutcome analysis:\n")
  cat("  Chi-square p-value:", round(outcome_test$p.value, 4), "\n")
  if (outcome_test$p.value < 0.05) {
    cat("  *** Clusters differ significantly on BZRA cessation! ***\n")
  } else {
    cat("  Clusters do not differ significantly on BZRA cessation.\n")
  }
}

cat("========================================\n")

cat("\nNext steps:\n")
cat("1. Review silhouette width - did it improve from your initial 0.107?\n")
cat("2. Check which variables differ significantly between clusters\n")
cat("3. Examine outcome differences between clusters\n")
cat("4. If results look good, re-run with file saving enabled\n")
cat("\nObjects created:\n")
cat("  - results_list: all clustering results\n")
cat("  - sil_summary: silhouette summary table\n")
cat("  - comparison_df: variable comparison results\n")
cat("  - final_imp_clustered_mids: imputed data with cluster assignments\n")
```


