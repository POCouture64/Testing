---
title: "NEW"
author: "PO Couture"
format: html
editor: visual
---

##  New

I will use this document to work on my SIMOA code since I am having trouble with it currently in the existing format. In this way I can mess around with this code and not be worried about it impacting my original data and now that I know what I want to do for my clusters it is easier for me to manipulate the variables in a manner that will set me up for success later.

## Loading the Data

The section I will use to load the dataset that I will use for the analysis.

```{r}
#| label: Loading the Data and Libraries
######
# Loading the data
######

library(readr)
SIMOA <- read_csv("SIMOA Report.csv")
#View(SIMOA)
```


## Eligible Participants

The section where I have set out the inclusion criteria to remove people from the dataset that do not meet our criteria.

```{r}
#| label: Eligible Participants
######
# In this section I will filter out those who have indicated they are <65 or that have not answered   
# yes to the question about age category or not answered either question. I will also filter out those 
# who did not select one of the 14 BZRAs listed because we do not want the results to be affected by 
# other sedating medications such as antihistamines or SSRI's.
# Additionally, filter to include only those who answered the scrn_stopped_bzra question.
######

# Original count
n_original <- nrow(SIMOA)

# After age filtering
SIMOA_age_filtered <- SIMOA %>%
  filter(age_cat == 1 | (age_cat == 0 & age >= 65))
n_after_age <- nrow(SIMOA_age_filtered)

# After c_sp filtering
SIMOA_c_sp_filtered <- SIMOA_age_filtered %>%
  filter(rowSums(select(., starts_with("c_sp___"))[, 1:14] == 1, na.rm = TRUE) > 0)
n_after_c_sp <- nrow(SIMOA_c_sp_filtered)

# After prov_terr filtering (remove answer 14)
SIMOA_prov_filtered <- SIMOA_c_sp_filtered %>%
  filter(prov_terr != 14 | is.na(prov_terr))
n_after_prov <- nrow(SIMOA_prov_filtered)

# After scrn_stopped_bzra filtering (only those who answered the question)
SIMOA <- SIMOA_prov_filtered %>%
  filter(!is.na(scrn_stopped_bzra))
n_final <- nrow(SIMOA)

# Report results
cat("Original sample:", n_original, "\n")
cat("After age filtering:", n_after_age, "(removed:", n_original - n_after_age, ")\n")
cat("After c_sp filtering:", n_after_c_sp, "(removed:", n_after_age - n_after_c_sp, ")\n")
cat("After prov_terr filtering:", n_after_prov, "(removed:", n_after_c_sp - n_after_prov, ")\n")
cat("After scrn_stopped_bzra filtering:", n_final, "(removed:", n_after_prov - n_final, ")\n")
cat("Total removed:", n_original - n_final, "\n")
```


## Data Preperation

This section prepare the data for MI and only include those with a complete scrn_stopped_bzra
```{r}
#| label: Data Preparation for Multiple Imputation
######
# Prepare data_personality dataset for multiple imputation
# Combine individual adverse effects items BEFORE imputation
######

library(dplyr)
library(mice)

cat("=== DATA PREPARATION FOR MULTIPLE IMPUTATION ===\n")

# Start with SIMOA dataset (the original full dataset)
# Note: Filtering for valid scrn_stopped_bzra cases was done previously
cat("SIMOA dataset size:", nrow(SIMOA), "\n")

# Verify outcome variable distribution
cat("scrn_stopped_bzra distribution:\n")
print(table(SIMOA$scrn_stopped_bzra, useNA = "ifany"))

######
# COMBINE ADVERSE EFFECTS ITEMS (v1 and v2 versions)
######

cat("\n=== COMBINING ADVERSE EFFECTS ITEMS ===\n")
cat("NOTE: Combining v1 and v2 versions into single variables.\n\n")

# Function to combine v1 and v2 versions (take first non-NA value)
combine_versions <- function(v1, v2) {
  ifelse(!is.na(v1), v1, v2)
}

# Define item pairs to combine
adverse_item_pairs <- list(
  # Side effects
  side_effects_1 = c("side_effects_1", "side_effects_1_v2"),
  side_effects_2 = c("side_effects_2", "side_effects_2_v2"),
  side_effects_3 = c("side_effects_3", "side_effects_3_v2"),
  side_effects_4 = c("side_effects_4", "side_effects_4_v2"),
  # Safety
  safety_1 = c("safety_1", "safety_1_v2"),
  safety_2 = c("safety_2", "safety_2_v2"),
  safety_3 = c("safety_3", "safety_3_v2"),
  safety_4 = c("safety_4", "safety_4_v2"),
  # ADLs
  adls_1 = c("adls_1", "adls_1_v2"),
  adls_2 = c("adls_2", "adls_2_v2"),
  # Dependence
  dependence_1 = c("dependence_1", "dependence_1_v2"),
  dependence_2 = c("dependence_2", "dependence_2_v2"),
  dependence_3 = c("dependence_3", "dependence_3_v2")
)

# Combine v1 and v2 versions
for(item_name in names(adverse_item_pairs)) {
  v1_col <- adverse_item_pairs[[item_name]][1]
  v2_col <- adverse_item_pairs[[item_name]][2]
  
  if(v1_col %in% names(SIMOA) && v2_col %in% names(SIMOA)) {
    SIMOA[[item_name]] <- combine_versions(
      SIMOA[[v1_col]], 
      SIMOA[[v2_col]]
    )
    na_count <- sum(is.na(SIMOA[[item_name]]))
    cat("Combined", v1_col, "and", v2_col, "into", item_name, "- Missing:", na_count, "\n")
  } else if(v1_col %in% names(SIMOA)) {
    SIMOA[[item_name]] <- SIMOA[[v1_col]]
    na_count <- sum(is.na(SIMOA[[item_name]]))
    cat("Only", v1_col, "found, using as", item_name, "- Missing:", na_count, "\n")
  } else if(v2_col %in% names(SIMOA)) {
    SIMOA[[item_name]] <- SIMOA[[v2_col]]
    na_count <- sum(is.na(SIMOA[[item_name]]))
    cat("Only", v2_col, "found, using as", item_name, "- Missing:", na_count, "\n")
  }
}

######
# DEFINE VARIABLES FOR ANALYSIS
######

cat("\n=== SELECTING VARIABLES FOR ANALYSIS ===\n")

# Core variables requested
core_vars <- c(
  "age", "sex", "gender",
  "osss_3_score", "phq2_score",
  "prov_terr", "education", "employment", "driving_freq", "income",
  "med_quant", "med_burden_1", "med_burden2", "medburden_3", "med_burden_4",
  "op_use", "can_use", "caf_use", "nico_use", "alc_sleep", "can_sleep", 
  "melatonin_use", "op_sleep", "quet_use", "traz_use", "otc_use",
  "alc_use_wmn", "alc_use_men"
)

# Combined adverse effects items (individual items, not totals)
adverse_items_combined <- c(
  # Side effects (4 items)
  "side_effects_1", "side_effects_2", "side_effects_3", "side_effects_4",
  # Safety (4 items)
  "safety_1", "safety_2", "safety_3", "safety_4",
  # ADLs (2 items)
  "adls_1", "adls_2",
  # Dependence (3 items)
  "dependence_1", "dependence_2", "dependence_3"
)

# Individual questionnaire items (to be imputed separately)
questionnaire_items <- c(
  # DBAS items (all 16 individual items)
  "dbas1", "dbas_2", "dbas_3", "dbas_4", "dbas_5", "dbas_6", "dbas_7", "dbas_8",
  "dbas_9", "dbas_10", "dbas_11", "dbas_12", "dbas_13", "dbas_14", "dbas_15", "dbas_16",
  # BFI items (all 10 individual items)
  "reserved", "outgoing", "find_fault", "trusting", "lazy", "thorough", 
  "relaxed", "nervous", "few_interests", "imagination",
  # SURPS items (all 23 individual items)
  "surps1", "surps2", "surps3", "surps4", "surps5", "surps6", "surps7", "surps8",
  "surps9", "surps10", "surps11", "surps12", "surps13", "surps14", "surps15", "surps16",
  "surps17", "surps18", "surps19", "surps20", "surps21", "surps22", "surps23",
  # CISS items (all 21 individual items)
  "ciss1", "ciss2", "ciss3", "ciss4", "ciss5", "ciss6", "ciss7", "ciss8", "ciss9",
  "ciss10", "ciss11", "ciss12", "ciss13", "ciss14", "ciss15", "ciss16", "ciss17",
  "ciss18", "ciss19", "ciss20", "ciss21"
)

cat("Specified", length(questionnaire_items), "individual questionnaire items\n")
cat("Found", length(adverse_items_combined), "combined adverse effects items\n")

# All variables for analysis (core + individual questionnaire items + adverse items)
all_analysis_vars <- unique(c(core_vars, questionnaire_items, adverse_items_combined))

cat("Total variables requested:", length(all_analysis_vars), "\n")

######
# CHECK VARIABLE AVAILABILITY AND CREATE SUBSET
######

# Check which variables are available
available_vars <- all_analysis_vars[all_analysis_vars %in% names(SIMOA)]
missing_vars <- all_analysis_vars[!all_analysis_vars %in% names(SIMOA)]

cat("Variables available:", length(available_vars), "\n")
cat("Variables not found:", length(missing_vars), "\n")

if(length(missing_vars) > 0) {
  cat("\nMissing variables:\n")
  for(var in missing_vars) {
    cat("  -", var, "\n")
  }
}

# Create analysis dataset with available variables
final_dataset_imputed <- SIMOA[, available_vars, drop = FALSE]

######
# HANDLE CONDITIONAL SUBSTANCE USE VARIABLES
######

cat("\n=== HANDLING CONDITIONAL SUBSTANCE USE VARIABLES ===\n")

# These variables were only shown to participants who selected them in previous questions
# NA means they never use these substances, so recode NA to 0 ("Never")
conditional_vars <- c("op_use", "can_use", "caf_use", "nico_use", "alc_sleep", 
                      "can_sleep", "melatonin_use", "op_sleep", "quet_use", 
                      "traz_use", "otc_use")

for(var in conditional_vars) {
  if(var %in% names(final_dataset_imputed)) {
    original_na_count <- sum(is.na(final_dataset_imputed[[var]]))
    
    # Recode NA to 0 (Never used)
    final_dataset_imputed[[var]][is.na(final_dataset_imputed[[var]])] <- 0
    
    cat("Recoded", original_na_count, "NA values to 0 ('Never') for", var, "\n")
  }
}

######
# HANDLE SEX-SPECIFIC ALCOHOL USE VARIABLES - ENFORCE MUTUAL EXCLUSIVITY
######

cat("\n=== HANDLING SEX-SPECIFIC ALCOHOL USE VARIABLES ===\n")

# CRITICAL: alc_use_wmn should ONLY have values for women (sex = 1)
#           alc_use_men should ONLY have values for men (sex = 2)
#           This ensures mutual exclusivity

if("alc_use_wmn" %in% names(final_dataset_imputed) && "sex" %in% names(final_dataset_imputed)) {
  # For women (sex = 1): Keep their actual values as-is (including true missing data)
  # For men (sex = 2): Set ALL values to NA (they should never have answered this)
  
  men_with_wmn_data <- sum(!is.na(final_dataset_imputed$alc_use_wmn) & final_dataset_imputed$sex == 2, na.rm = TRUE)
  if(men_with_wmn_data > 0) {
    cat("⚠ WARNING: Found", men_with_wmn_data, "men with alc_use_wmn data - setting to NA\n")
  }
  
  final_dataset_imputed$alc_use_wmn[final_dataset_imputed$sex == 2] <- NA
  
  # Report missing data in women (true missing that needs imputation)
  women_na_count <- sum(is.na(final_dataset_imputed$alc_use_wmn) & final_dataset_imputed$sex == 1, na.rm = TRUE)
  women_total <- sum(final_dataset_imputed$sex == 1, na.rm = TRUE)
  cat("alc_use_wmn - Women (sex=1): ", women_na_count, " missing out of ", women_total, 
      " (", round(100*women_na_count/women_total, 1), "%)\n", sep="")
  cat("alc_use_wmn - Men (sex=2): All set to NA (mutually exclusive)\n")
}

if("alc_use_men" %in% names(final_dataset_imputed) && "sex" %in% names(final_dataset_imputed)) {
  # For men (sex = 2): Keep their actual values as-is (including true missing data)
  # For women (sex = 1): Set ALL values to NA (they should never have answered this)
  
  women_with_men_data <- sum(!is.na(final_dataset_imputed$alc_use_men) & final_dataset_imputed$sex == 1, na.rm = TRUE)
  if(women_with_men_data > 0) {
    cat("⚠ WARNING: Found", women_with_men_data, "women with alc_use_men data - setting to NA\n")
  }
  
  final_dataset_imputed$alc_use_men[final_dataset_imputed$sex == 1] <- NA
  
  # Report missing data in men (true missing that needs imputation)
  men_na_count <- sum(is.na(final_dataset_imputed$alc_use_men) & final_dataset_imputed$sex == 2, na.rm = TRUE)
  men_total <- sum(final_dataset_imputed$sex == 2, na.rm = TRUE)
  cat("alc_use_men - Men (sex=2): ", men_na_count, " missing out of ", men_total, 
      " (", round(100*men_na_count/men_total, 1), "%)\n", sep="")
  cat("alc_use_men - Women (sex=1): All set to NA (mutually exclusive)\n")
}

# Verify mutual exclusivity
if("alc_use_wmn" %in% names(final_dataset_imputed) && "alc_use_men" %in% names(final_dataset_imputed)) {
  both_present <- sum(!is.na(final_dataset_imputed$alc_use_wmn) & !is.na(final_dataset_imputed$alc_use_men))
  cat("\n✓ VERIFICATION: Cases with both alc_use_wmn AND alc_use_men:", both_present, "\n")
  
  if(both_present > 0) {
    cat("⚠ ERROR: Mutual exclusivity NOT achieved!\n")
  } else {
    cat("✓ SUCCESS: Mutual exclusivity confirmed - no participant has values in both variables\n")
  }
}

######
# FINAL DATASET SUMMARY
######

cat("\n=== FINAL DATASET SUMMARY ===\n")
cat("Final dataset dimensions:", dim(final_dataset_imputed), "\n")
cat("Number of participants:", nrow(final_dataset_imputed), "\n")
cat("Number of variables:", ncol(final_dataset_imputed), "\n")

# Missing data summary
cat("\n=== MISSING DATA SUMMARY ===\n")
missing_summary <- sapply(final_dataset_imputed, function(x) sum(is.na(x)))
variables_with_missing <- missing_summary[missing_summary > 0]

if(length(variables_with_missing) > 0) {
  cat("Variables with missing data:\n")
  for(i in 1:length(variables_with_missing)) {
    var_name <- names(variables_with_missing)[i]
    missing_count <- variables_with_missing[i]
    missing_pct <- round((missing_count / nrow(final_dataset_imputed)) * 100, 1)
    cat(paste("  ", var_name, ":", missing_count, "(", missing_pct, "%)\n"))
  }
  
  # Overall completeness
  complete_cases <- sum(complete.cases(final_dataset_imputed))
  complete_pct <- round((complete_cases / nrow(final_dataset_imputed)) * 100, 1)
  cat("\nComplete cases:", complete_cases, "out of", nrow(final_dataset_imputed), 
      "(", complete_pct, "%)\n")
} else {
  cat("No missing data found in any variables!\n")
}

cat("\n=== DATA PREPARATION COMPLETE ===\n")
cat("Dataset 'final_dataset_imputed' is ready for multiple imputation analysis\n")
cat("IMPORTANT: Individual questionnaire items (DBAS, BFI, SURPS, CISS) are included for imputation.\n")
cat("           Create subscale scores AFTER imputation is complete.\n")
cat("           Adverse effects items (side_effects_1-4, safety_1-4, adls_1-2, dependence_1-3)\n")
cat("           have been combined from v1 and v2 versions and are ready for imputation.\n")
```


## MI Optimization and Pilot

```{r}
#| label: Multiple Imputation with Proper Variable Types

library(mice)
library(dplyr)

cat("\n=== OPTIMIZED MULTIPLE IMPUTATION ===\n")

# ===== DATA PREPARATION =====
impute_data <- as.data.frame(final_dataset_imputed)
impute_data$alc_use_wmn <- NULL
impute_data$alc_use_men <- NULL

cat("Working dimensions:", dim(impute_data), "\n")
cat("Total missing values:", sum(is.na(impute_data)), "\n")

# ===== STEP 1: SET VARIABLE TYPES =====
cat("\n=== STEP 1: SETTING VARIABLE TYPES ===\n")

continuous_vars <- c(
  "age", "med_quant", "osss_3_score", "phq2_score",
  "dbas1", "dbas_2", "dbas_3", "dbas_4", "dbas_5", "dbas_6", "dbas_7", "dbas_8",
  "dbas_9", "dbas_10", "dbas_11", "dbas_12", "dbas_13", "dbas_14", "dbas_15", "dbas_16",
  "reserved", "outgoing", "find_fault", "trusting", "lazy", "thorough", 
  "relaxed", "nervous", "few_interests", "imagination",
  "surps1", "surps2", "surps3", "surps4", "surps5", "surps6", "surps7", "surps8",
  "surps9", "surps10", "surps11", "surps12", "surps13", "surps14", "surps15", "surps16",
  "surps17", "surps18", "surps19", "surps20", "surps21", "surps22", "surps23",
  "ciss1", "ciss2", "ciss3", "ciss4", "ciss5", "ciss6", "ciss7", "ciss8", "ciss9",
  "ciss10", "ciss11", "ciss12", "ciss13", "ciss14", "ciss15", "ciss16", "ciss17",
  "ciss18", "ciss19", "ciss20", "ciss21"
)

binary_vars <- c("sex")

unordered_categorical <- c("prov_terr", "gender")

ordered_vars <- c(
  "education", "income", "driving_freq", "employment",
  "side_effects_1", "side_effects_2", "side_effects_3", "side_effects_4",
  "safety_1", "safety_2", "safety_3", "safety_4",
  "adls_1", "adls_2",
  "dependence_1", "dependence_2", "dependence_3",
  "med_burden_1", "med_burden2", "medburden_3", "med_burden_4",
  "op_use", "can_use", "caf_use", "nico_use", 
  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
  "quet_use", "traz_use", "otc_use"
)

# Format variables
for(var in continuous_vars) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- as.numeric(impute_data[[var]])
  }
}

for(var in binary_vars) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- factor(impute_data[[var]])
  }
}

for(var in unordered_categorical) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- factor(impute_data[[var]], ordered = FALSE)
  }
}

for(var in ordered_vars) {
  if(var %in% names(impute_data)) {
    impute_data[[var]] <- factor(impute_data[[var]], ordered = TRUE)
  }
}

cat("Continuous:", length(intersect(continuous_vars, names(impute_data))), "\n")
cat("Binary:", length(intersect(binary_vars, names(impute_data))), "\n")
cat("Unordered categorical:", length(intersect(unordered_categorical, names(impute_data))), "\n")
cat("Ordered categorical:", length(intersect(ordered_vars, names(impute_data))), "\n")

# ===== STEP 2: FIND OPTIMAL THRESHOLDS =====
cat("\n=== STEP 2: TESTING PREDICTOR MATRIX THRESHOLDS ===\n")

test_thresholds <- function(data, mincor_vals, minpuc_vals) {
  results <- data.frame()
  
  for(mc in mincor_vals) {
    for(mp in minpuc_vals) {
      pred <- quickpred(data, mincor = mc, minpuc = mp)
      n_vars_with_predictors <- sum(rowSums(pred) > 0)
      
      if(n_vars_with_predictors > 0) {
        avg_preds <- sum(pred) / n_vars_with_predictors
      } else {
        avg_preds <- 0
      }
      
      results <- rbind(results, data.frame(
        mincor = mc,
        minpuc = mp,
        total_predictions = sum(pred),
        avg_predictors = round(avg_preds, 1),
        pct_reduction = round((1 - sum(pred)/prod(dim(pred))) * 100, 1)
      ))
    }
  }
  return(results)
}

threshold_results <- test_thresholds(
  impute_data,
  mincor_vals = c(0.1, 0.2, 0.3, 0.4),
  minpuc_vals = c(0.2, 0.3, 0.4, 0.5)
)

print(threshold_results)

# Select threshold with avg_predictors between 10-25
optimal <- threshold_results[
  threshold_results$avg_predictors >= 10 & 
  threshold_results$avg_predictors <= 25, 
][1,]

if(nrow(optimal) == 0) {
  cat("\nNo optimal threshold found in 10-25 range, using mincor=0.3, minpuc=0.3\n")
  mincor_use <- 0.3
  minpuc_use <- 0.3
} else {
  cat("\nOptimal threshold selected:\n")
  print(optimal)
  mincor_use <- optimal$mincor
  minpuc_use <- optimal$minpuc
}

# ===== STEP 3: CREATE REDUCED PREDICTOR MATRIX =====
cat("\n=== STEP 3: CREATING OPTIMIZED PREDICTOR MATRIX ===\n")

predMatrix <- quickpred(impute_data, mincor = mincor_use, minpuc = minpuc_use)

# Remove problematic predictors (sparse categories causing convergence issues)
predMatrix[, "prov_terr"] <- 0

cat("Original predictor matrix:", prod(dim(impute_data)), "potential predictions\n")
cat("Reduced predictor matrix:", sum(predMatrix), "predictions\n")
cat("Reduction:", round((1 - sum(predMatrix)/prod(dim(predMatrix))) * 100, 1), "%\n")
cat("Note: Removed prov_terr as predictor (sparse categories)\n")

# ===== STEP 4: INITIALIZE AND SET METHODS =====
cat("\n=== STEP 4: INITIALIZING MICE WITH CUSTOM METHODS ===\n")

init <- mice(impute_data, maxit = 0, print = FALSE)
method <- init$method

# Set methods
for(var in continuous_vars) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "pmm"
  }
}

for(var in binary_vars) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "logreg"
  }
}

for(var in unordered_categorical) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "polyreg"
  }
}

for(var in ordered_vars) {
  if(var %in% names(method) && method[var] != "") {
    method[var] <- "polr"
  }
}

cat("Method assignment:\n")
print(table(method[method != ""]))

# ===== STEP 5: RUN OPTIMIZED PILOT =====
cat("\n=== STEP 5: RUNNING OPTIMIZED PILOT (m=5, maxit=5) ===\n")

start_time <- Sys.time()
pilot <- mice(
  impute_data,
  method = method,
  predictorMatrix = predMatrix,
  m = 5,
  maxit = 5,
  seed = 123,
  printFlag = FALSE
)
end_time <- Sys.time()

pilot_time <- round(difftime(end_time, start_time, units="secs"), 2)
cat("Pilot completed in", pilot_time, "seconds\n")

# ===== STEP 6: VERIFY AND DIAGNOSE =====
cat("\n=== STEP 6: VERIFICATION & DIAGNOSTICS ===\n")

cat("Logged events:", nrow(pilot$loggedEvents), "\n")
completed <- complete(pilot, 1)
remaining_na <- sum(is.na(completed))

if(remaining_na == 0) {
  cat("SUCCESS: All missing values imputed!\n\n")
  
  # Check convergence
  cat("Checking convergence (visual inspection recommended):\n")
  cat("Run: plot(pilot) to inspect trace plots\n\n")
  
  # Estimate full imputation time
  overall_missing_pct <- mean(is.na(impute_data)) * 100
  m_rec <- max(20, min(100, ceiling(overall_missing_pct)))
  maxit_rec <- max(10, ceiling(overall_missing_pct / 2))
  
  estimated_time <- as.numeric(pilot_time) * (m_rec / 5) * (maxit_rec / 5)
  
  cat("=== READY FOR FULL IMPUTATION ===\n")
  cat("Recommended settings:\n")
  cat("  m =", m_rec, "\n")
  cat("  maxit =", maxit_rec, "\n")
  cat("  mincor =", mincor_use, "\n")
  cat("  minpuc =", minpuc_use, "\n\n")
  cat("Estimated time:", round(estimated_time / 60, 1), "minutes\n\n")
  
  cat("To run full imputation:\n")
  cat("final_imp <- mice(\n")
  cat("  impute_data,\n")
  cat("  method = method,\n")
  cat("  predictorMatrix = predMatrix,\n")
  cat("  m =", m_rec, ",\n")
  cat("  maxit =", maxit_rec, ",\n")
  cat("  seed = 123,\n")
  cat("  printFlag = TRUE\n")
  cat(")\n\n")
  
  cat("Save results:\n")
  cat("saveRDS(final_imp, 'imputed_data.rds')\n")
  
} else {
  cat("WARNING:", remaining_na, "values still missing\n")
  na_by_var <- colSums(is.na(completed))
  cat("\nVariables with remaining NAs:\n")
  print(na_by_var[na_by_var > 0])
  cat("\nConsider:\n")
  cat("1. Lowering mincor/minpuc thresholds\n")
  cat("2. Checking variable types and coding\n")
  cat("3. Increasing maxit\n")
}

# Save convergence trace plots
png("IMP_CONV_PLOT.png", width = 1200, height = 800, res = 120)
plot(pilot)
dev.off()

# Get convergence statistics
install.packages("broom")
library(broom)

# Extract mean and SD across iterations for each variable
conv_summary <- pilot$chainMean
print(conv_summary)

# Or get the full chain variance
conv_var <- pilot$chainVar
print(conv_var)

cat("\n=== OPTIMIZATION COMPLETE ===\n")
```


## Multiple Imputation

```{r}
#| label: MI Execution

library(mice)

cat("\n=== RUNNING FULL IMPUTATION ===\n")
cat("Start time:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n\n")

# You should already have these from your optimization:
# - impute_data (prepared data)
# - method (imputation methods)
# - predMatrix (optimized predictor matrix)

cat("Configuration:\n")
cat("  Variables to impute:", sum(method != ""), "\n")
cat("  Predictor relationships:", sum(predMatrix), "\n")
cat("  m = 20 datasets\n")
cat("  maxit = 10 iterations\n")
cat("  Estimated time: ~10-12 minutes\n\n")

# ===== RUN FULL IMPUTATION =====
start_time <- Sys.time()

final_imp <- mice(
  impute_data,
  method = method,
  predictorMatrix = predMatrix,
  m = 20,
  maxit = 10,
  seed = 123,
  printFlag = TRUE
)

end_time <- Sys.time()
imputation_time <- difftime(end_time, start_time, units = "mins")

# ===== VERIFY AND SAVE =====
cat("\n=== IMPUTATION COMPLETE ===\n")
cat("Total time:", round(imputation_time, 2), "minutes\n")
cat("Logged events:", nrow(final_imp$loggedEvents), "\n\n")

# Check completion
completed_data <- complete(final_imp, 1)
remaining_na <- sum(is.na(completed_data))

if(remaining_na == 0) {
  cat("SUCCESS: All missing values imputed\n\n")
} else {
  cat("WARNING:", remaining_na, "values still missing\n\n")
}

# Save results
saveRDS(final_imp, "final_imputation.rds")
cat("Saved: final_imputation.rds\n")

write.csv(completed_data, "imputed_dataset_1.csv", row.names = FALSE)
cat("Saved: imputed_dataset_1.csv\n\n")

# Save diagnostics
png("FULL_IMP_CONV.png", width = 1400, height = 1000, res = 120)
plot(final_imp)
dev.off()
cat("Saved: FULL_IMP_CONV.png\n")

# For continuous variables
png("FULL_IMP_STRIP_CONT.png", width = 1400, height = 1000, res = 120)
stripplot(final_imp, osss_3_score + dbas1 + surps1 + ciss1 ~ .imp, 
          pch = 20, cex = 0.8)
dev.off()

# For categorical variables
png("FULL_IMP_STRIP_CAT.png", width = 1400, height = 1000, res = 120)
stripplot(final_imp, education + income + employment ~ .imp, pch = 20, cex = 1.2)
dev.off()

cat("End time:", format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
cat("\nTo use imputed data:\n")
cat("fit <- with(final_imp, lm(outcome ~ predictors))\n")
cat("summary(pool(fit))\n")
```



## Calculating Subscale Scores

The section where I go about calculating the subscale scores for all the measures and ensure that this is properly done and that way I can compare the groups in subscales rather than the full measure and it makes it easier to report.

```{r}
#| label: Subscale Scores
######
# In this section I will get the subscale scores for all the measures I # have used. I will also ensure that items are appropriately            # reverse-coded.
# All subscale score coding will be found in this chunk but I have      # divided them to make them easy to find. I would rather have 1 chunk   # that way it cuts down on the amount of space being taken up for this  # step.
######

# ===== CREATE SUBSCALES AFTER IMPUTATION =====
# This must be done AFTER imputation, not before
# We'll use mice::complete() with "long" format to work with all imputed datasets

cat("\n=== CREATING SUBSCALES FOR IMPUTED DATA ===\n")

# Get all imputed datasets in long format
imputed_long <- complete(final_imp, "long", include = TRUE)

# ===== BFI-10 SUBSCALE SCORES =====
cat("Creating BFI-10 subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    # Reverse code items (assuming 1-5 scale, adjust if different)
    reserved_rev = 6 - reserved,
    find_fault_rev = 6 - find_fault,
    lazy_rev = 6 - lazy,
    relaxed_rev = 6 - relaxed,
    few_interests_rev = 6 - few_interests,
    
    # Create subscales
    Extraversion = reserved_rev + outgoing,
    Agreeableness = trusting + find_fault_rev,
    Conscientiousness = lazy_rev + thorough,
    Neuroticism = relaxed_rev + nervous,
    Openness = few_interests_rev + imagination
  )

# ===== SURPS SUBSCALE SCORES =====
cat("Creating SURPS subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    # Reverse code Hopelessness items (1-4 scale)
    surps1_rev = 5 - surps1,
    surps4_rev = 5 - surps4,
    surps7_rev = 5 - surps7,
    surps13_rev = 5 - surps13,
    surps20_rev = 5 - surps20,
    surps23_rev = 5 - surps23,
    
    # Create subscales
    SURPS_Impulsivity = surps2 + surps5 + surps11 + surps15 + surps22,
    SURPS_Sensation_Seeking = surps3 + surps6 + surps9 + surps12 + surps16 + surps19,
    SURPS_Hopelessness = surps1_rev + surps4_rev + surps7_rev + surps13_rev + 
                         surps17 + surps20_rev + surps23_rev,
    SURPS_Anxiety_Sensitivity = surps8 + surps10 + surps14 + surps18 + surps21
  )

# ===== DBAS SUBSCALE SCORES =====
cat("Creating DBAS subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    # Using rowMeans for averaging (0-10 scale, no reverse coding)
    DBAS_Expectations = (dbas1 + dbas_2) / 2,
    DBAS_Medications = (dbas_6 + dbas_13 + dbas_15) / 3,
    DBAS_Worry_Helplessness = (dbas_3 + dbas_4 + dbas_8 + dbas_10 + dbas_11 + dbas_14) / 6,
    DBAS_Consequences = (dbas_5 + dbas_7 + dbas_9 + dbas_12 + dbas_16) / 5,
    
    # Total DBAS score
    dbas_score = DBAS_Expectations + DBAS_Medications + 
                 DBAS_Worry_Helplessness + DBAS_Consequences
  )

# ===== CISS SUBSCALE SCORES =====
cat("Creating CISS subscales...\n")

imputed_long <- imputed_long %>%
  mutate(
    CISS_Avoidance_Style = ciss1 + ciss4 + ciss7 + ciss9 + ciss15 + ciss18 + ciss21,
    CISS_Task_Style = ciss2 + ciss6 + ciss8 + ciss11 + ciss13 + ciss16 + ciss19,
    CISS_Emotional_Style = ciss3 + ciss5 + ciss10 + ciss12 + ciss14 + ciss17 + ciss20
  )

# ===== CONVERT BACK TO MIDS OBJECT =====
cat("Converting back to mids object...\n")

final_imp <- as.mids(imputed_long)

# ===== VERIFICATION =====
cat("\n=== SUBSCALE VERIFICATION ===\n")

# Check one imputed dataset
check_data <- complete(final_imp, 1)

cat("\nBFI-10 Subscales:\n")
print(summary(check_data[, c("Extraversion", "Agreeableness", "Conscientiousness", 
                              "Neuroticism", "Openness")]))

cat("\nSURPS Subscales:\n")
print(summary(check_data[, c("SURPS_Impulsivity", "SURPS_Sensation_Seeking", 
                              "SURPS_Hopelessness", "SURPS_Anxiety_Sensitivity")]))

cat("\nDBAS Subscales:\n")
print(summary(check_data[, c("DBAS_Expectations", "DBAS_Medications", 
                              "DBAS_Worry_Helplessness", "DBAS_Consequences", 
                              "dbas_score")]))

cat("\nCISS Subscales:\n")
print(summary(check_data[, c("CISS_Avoidance_Style", "CISS_Task_Style", 
                              "CISS_Emotional_Style")]))

# ===== SAVE UPDATED IMPUTATION OBJECT =====
saveRDS(final_imp, "final_imputation_with_subscales.rds")
cat("\nSaved: final_imputation_with_subscales.rds\n")

# Save first imputed dataset with subscales
write.csv(check_data, "imputed_dataset_1_with_subscales.csv", row.names = FALSE)
cat("Saved: imputed_dataset_1_with_subscales.csv\n")

# ===== NOW YOU CAN CREATE DIAGNOSTIC PLOTS =====
cat("\n=== CREATING DIAGNOSTIC PLOTS WITH SUBSCALES ===\n")

# Density plots for subscale scores
png("FULL_IMP_DENS_SUBSCALES.png", width = 1600, height = 1200, res = 120)
densityplot(final_imp, ~ DBAS_Expectations + SURPS_Impulsivity + 
            CISS_Avoidance_Style + Extraversion)
dev.off()
cat("Saved: FULL_IMP_DENS_SUBSCALES.png\n")

# Strip plot for subscales
png("FULL_IMP_STRIP_SUBSCALES.png", width = 1600, height = 1200, res = 120)
stripplot(final_imp, DBAS_Expectations + SURPS_Impulsivity + 
          CISS_Avoidance_Style + Neuroticism ~ .imp, 
          pch = 20, cex = 0.8)
dev.off()
cat("Saved: FULL_IMP_STRIP_SUBSCALES.png\n")

cat("\n=== COMPLETE ===\n")
cat("You can now use subscales in your analyses:\n")
cat("fit <- with(final_imp, lm(outcome ~ DBAS_Expectations + SURPS_Impulsivity))\n")
cat("summary(pool(fit))\n")
```


## Descriptive Stats

```{r}
#| label: Descriptive Statistics

library(mice)
library(dplyr)
library(tidyr)

cat("\n=== DESCRIPTIVE STATISTICS FOR IMPUTED DATA ===\n")

# Load the imputation object with subscales
final_imp <- readRDS("final_imputation_with_subscales.rds")

# ===== ADD VARIABLES FROM SIMOA =====
cat("Adding variables from SIMOA dataset...\n")

# Get all imputed datasets in long format
imputed_long <- complete(final_imp, "long", include = TRUE)

# Check if SIMOA exists
if (exists("SIMOA")) {
  # Add scrn_stopped_bzra
  if ("scrn_stopped_bzra" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(scrn_stopped_bzra = SIMOA$scrn_stopped_bzra) %>%
      ungroup()
    cat("  - Added scrn_stopped_bzra\n")
  }
  
  # Add alc_use_men
  if ("alc_use_men" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(alc_use_men = SIMOA$alc_use_men) %>%
      ungroup()
    cat("  - Added alc_use_men\n")
  }
  
  # Add alc_use_wmn
  if ("alc_use_wmn" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(alc_use_wmn = SIMOA$alc_use_wmn) %>%
      ungroup()
    cat("  - Added alc_use_wmn\n")
  }
  
  # Convert back to mids object
  final_imp <- as.mids(imputed_long)
  cat("Successfully updated imputation object\n\n")
} else {
  cat("Warning: SIMOA dataset not found in environment\n\n")
}

# ===== DEFINE ALL VARIABLES =====

continuous_vars <- c(
  "age", "med_quant", "osss_3_score", "phq2_score"
)

subscale_vars <- c(
  "Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
  "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
  "SURPS_Anxiety_Sensitivity",
  "DBAS_Expectations", "DBAS_Medications", "DBAS_Worry_Helplessness", 
  "DBAS_Consequences", "dbas_score",
  "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style"
)

binary_vars <- c("sex", "scrn_stopped_bzra")

unordered_categorical <- c("prov_terr", "gender")

ordered_vars <- c(
  "education", "income", "driving_freq", "employment",
  "side_effects_1", "side_effects_2", "side_effects_3", "side_effects_4",
  "safety_1", "safety_2", "safety_3", "safety_4",
  "adls_1", "adls_2",
  "dependence_1", "dependence_2", "dependence_3",
  "med_burden_1", "med_burden2", "medburden_3", "med_burden_4",
  "op_use", "can_use", "caf_use", "nico_use", 
  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
  "quet_use", "traz_use", "otc_use", "alc_use_men", "alc_use_wmn"
)

# ===== FUNCTIONS FOR POOLING STATISTICS =====

pool_descriptives <- function(mids_obj, vars) {
  results <- data.frame(
    Variable = character(),
    M = numeric(),
    SD = numeric(),
    stringsAsFactors = FALSE
  )
  
  for (var in vars) {
    # Check if variable exists
    if (!var %in% names(complete(mids_obj, 1))) {
      cat(paste0("Warning: Variable '", var, "' not found. Skipping.\n"))
      next
    }
    
    # Extract variable across all imputations
    means <- sapply(1:mids_obj$m, function(i) {
      data <- complete(mids_obj, i)
      mean(data[[var]], na.rm = TRUE)
    })
    
    sds <- sapply(1:mids_obj$m, function(i) {
      data <- complete(mids_obj, i)
      sd(data[[var]], na.rm = TRUE)
    })
    
    # Pool using Rubin's rules
    pooled_mean <- mean(means)
    pooled_sd <- sqrt(mean(sds^2))
    
    results <- rbind(results, data.frame(
      Variable = var,
      M = round(pooled_mean, 2),
      SD = round(pooled_sd, 2)
    ))
  }
  
  return(results)
}

pool_frequencies <- function(mids_obj, vars) {
  results <- list()
  
  for (var in vars) {
    # Check if variable exists
    if (!var %in% names(complete(mids_obj, 1))) {
      cat(paste0("Warning: Variable '", var, "' not found. Skipping.\n"))
      next
    }
    
    data <- complete(mids_obj, 1)
    
    freq_table <- table(data[[var]], useNA = "no")
    pct_table <- prop.table(freq_table) * 100
    
    results[[var]] <- data.frame(
      Variable = var,
      Category = names(freq_table),
      N = as.numeric(freq_table),
      Percentage = round(as.numeric(pct_table), 1)
    )
  }
  
  return(results)
}

# ===== CONTINUOUS VARIABLES =====

cat("\n=== CONTINUOUS VARIABLES (M and SD) ===\n\n")

cat("Demographics & Scale Scores:\n")
continuous_stats <- pool_descriptives(final_imp, continuous_vars)
print(continuous_stats, row.names = FALSE)

cat("\n\nSubscale Scores:\n")
subscale_stats <- pool_descriptives(final_imp, subscale_vars)
print(subscale_stats, row.names = FALSE)

# ===== BINARY VARIABLES =====

cat("\n\n=== BINARY VARIABLES (N and %) ===\n\n")

binary_stats <- pool_frequencies(final_imp, binary_vars)

for (var in names(binary_stats)) {
  print(binary_stats[[var]], row.names = FALSE)
  cat("\n")
}

# ===== UNORDERED CATEGORICAL VARIABLES =====

cat("\n=== UNORDERED CATEGORICAL VARIABLES (N and %) ===\n\n")

unordered_stats <- pool_frequencies(final_imp, unordered_categorical)

for (var in names(unordered_stats)) {
  print(unordered_stats[[var]], row.names = FALSE)
  cat("\n")
}

# ===== ORDERED CATEGORICAL VARIABLES =====

cat("\n=== ORDERED CATEGORICAL VARIABLES (N and %) ===\n\n")

ordered_stats <- pool_frequencies(final_imp, ordered_vars)

for (var in names(ordered_stats)) {
  print(ordered_stats[[var]], row.names = FALSE)
  cat("\n")
}

# ===== CREATE MANUSCRIPT-READY FORMATTED TABLES =====

cat("\n\n=== FORMATTED TABLES FOR MANUSCRIPT ===\n\n")

# Combine all continuous variables
all_continuous <- rbind(
  continuous_stats,
  subscale_stats
)

# Continuous variables with M (SD) format
cat("CONTINUOUS VARIABLES:\n")
formatted_continuous <- all_continuous %>%
  mutate(`M (SD)` = paste0(M, " (", SD, ")")) %>%
  select(Variable, `M (SD)`)
print(formatted_continuous, row.names = FALSE)

# Combine all categorical variables
all_categorical_list <- c(binary_stats, unordered_stats, ordered_stats)
cat_combined <- bind_rows(all_categorical_list, .id = "Variable")

# Categorical variables with N (%) format
cat("\n\nCATEGORICAL VARIABLES:\n")
formatted_categorical <- cat_combined %>%
  mutate(`N (%)` = paste0(N, " (", Percentage, "%)")) %>%
  select(Variable, Category, `N (%)`)
print(formatted_categorical, row.names = FALSE)

# ===== SUMMARY STATISTICS =====

cat("\n\n=== SUMMARY ===\n")
cat(paste0("Total continuous variables: ", nrow(all_continuous), "\n"))
cat(paste0("Total categorical variables: ", length(all_categorical_list), "\n"))
cat(paste0("  - Binary: ", length(binary_stats), "\n"))
cat(paste0("  - Unordered: ", length(unordered_stats), "\n"))
cat(paste0("  - Ordered: ", length(ordered_stats), "\n"))

cat("\n=== COMPLETE ===\n")
```


## DS by BZRA STATUS

```{r}
#| label: Descriptive Statistics by BZRA Status

library(mice)
library(dplyr)
library(tidyr)

cat("\n=== DESCRIPTIVE STATISTICS BY BZRA STATUS ===\n")

final_imp <- readRDS("final_imputation_with_subscales.rds")

# ===== ADD AND RECODE VARIABLES FROM SIMOA =====
cat("Adding and recoding variables from SIMOA...\n")

imputed_long <- complete(final_imp, "long", include = TRUE)

if (exists("SIMOA")) {
  SIMOA <- SIMOA %>%
    mutate(
      region = case_when(
        prov_terr %in% c(1, 2, 3, 12) ~ "Prairies",
        prov_terr %in% c(9, 11) ~ "Central Canada",
        prov_terr %in% c(4, 5, 7, 10) ~ "Atlantic",
        TRUE ~ "Territories"
      ),
      education_grouped = case_when(
        education %in% c(1, 2, 3) ~ "High School or Less",
        education %in% c(4, 5) ~ "University/Trade School",
        TRUE ~ NA_character_
      ),
      employment_grouped = case_when(
        employment %in% c(0, 3, 4) ~ "Not in Workforce",
        employment %in% c(1, 2) ~ "Full- or Part-Time Work",
        TRUE ~ NA_character_
      )
    )
  
  for (new_var in c("scrn_stopped_bzra", "alc_use_men", "alc_use_wmn", 
                     "region", "education_grouped", "employment_grouped")) {
    if (new_var %in% names(SIMOA)) {
      imputed_long <- imputed_long %>%
        group_by(.imp) %>%
        mutate(!!new_var := SIMOA[[new_var]]) %>%
        ungroup()
    }
  }
  
  final_imp <- as.mids(imputed_long)
  cat("Successfully added and recoded variables\n\n")
}

# ===== DEFINE VARIABLES =====
continuous_vars <- c("age", "med_quant", "osss_3_score", "phq2_score")
subscale_vars <- c("Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
                   "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
                   "SURPS_Anxiety_Sensitivity", "DBAS_Expectations", "DBAS_Medications", 
                   "DBAS_Worry_Helplessness", "DBAS_Consequences", "dbas_score",
                   "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style")
binary_vars <- c("sex")
unordered_categorical <- c("gender", "region", "education_grouped", "employment_grouped")
ordered_vars <- c("income", "driving_freq", "side_effects_1", "side_effects_2", 
                  "side_effects_3", "side_effects_4", "safety_1", "safety_2", "safety_3", 
                  "safety_4", "adls_1", "adls_2", "dependence_1", "dependence_2", 
                  "dependence_3", "med_burden_1", "med_burden2", "medburden_3", 
                  "med_burden_4", "op_use", "can_use", "caf_use", "nico_use", 
                  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
                  "quet_use", "traz_use", "otc_use", "alc_use_men", "alc_use_wmn")

# ===== POOLING FUNCTIONS =====
pool_desc_by_group <- function(mids_obj, vars, group_var, group_value) {
  do.call(rbind, lapply(vars, function(var) {
    if (!var %in% names(complete(mids_obj, 1))) return(NULL)
    means <- sapply(1:mids_obj$m, function(i) {
      mean(complete(mids_obj, i)[complete(mids_obj, i)[[group_var]] == group_value, var], na.rm = TRUE)
    })
    sds <- sapply(1:mids_obj$m, function(i) {
      sd(complete(mids_obj, i)[complete(mids_obj, i)[[group_var]] == group_value, var], na.rm = TRUE)
    })
    data.frame(Variable = var, M = round(mean(means), 2), SD = round(sqrt(mean(sds^2)), 2))
  }))
}

pool_freq_by_group <- function(mids_obj, vars, group_var, group_value) {
  setNames(lapply(vars, function(var) {
    if (!var %in% names(complete(mids_obj, 1))) return(NULL)
    group_data <- complete(mids_obj, 1)[complete(mids_obj, 1)[[group_var]] == group_value, ]
    freq <- table(group_data[[var]], useNA = "no")
    pct <- round(prop.table(freq) * 100, 1)
    data.frame(Variable = var, 
               Category = names(freq), 
               N = as.numeric(freq), 
               Pct = as.numeric(pct), 
               stringsAsFactors = FALSE)
  }), vars)
}

pool_t_test <- function(mids_obj, var, group_var) {
  t_res <- lapply(1:mids_obj$m, function(i) {
    data <- complete(mids_obj, i)
    g1 <- data[data[[group_var]] == 1, var]
    g0 <- data[data[[group_var]] == 0, var]
    
    # Remove NAs
    g1 <- g1[!is.na(g1)]
    g0 <- g0[!is.na(g0)]
    
    if(length(g1) > 1 && length(g0) > 1 && sd(g1) > 0 && sd(g0) > 0) {
      t_test <- t.test(g1, g0, var.equal = FALSE)
      list(
        mean_diff = mean(g1) - mean(g0),
        se = t_test$stderr,
        df = t_test$parameter,
        ci_lower = t_test$conf.int[1],
        ci_upper = t_test$conf.int[2]
      )
    } else {
      NULL
    }
  })
  
  # Remove NULL results
  t_res <- t_res[!sapply(t_res, is.null)]
  
  if(length(t_res) == 0) {
    return(list(mean_diff = NA, ci_lower = NA, ci_upper = NA, p_value = NA))
  }
  
  mean_diffs <- sapply(t_res, function(x) x$mean_diff)
  ses <- sapply(t_res, function(x) x$se)
  
  pooled_md <- mean(mean_diffs)
  within_var <- mean(ses^2)
  between_var <- var(mean_diffs)
  
  # Handle case where between_var is 0 or very small
  if(is.na(between_var) || between_var < 1e-10) {
    between_var <- 0
  }
  
  total_var <- within_var + between_var + between_var/length(t_res)
  pooled_se <- sqrt(total_var)
  
  # Calculate degrees of freedom
  if(between_var > 1e-10) {
    lambda <- (between_var + between_var/length(t_res)) / total_var
    df_old <- (length(t_res) - 1) / lambda^2
    df_obs <- mean(sapply(t_res, function(x) x$df))
    df_adj <- (df_obs + 1) / (df_obs + 3) * df_obs * (1 - lambda)
    pooled_df <- df_old * df_adj / (df_old + df_adj)
  } else {
    # If no between-imputation variance, use average df from t-tests
    pooled_df <- mean(sapply(t_res, function(x) x$df))
  }
  
  t_stat <- pooled_md / pooled_se
  p_value <- 2 * pt(-abs(t_stat), df = pooled_df)
  
  t_crit <- qt(0.975, df = pooled_df)
  ci_lower <- pooled_md - t_crit * pooled_se
  ci_upper <- pooled_md + t_crit * pooled_se
  
  list(mean_diff = pooled_md, ci_lower = ci_lower, ci_upper = ci_upper, p_value = p_value)
}

calc_cohens_d <- function(mids_obj, var, group_var) {
  mean(sapply(1:mids_obj$m, function(i) {
    data <- complete(mids_obj, i)
    g1 <- data[data[[group_var]] == 1, var]
    g0 <- data[data[[group_var]] == 0, var]
    (mean(g1, na.rm = TRUE) - mean(g0, na.rm = TRUE)) / 
      sqrt(((length(g1) - 1) * var(g1, na.rm = TRUE) + (length(g0) - 1) * var(g0, na.rm = TRUE)) / 
           (length(g1) + length(g0) - 2))
  }))
}

calc_cramers_v <- function(mids_obj, var, group_var) {
  data <- complete(mids_obj, 1)
  chi <- chisq.test(table(data[[group_var]], data[[var]]))
  list(cramers_v = as.numeric(sqrt(chi$statistic / (sum(table(data[[group_var]], data[[var]])) * 
       (min(dim(table(data[[group_var]], data[[var]]))) - 1)))), p_value = chi$p.value)
}

# ===== SAMPLE SIZES =====
first_imp <- complete(final_imp, 1)
n_yes <- sum(first_imp$scrn_stopped_bzra == 1, na.rm = TRUE)
n_no <- sum(first_imp$scrn_stopped_bzra == 0, na.rm = TRUE)

cat("\n=== SAMPLE SIZES ===\n")
cat("No Longer Taking BZRA (Yes = 1):", n_yes, "\n")
cat("Still Using BZRA (No = 0):", n_no, "\n")
cat("Total:", n_yes + n_no, "\n\n")

# ===== CALCULATE STATISTICS FOR BOTH GROUPS =====
cat("Calculating descriptive statistics...\n")

all_cont_vars <- c(continuous_vars, subscale_vars)
all_cat_vars <- c(binary_vars, unordered_categorical, ordered_vars)

cont_yes <- pool_desc_by_group(final_imp, all_cont_vars, "scrn_stopped_bzra", 1)
cont_no <- pool_desc_by_group(final_imp, all_cont_vars, "scrn_stopped_bzra", 0)

cat_yes <- pool_freq_by_group(final_imp, all_cat_vars, "scrn_stopped_bzra", 1)
cat_no <- pool_freq_by_group(final_imp, all_cat_vars, "scrn_stopped_bzra", 0)

# ===== CONTINUOUS VARIABLES COMPARISON =====
cat("\n========================================\n")
cat("CONTINUOUS VARIABLES COMPARISON\n")
cat("========================================\n\n")

effect_cont <- do.call(rbind, lapply(all_cont_vars, function(var) {
  if (var %in% names(complete(final_imp, 1))) {
    t_res <- pool_t_test(final_imp, var, "scrn_stopped_bzra")
    data.frame(Variable = var, Mean_Diff = round(t_res$mean_diff, 2),
               CI_Lower = round(t_res$ci_lower, 2), CI_Upper = round(t_res$ci_upper, 2),
               Cohens_d = round(calc_cohens_d(final_imp, var, "scrn_stopped_bzra"), 2),
               p_value = round(t_res$p_value, 4))
  }
}))

comparison_cont <- cont_yes %>%
  mutate(`No Longer Taking M (SD)` = paste0(M, " (", SD, ")")) %>%
  select(Variable, `No Longer Taking M (SD)`) %>%
  left_join(cont_no %>% mutate(`Still Using M (SD)` = paste0(M, " (", SD, ")")) %>%
            select(Variable, `Still Using M (SD)`), by = "Variable") %>%
  left_join(effect_cont, by = "Variable") %>%
  mutate(`Mean Diff [95% CI]` = paste0(Mean_Diff, " [", CI_Lower, ", ", CI_Upper, "]"),
         p = ifelse(p_value < 0.001, "<.001", as.character(p_value))) %>%
  select(Variable, `No Longer Taking M (SD)`, `Still Using M (SD)`, 
         `Mean Diff [95% CI]`, Cohens_d, p)

print(comparison_cont, row.names = FALSE)

# ===== CATEGORICAL VARIABLES COMPARISON =====
cat("\n========================================\n")
cat("CATEGORICAL VARIABLES COMPARISON\n")
cat("========================================\n\n")

effect_cat <- do.call(rbind, lapply(all_cat_vars, function(var) {
  if (var %in% names(complete(final_imp, 1))) {
    tryCatch({
      cv <- calc_cramers_v(final_imp, var, "scrn_stopped_bzra")
      data.frame(Variable = var, Cramers_V = round(cv$cramers_v, 3), 
                 p_value = round(cv$p_value, 4))
    }, error = function(e) NULL)
  }
}))

for (var in all_cat_vars) {
  if (var %in% names(cat_yes) && var %in% names(cat_no) && 
      !is.null(cat_yes[[var]]) && !is.null(cat_no[[var]])) {
    cat(paste0("\n", var, ":\n"))
    
    if (var %in% effect_cat$Variable) {
      eff <- effect_cat[effect_cat$Variable == var, ]
      cat(paste0("  Cramers V = ", eff$Cramers_V, ", p ", 
                 ifelse(eff$p_value < 0.001, "< .001", paste0("= ", eff$p_value)), "\n\n"))
    }
    
    # Fix: Add Variable column to the table
    yes_data <- cat_yes[[var]]
    yes_data$Variable <- var
    yes_data$`No Longer Taking N (%)` <- paste0(yes_data$N, " (", yes_data$Pct, "%)")
    yes_data <- yes_data[, c("Variable", "Category", "No Longer Taking N (%)")]
    
    no_data <- cat_no[[var]]
    no_data$`Still Using N (%)` <- paste0(no_data$N, " (", no_data$Pct, "%)")
    no_data <- no_data[, c("Category", "Still Using N (%)")]
    
    comp <- full_join(yes_data, no_data, by = "Category")
    
    print(comp, row.names = FALSE)
    cat("\n")
  }
}

cat("\n=== COMPLETE ===\n")
```

## Random Forest Model

```{r}
#| label: Complete Random Forest Analysis - Updated Variable Names

library(mice)
library(dplyr)
library(randomForest)
library(ggplot2)
library(caret)
library(pROC)
library(gridExtra)
library(viridis)

cat("\n=== COMPLETE RANDOM FOREST ANALYSIS ===\n")

# ===== LOAD DATA AND PREPARE VARIABLES =====
cat("Loading imputed data...\n")
final_imp <- readRDS("final_imputation_with_subscales.rds")

cat("Adding and recoding variables from SIMOA...\n")

imputed_long <- complete(final_imp, "long", include = TRUE)

if (exists("SIMOA")) {
  SIMOA <- SIMOA %>%
    mutate(
      region = case_when(
        prov_terr %in% c(1, 2, 3, 12) ~ "Prairies",
        prov_terr %in% c(9, 11) ~ "Central Canada",
        prov_terr %in% c(4, 5, 7, 10) ~ "Atlantic",
        TRUE ~ "Territories"
      ),
      education_grouped = case_when(
        education %in% c(1, 2, 3) ~ "High School or Less",
        education %in% c(4, 5) ~ "University/Trade School",
        TRUE ~ NA_character_
      ),
      employment_grouped = case_when(
        employment %in% c(0, 3, 4) ~ "Not in Workforce",
        employment %in% c(1, 2) ~ "Full- or Part-Time Work",
        TRUE ~ NA_character_
      )
    )
  
  for (new_var in c("scrn_stopped_bzra", "alc_use_men", "alc_use_wmn", 
                     "region", "education_grouped", "employment_grouped")) {
    if (new_var %in% names(SIMOA)) {
      imputed_long <- imputed_long %>%
        group_by(.imp) %>%
        mutate(!!new_var := SIMOA[[new_var]]) %>%
        ungroup()
    }
  }
  
  final_imp <- as.mids(imputed_long)
  cat("Successfully added and recoded variables\n\n")
} else {
  stop("SIMOA dataset not found. Please load it first.")
}

# ===== DEFINE VARIABLES (FROM DESCRIPTIVE STATS) =====
continuous_vars <- c("age", "med_quant", "osss_3_score", "phq2_score")

subscale_vars <- c("Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
                   "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
                   "SURPS_Anxiety_Sensitivity", "DBAS_Expectations", "DBAS_Medications", 
                   "DBAS_Worry_Helplessness", "DBAS_Consequences", "dbas_score",
                   "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style")

binary_vars <- c("sex")

unordered_categorical <- c("gender", "region", "education_grouped", "employment_grouped")

ordered_vars <- c("income", "driving_freq", "side_effects_1", "side_effects_2", 
                  "side_effects_3", "side_effects_4", "safety_1", "safety_2", "safety_3", 
                  "safety_4", "adls_1", "adls_2", "dependence_1", "dependence_2", 
                  "dependence_3", "med_burden_1", "med_burden2", "medburden_3", 
                  "med_burden_4", "op_use", "can_use", "caf_use", "nico_use", 
                  "alc_sleep", "can_sleep", "melatonin_use", "op_sleep", 
                  "quet_use", "traz_use", "otc_use")

# Note: alc_use_men and alc_use_wmn are sex-specific and will be combined

predictor_vars <- c(continuous_vars, subscale_vars, binary_vars, 
                    unordered_categorical, ordered_vars)

# Check which variables actually exist in the data
temp_data <- complete(final_imp, 1)
missing_vars <- predictor_vars[!predictor_vars %in% names(temp_data)]
available_vars <- predictor_vars[predictor_vars %in% names(temp_data)]

if (length(missing_vars) > 0) {
  cat("\n⚠ Warning: The following variables are not in the dataset:\n")
  cat(paste("  -", missing_vars, collapse = "\n"), "\n\n")
}

predictor_vars <- available_vars

cat("✓ Variables defined\n")
cat("  Total predictors available:", length(predictor_vars), "\n")
cat("  Variables excluded:", length(missing_vars), "\n\n")

# Diagnostic: Check missing data patterns
cat("Checking data completeness...\n")
temp_check <- complete(final_imp, 1) %>%
  select(all_of(c("scrn_stopped_bzra", predictor_vars)))

cat("  Total rows in dataset:", nrow(temp_check), "\n")
cat("  Rows with scrn_stopped_bzra:", sum(!is.na(temp_check$scrn_stopped_bzra)), "\n")

# Check missingness by variable
miss_count <- colSums(is.na(temp_check))
if (any(miss_count > 0)) {
  cat("\n  Variables with missing data:\n")
  miss_vars <- miss_count[miss_count > 0]
  for (v in names(miss_vars)) {
    cat(sprintf("    %s: %d missing (%.1f%%)\n", 
                v, miss_vars[v], 100 * miss_vars[v] / nrow(temp_check)))
  }
}

cat("\n  Complete cases after na.omit():", sum(complete.cases(temp_check)), "\n\n")

# ===== CHECK FOR EXISTING RESULTS =====
if (file.exists("random_forest_results.rds")) {
  cat("✓ Found existing results. Loading...\n")
  results <- readRDS("random_forest_results.rds")
  rf_models <- results$models_full
  optimal_split <- results$optimal_split
  pooled_importance <- results$pooled_importance
  run_full_analysis <- FALSE
} else {
  cat("⚠ No existing results found. Running full analysis...\n\n")
  run_full_analysis <- TRUE
}

# ===== PREPARE OUTCOME VARIABLE =====
imputed_long <- complete(final_imp, "long", include = TRUE)

# Create combined alcohol use variable (sex-agnostic)
if ("alc_use_men" %in% names(imputed_long) && "alc_use_wmn" %in% names(imputed_long)) {
  imputed_long <- imputed_long %>%
    mutate(alc_use_combined = coalesce(alc_use_men, alc_use_wmn))
  cat("✓ Created combined alcohol use variable\n")
  
  # Add to predictor list
  predictor_vars <- c(predictor_vars, "alc_use_combined")
}

imputed_long$scrn_stopped_bzra <- factor(imputed_long$scrn_stopped_bzra, 
                                         levels = c(0, 1), 
                                         labels = c("Still_Using", "No_Longer_Taking"))

# Convert categorical variables to factors
for (var in c(binary_vars, unordered_categorical, ordered_vars)) {
  if (var %in% names(imputed_long)) {
    imputed_long[[var]] <- as.factor(imputed_long[[var]])
  }
}

final_imp <- as.mids(imputed_long)

# ===== IF NEEDED: RUN FULL RANDOM FOREST ANALYSIS =====
if (run_full_analysis) {
  cat("\n========================================\n")
  cat("STEP 1: FINDING OPTIMAL TRAIN/TEST SPLIT\n")
  cat("========================================\n\n")
  
  split_ratios <- c(0.7, 0.75, 0.8)
  split_results <- list()
  
  # Check overall class distribution first
  temp_data <- complete(final_imp, 1) %>%
    select(all_of(c("scrn_stopped_bzra", predictor_vars))) %>%
    na.omit()
  
  cat("Overall class distribution:\n")
  print(table(temp_data$scrn_stopped_bzra))
  cat("\n")
  
  for (ratio in split_ratios) {
    cat("Testing", ratio*100, "/", (1-ratio)*100, "split...\n")
    temp_aucs <- numeric(final_imp$m)
    
    for (i in 1:final_imp$m) {
      data_imp <- complete(final_imp, i) %>%
        select(all_of(c("scrn_stopped_bzra", predictor_vars))) %>%
        na.omit()
      
      # Check if we have enough data
      if (nrow(data_imp) < 10) {
        cat("  ⚠ Warning: Only", nrow(data_imp), "complete cases in imputation", i, "\n")
        next
      }
      
      # Check class balance
      class_counts <- table(data_imp$scrn_stopped_bzra)
      if (min(class_counts) < 5) {
        cat("  ⚠ Warning: Insufficient samples in minority class for imputation", i, "\n")
        next
      }
      
      set.seed(123 + i)
      train_idx <- createDataPartition(data_imp$scrn_stopped_bzra, p = ratio, list = FALSE)
      train_data <- data_imp[train_idx, ]
      
      # Use balanced sampling: both classes get minority class size
      minority_n <- min(sum(train_data$scrn_stopped_bzra == "Still_Using"),
                       sum(train_data$scrn_stopped_bzra == "No_Longer_Taking"))
      
      temp_rf <- randomForest(
        scrn_stopped_bzra ~ .,
        data = train_data,
        ntree = 100,
        sampsize = c(minority_n, minority_n)
      )
      
      test_data <- data_imp[-train_idx, ]
      pred_prob <- predict(temp_rf, test_data, type = "prob")[, "No_Longer_Taking"]
      temp_aucs[i] <- auc(roc(test_data$scrn_stopped_bzra, pred_prob, quiet = TRUE))
    }
    
    split_results[[as.character(ratio)]] <- mean(temp_aucs)
    cat("  Mean AUC:", round(mean(temp_aucs), 4), "\n")
  }
  
  optimal_split <- as.numeric(names(which.max(split_results)))
  cat("\n✓ Optimal split:", optimal_split*100, "/", (1-optimal_split)*100, "\n")
  
  cat("\n========================================\n")
  cat("STEP 2: FITTING RANDOM FOREST MODELS\n")
  cat("========================================\n\n")
  
  rf_models <- list()
  rf_importance <- list()
  
  for (i in 1:final_imp$m) {
    cat("  Fitting model for imputation", i, "of", final_imp$m, "...\n")
    
    data_imp <- complete(final_imp, i) %>%
      select(all_of(c("scrn_stopped_bzra", predictor_vars))) %>%
      na.omit()
    
    cat("    Complete cases:", nrow(data_imp), "\n")
    
    set.seed(123 + i)
    train_idx <- createDataPartition(data_imp$scrn_stopped_bzra, p = optimal_split, list = FALSE)
    train_data <- data_imp[train_idx, ]
    
    minority_n <- sum(train_data$scrn_stopped_bzra == "No_Longer_Taking")
    
    rf_models[[i]] <- randomForest(
      scrn_stopped_bzra ~ .,
      data = train_data,
      ntree = 500,
      mtry = floor(sqrt(length(predictor_vars))),
      importance = TRUE,
      sampsize = c(minority_n, minority_n),
      replace = TRUE
    )
    
    rf_importance[[i]] <- importance(rf_models[[i]])
  }
  
  cat("\n✓ All models fitted!\n")
  
  # Pool importance
  mda_list <- lapply(rf_importance, function(x) x[, "MeanDecreaseAccuracy"])
  mdg_list <- lapply(rf_importance, function(x) x[, "MeanDecreaseGini"])
  
  pooled_importance <- data.frame(
    Variable = rownames(rf_importance[[1]]),
    MeanDecreaseAccuracy = rowMeans(do.call(cbind, mda_list)),
    MeanDecreaseGini = rowMeans(do.call(cbind, mdg_list)),
    SD_MDA = apply(do.call(cbind, mda_list), 1, sd),
    stringsAsFactors = FALSE
  ) %>%
    arrange(desc(MeanDecreaseAccuracy))
  
  # Save basic results
  results <- list(
    models_full = rf_models,
    pooled_importance = pooled_importance,
    optimal_split = optimal_split
  )
  
  saveRDS(results, "random_forest_results.rds")
  cat("\n✓ Basic results saved\n")
}

cat("\n========================================\n")
cat("ENHANCED ANALYSIS: VARIABLE STABILITY\n")
cat("========================================\n\n")

# Extract importance from all models
all_importance <- lapply(rf_models, function(model) {
  imp <- importance(model)
  data.frame(
    Variable = rownames(imp),
    MDA = imp[, "MeanDecreaseAccuracy"],
    MDG = imp[, "MeanDecreaseGini"],
    stringsAsFactors = FALSE
  )
})

# Calculate ranks
importance_ranks <- lapply(all_importance, function(df) {
  df %>%
    arrange(desc(MDA)) %>%
    mutate(Rank = row_number()) %>%
    select(Variable, Rank)
})

# Merge ranks
rank_matrix <- importance_ranks[[1]]
for (i in 2:length(importance_ranks)) {
  rank_matrix <- merge(rank_matrix, importance_ranks[[i]], 
                       by = "Variable", 
                       suffixes = c("", paste0("_", i)))
}

# Stability metrics
rank_cols <- grep("Rank", names(rank_matrix), value = TRUE)
rank_matrix$Mean_Rank <- rowMeans(rank_matrix[, rank_cols])
rank_matrix$SD_Rank <- apply(rank_matrix[, rank_cols], 1, sd)
rank_matrix$CV_Rank <- rank_matrix$SD_Rank / rank_matrix$Mean_Rank

stability_df <- rank_matrix %>%
  select(Variable, Mean_Rank, SD_Rank, CV_Rank) %>%
  arrange(Mean_Rank)

pooled_importance_enhanced <- pooled_importance %>%
  left_join(stability_df, by = "Variable") %>%
  arrange(desc(MeanDecreaseAccuracy))

cat("Top 10 Variables with Stability:\n")
print(head(pooled_importance_enhanced, 10), row.names = FALSE)

cat("\n========================================\n")
cat("ENHANCED ANALYSIS: POOLED PREDICTIONS\n")
cat("========================================\n\n")

# Get predictor names from first model
predictor_names <- names(rf_models[[1]]$forest$xlevels)

pooled_predictions_list <- list()

for (i in 1:final_imp$m) {
  data_imp <- complete(final_imp, i) %>%
    select(all_of(c("scrn_stopped_bzra", predictor_names))) %>%
    na.omit()
  
  set.seed(123 + i)
  train_idx <- createDataPartition(data_imp$scrn_stopped_bzra, p = optimal_split, list = FALSE)
  test_data <- data_imp[-train_idx, ]
  
  pred_prob <- predict(rf_models[[i]], test_data, type = "prob")[, "No_Longer_Taking"]
  
  pooled_predictions_list[[i]] <- data.frame(
    row_id = rownames(test_data),
    prob = pred_prob,
    actual = test_data$scrn_stopped_bzra
  )
}

pooled_df <- bind_rows(pooled_predictions_list, .id = "imputation") %>%
  group_by(row_id) %>%
  summarise(
    pooled_prob = mean(prob),
    actual = first(actual),
    prob_sd = sd(prob),
    .groups = "drop"
  )

cat("✓ Predictions pooled across", final_imp$m, "imputations\n")
cat("  Mean prediction SD:", round(mean(pooled_df$prob_sd, na.rm = TRUE), 4), "\n")

cat("\n========================================\n")
cat("OPTIMAL THRESHOLD SELECTION\n")
cat("========================================\n\n")

roc_pooled <- roc(pooled_df$actual, pooled_df$pooled_prob, quiet = TRUE)

# Youden's J method
coords_all <- coords(roc_pooled, x = "all", ret = "all")
youden_j <- coords_all$sensitivity + coords_all$specificity - 1
youden_idx <- which.max(youden_j)
youden_threshold <- coords_all$threshold[youden_idx]

cat("Optimal Threshold (Youden's J):", round(youden_threshold, 4), "\n")
cat("  Sensitivity:", round(coords_all$sensitivity[youden_idx], 4), "\n")
cat("  Specificity:", round(coords_all$specificity[youden_idx], 4), "\n")
cat("  AUC:", round(auc(roc_pooled), 4), "\n\n")

# Performance with optimal threshold
pooled_df$pred_class_optimal <- ifelse(pooled_df$pooled_prob > youden_threshold,
                                       "No_Longer_Taking", "Still_Using")
pooled_df$pred_class_optimal <- factor(pooled_df$pred_class_optimal, 
                                       levels = levels(pooled_df$actual))

cm_optimal <- confusionMatrix(pooled_df$pred_class_optimal, 
                              pooled_df$actual, 
                              positive = "No_Longer_Taking")

cat("Performance Metrics:\n")
cat("  Accuracy:", round(cm_optimal$overall["Accuracy"], 4), "\n")
cat("  Precision:", round(cm_optimal$byClass["Precision"], 4), "\n")
cat("  F1-Score:", round(cm_optimal$byClass["F1"], 4), "\n")

cat("\n========================================\n")
cat("CREATING VISUALIZATIONS\n")
cat("========================================\n\n")

# 1. Variable Importance with Stability
top15 <- head(pooled_importance_enhanced, 15)

p1 <- ggplot(top15, aes(x = reorder(Variable, MeanDecreaseAccuracy), 
                        y = MeanDecreaseAccuracy,
                        fill = CV_Rank)) +
  geom_col() +
  geom_errorbar(aes(ymin = MeanDecreaseAccuracy - SD_MDA,
                    ymax = MeanDecreaseAccuracy + SD_MDA),
                width = 0.3, alpha = 0.6) +
  scale_fill_viridis(option = "plasma", direction = -1,
                     name = "Rank\nVariability") +
  coord_flip() +
  labs(title = "Top 15 Most Predictive Variables",
       subtitle = "Error bars show SD; darker = more stable",
       x = NULL,
       y = "Mean Decrease in Accuracy") +
  theme_minimal(base_size = 11) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p1)

# 2. ROC Curve
roc_data <- data.frame(
  FPR = 1 - roc_pooled$specificities,
  TPR = roc_pooled$sensitivities
)

p2 <- ggplot(roc_data, aes(x = FPR, y = TPR)) +
  geom_line(color = "steelblue", linewidth = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(aes(x = 1 - coords_all$specificity[youden_idx],
                 y = coords_all$sensitivity[youden_idx]),
             color = "red", size = 4, shape = 18) +
  annotate("text", 
           x = 1 - coords_all$specificity[youden_idx] + 0.15,
           y = coords_all$sensitivity[youden_idx],
           label = paste0("Optimal\n(", round(youden_threshold, 3), ")"),
           color = "red", size = 3.5, fontface = "bold") +
  labs(title = "ROC Curve",
       subtitle = paste0("AUC = ", round(auc(roc_pooled), 3)),
       x = "False Positive Rate",
       y = "True Positive Rate") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p2)

# 3. Prediction Distribution
p3 <- ggplot(pooled_df, aes(x = pooled_prob, fill = actual)) +
  geom_histogram(bins = 30, alpha = 0.7, position = "identity") +
  geom_vline(xintercept = youden_threshold, linetype = "dashed", 
             color = "red", linewidth = 1) +
  scale_fill_manual(values = c("Still_Using" = "coral", 
                               "No_Longer_Taking" = "skyblue"),
                   name = "Actual Status") +
  labs(title = "Distribution of Predicted Probabilities",
       x = "Predicted Probability (No Longer Taking)",
       y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "top")

print(p3)

# 4. Confusion Matrix
cm_df <- as.data.frame(cm_optimal$table)
names(cm_df) <- c("Predicted", "Actual", "Count")

p4 <- ggplot(cm_df, aes(x = Actual, y = Predicted, fill = Count)) +
  geom_tile(color = "white", linewidth = 1) +
  geom_text(aes(label = Count), size = 8, fontface = "bold") +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Confusion Matrix",
       subtitle = paste0("Threshold = ", round(youden_threshold, 3))) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "none")

print(p4)

cat("\n========================================\n")
cat("SAVING RESULTS\n")
cat("========================================\n\n")

enhanced_results <- list(
  pooled_importance_enhanced = pooled_importance_enhanced,
  pooled_predictions = pooled_df,
  optimal_threshold = youden_threshold,
  confusion_matrix = cm_optimal,
  roc_object = roc_pooled,
  models = rf_models,
  optimal_split = optimal_split
)

saveRDS(enhanced_results, "enhanced_random_forest_results.rds")

cat("✓ Results saved to 'enhanced_random_forest_results.rds'\n")
cat("\n=== ANALYSIS COMPLETE ===\n\n")

# Summary
cat("SUMMARY:\n")
cat("  AUC:", round(auc(roc_pooled), 3), "\n")
cat("  Optimal Threshold:", round(youden_threshold, 3), "\n")
cat("  Accuracy:", round(cm_optimal$overall["Accuracy"], 3), "\n")
cat("  Top Predictor:", pooled_importance_enhanced$Variable[1], "\n")
```


## Logistic Regression Confirmation

```{r}
#| label: Logistic Regression Validation of Random Forest Results

library(mice)
library(dplyr)
library(pROC)
library(caret)
library(ggplot2)
library(gridExtra)
library(broom)

cat("\n=== LOGISTIC REGRESSION VALIDATION ===\n\n")

# Load data
cat("Loading imputed data and RF results...\n")
final_imp <- readRDS("final_imputation_with_subscales.rds")
rf_results <- readRDS("enhanced_random_forest_results.rds")
top_predictors <- head(rf_results$pooled_importance_enhanced, 15)$Variable
cat("Top 15 RF predictors identified\n\n")

# Prepare data
cat("Preparing data with outcome variable...\n")
imputed_long <- complete(final_imp, "long", include = TRUE)

if (exists("SIMOA")) {
  if ("scrn_stopped_bzra" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(scrn_stopped_bzra = SIMOA$scrn_stopped_bzra) %>%
      ungroup()
    
    if ("alc_use_men" %in% names(SIMOA) && "alc_use_wmn" %in% names(SIMOA)) {
      imputed_long <- imputed_long %>%
        group_by(.imp) %>%
        mutate(alc_use_men = SIMOA$alc_use_men, alc_use_wmn = SIMOA$alc_use_wmn) %>%
        ungroup() %>%
        mutate(alc_use_combined = coalesce(alc_use_men, alc_use_wmn))
      cat("✓ Created combined alcohol use variable\n")
    }
    
    imputed_long$scrn_stopped_bzra <- factor(imputed_long$scrn_stopped_bzra,
                                            levels = c(0, 1),
                                            labels = c("Still_Using", "No_Longer_Taking"))
    cat("✓ Outcome variable added\n")
    
    test_imp1 <- imputed_long %>% filter(.imp == 1)
    cat("  Class distribution:\n")
    print(table(test_imp1$scrn_stopped_bzra))
    
    missing_predictors <- top_predictors[!top_predictors %in% names(test_imp1)]
    if (length(missing_predictors) > 0) {
      cat("\n⚠ Removing missing predictors:", paste(missing_predictors, collapse = ", "), "\n")
      top_predictors <- top_predictors[top_predictors %in% names(test_imp1)]
    }
    cat("\n")
  }
}

# Pooling function
pool_glm_results <- function(fit_list) {
  coefs <- lapply(fit_list, coef)
  vcovs <- lapply(fit_list, vcov)
  m <- length(fit_list)
  Q_bar <- Reduce("+", coefs) / m
  U_bar <- Reduce("+", vcovs) / m
  B <- Reduce("+", lapply(coefs, function(q) (q - Q_bar) %*% t(q - Q_bar))) / (m - 1)
  T_total <- U_bar + (1 + 1/m) * B
  se <- sqrt(diag(T_total))
  lambda <- (1 + 1/m) * diag(B) / diag(T_total)
  df_old <- (m - 1) / lambda^2
  n_obs <- nrow(fit_list[[1]]$model)
  p <- length(Q_bar)
  df_obs <- n_obs - p
  df <- (df_old * df_obs) / (df_old + df_obs)
  t_stat <- Q_bar / se
  p_values <- 2 * pt(abs(t_stat), df = df, lower.tail = FALSE)
  ci_lower <- Q_bar - qt(0.975, df) * se
  ci_upper <- Q_bar + qt(0.975, df) * se
  data.frame(term = names(Q_bar), estimate = Q_bar, std.error = se,
             statistic = t_stat, p.value = p_values,
             `2.5 %` = ci_lower, `97.5 %` = ci_upper,
             check.names = FALSE, row.names = NULL)
}

# MODEL 1: Top 15
cat("========================================\n")
cat("MODEL 1: TOP 15 RF PREDICTORS\n")
cat("========================================\n\n")
formula_top15 <- as.formula(paste("scrn_stopped_bzra ~", paste(top_predictors, collapse = " + ")))
fit_list_top15 <- list()
for (i in 1:final_imp$m) {
  cat("  Fitting model", i, "...\n")
  data_imp <- imputed_long %>% filter(.imp == i) %>% select(-c(.imp, .id))
  fit_list_top15[[i]] <- glm(formula_top15, data = data_imp, family = binomial())
}
cat("\n✓ Models fitted\n")
pooled_top15 <- pool_glm_results(fit_list_top15)
summary_top15 <- pooled_top15
cat("\nCoefficients:\n")
print(summary_top15, digits = 3)
summary_top15$OR <- exp(summary_top15$estimate)
summary_top15$OR_lower <- exp(summary_top15$`2.5 %`)
summary_top15$OR_upper <- exp(summary_top15$`97.5 %`)
cat("\nOdds Ratios:\n")
print(summary_top15[, c("term", "OR", "OR_lower", "OR_upper", "p.value")], digits = 3, row.names = FALSE)

# MODEL 2: Top 10
cat("\n========================================\n")
cat("MODEL 2: TOP 10 RF PREDICTORS\n")
cat("========================================\n\n")
top10_predictors <- head(rf_results$pooled_importance_enhanced, 10)$Variable
formula_top10 <- as.formula(paste("scrn_stopped_bzra ~", paste(top10_predictors, collapse = " + ")))
fit_list_top10 <- list()
for (i in 1:final_imp$m) {
  data_imp <- imputed_long %>% filter(.imp == i) %>% select(-c(.imp, .id))
  fit_list_top10[[i]] <- glm(formula_top10, data = data_imp, family = binomial())
}
pooled_top10 <- pool_glm_results(fit_list_top10)
summary_top10 <- pooled_top10
cat("Coefficients:\n")
print(summary_top10, digits = 3)

# MODEL 3: Parsimonious
cat("\n========================================\n")
cat("MODEL 3: PARSIMONIOUS (p < 0.10)\n")
cat("========================================\n\n")
sig_predictors <- summary_top15$term[summary_top15$p.value < 0.10 & summary_top15$term != "(Intercept)"]
if (length(sig_predictors) > 0) {
  sig_predictors_clean <- unique(gsub("\\.(L|Q|C|\\^[0-9]+)$", "", sig_predictors))
  cat("Significant predictors:", paste(sig_predictors_clean, collapse = ", "), "\n\n")
  formula_sig <- as.formula(paste("scrn_stopped_bzra ~", paste(sig_predictors_clean, collapse = " + ")))
  fit_list_sig <- list()
  for (i in 1:final_imp$m) {
    data_imp <- imputed_long %>% filter(.imp == i) %>% select(-c(.imp, .id))
    fit_list_sig[[i]] <- glm(formula_sig, data = data_imp, family = binomial())
  }
  pooled_sig <- pool_glm_results(fit_list_sig)
  summary_sig <- pooled_sig
  cat("Coefficients:\n")
  print(summary_sig, digits = 3)
  summary_sig$OR <- exp(summary_sig$estimate)
  summary_sig$OR_lower <- exp(summary_sig$`2.5 %`)
  summary_sig$OR_upper <- exp(summary_sig$`97.5 %`)
  cat("\nOdds Ratios:\n")
  print(summary_sig[, c("term", "OR", "OR_lower", "OR_upper", "p.value")], digits = 3, row.names = FALSE)
} else {
  cat("No predictors significant at p < 0.10\n")
  fit_list_sig <- NULL
}

# Performance evaluation
cat("\n========================================\n")
cat("MODEL PERFORMANCE\n")
cat("========================================\n\n")
evaluate_model <- function(model_fit_list, model_name) {
  results_list <- list()
  for (i in 1:final_imp$m) {
    data_imp <- imputed_long %>% filter(.imp == i) %>% select(-c(.imp, .id)) %>%
      select(scrn_stopped_bzra, all_of(all.vars(model_fit_list[[i]]$formula)[-1])) %>% na.omit()
    set.seed(123 + i)
    train_idx <- createDataPartition(data_imp$scrn_stopped_bzra, p = 0.8, list = FALSE)
    test_data <- data_imp[-train_idx, ]
    pred_prob <- predict(model_fit_list[[i]], newdata = test_data, type = "response")
    roc_obj <- roc(test_data$scrn_stopped_bzra, pred_prob, quiet = TRUE)
    auc_val <- as.numeric(auc(roc_obj))
    coords_all <- coords(roc_obj, x = "all", ret = "all")
    youden_j <- coords_all$sensitivity + coords_all$specificity - 1
    optimal_thresh <- coords_all$threshold[which.max(youden_j)]
    pred_class <- factor(ifelse(pred_prob > optimal_thresh, "No_Longer_Taking", "Still_Using"),
                        levels = levels(test_data$scrn_stopped_bzra))
    cm <- confusionMatrix(pred_class, test_data$scrn_stopped_bzra, positive = "No_Longer_Taking")
    results_list[[i]] <- data.frame(imputation = i, auc = auc_val,
                                    accuracy = cm$overall["Accuracy"],
                                    sensitivity = cm$byClass["Sensitivity"],
                                    specificity = cm$byClass["Specificity"],
                                    precision = cm$byClass["Precision"],
                                    f1 = cm$byClass["F1"])
  }
  results_df <- bind_rows(results_list)
  data.frame(Model = model_name, AUC = mean(results_df$auc), AUC_SD = sd(results_df$auc),
             Accuracy = mean(results_df$accuracy), Sensitivity = mean(results_df$sensitivity),
             Specificity = mean(results_df$specificity),
             Precision = mean(results_df$precision, na.rm = TRUE),
             F1 = mean(results_df$f1, na.rm = TRUE))
}

perf_top15 <- evaluate_model(fit_list_top15, "Top 15")
perf_top10 <- evaluate_model(fit_list_top10, "Top 10")
if (!is.null(fit_list_sig)) {
  perf_sig <- evaluate_model(fit_list_sig, "Parsimonious")
  performance_comparison <- bind_rows(perf_top15, perf_top10, perf_sig)
} else {
  performance_comparison <- bind_rows(perf_top15, perf_top10)
}

cat("Performance Metrics:\n")
print(performance_comparison, digits = 3, row.names = FALSE)
cat("\nRF Performance:\n")
cat("  AUC:", round(auc(rf_results$roc_object), 3), "\n")
cat("  Accuracy:", round(rf_results$confusion_matrix$overall["Accuracy"], 3), "\n")

# Visualizations
cat("\n========================================\n")
cat("CREATING VISUALIZATIONS\n")
cat("========================================\n\n")

or_plot_data <- summary_top15 %>% filter(term != "(Intercept)") %>%
  mutate(significant = ifelse(p.value < 0.05, "p < 0.05", ifelse(p.value < 0.10, "p < 0.10", "NS")))
p1 <- ggplot(or_plot_data, aes(x = reorder(term, OR), y = OR, color = significant)) +
  geom_point(size = 3) + geom_errorbar(aes(ymin = OR_lower, ymax = OR_upper), width = 0.3, linewidth = 0.8) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = c("p < 0.05" = "red", "p < 0.10" = "orange", "NS" = "gray60")) +
  coord_flip() + scale_y_log10() + labs(title = "Odds Ratios: Top 15 RF Predictors", x = NULL, y = "OR (log)") +
  theme_minimal(base_size = 11) + theme(plot.title = element_text(hjust = 0.5, face = "bold"), legend.position = "top")
print(p1)

perf_long <- performance_comparison %>% select(Model, AUC, Accuracy, Sensitivity, Specificity, F1) %>%
  tidyr::pivot_longer(cols = -Model, names_to = "Metric", values_to = "Value")
p2 <- ggplot(perf_long, aes(x = Metric, y = Value, fill = Model)) +
  geom_col(position = "dodge") + geom_hline(yintercept = 0.5, linetype = "dashed") +
  scale_fill_brewer(palette = "Set2") + labs(title = "Model Comparison", y = "Performance", x = NULL) +
  theme_minimal() + theme(plot.title = element_text(hjust = 0.5, face = "bold"),
                         legend.position = "top", axis.text.x = element_text(angle = 45, hjust = 1))
print(p2)

comparison_data <- data.frame(
  Method = c("Random Forest", "LR (Top 15)", "LR (Top 10)"),
  AUC = c(auc(rf_results$roc_object), perf_top15$AUC, perf_top10$AUC),
  Accuracy = c(rf_results$confusion_matrix$overall["Accuracy"], perf_top15$Accuracy, perf_top10$Accuracy))
if (!is.null(fit_list_sig)) {
  comparison_data <- rbind(comparison_data, data.frame(Method = "LR (Parsimonious)",
                                                       AUC = perf_sig$AUC, Accuracy = perf_sig$Accuracy))
}
comp_long <- comparison_data %>% tidyr::pivot_longer(cols = c(AUC, Accuracy), names_to = "Metric", values_to = "Value")
p3 <- ggplot(comp_long, aes(x = Method, y = Value, fill = Metric)) +
  geom_col(position = "dodge") + geom_text(aes(label = round(Value, 3)), position = position_dodge(0.9), vjust = -0.5, size = 3) +
  scale_fill_manual(values = c("AUC" = "steelblue", "Accuracy" = "coral")) +
  labs(title = "RF vs LR", y = "Performance", x = NULL) + ylim(0, 1) + theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"), legend.position = "top",
        axis.text.x = element_text(angle = 45, hjust = 1))
print(p3)

# Save
cat("\n========================================\n")
cat("SAVING RESULTS\n")
cat("========================================\n\n")
logistic_results <- list(
  model_top15 = list(fit = fit_list_top15, pooled = pooled_top15, summary = summary_top15),
  model_top10 = list(fit = fit_list_top10, pooled = pooled_top10, summary = summary_top10),
  model_parsimonious = if (!is.null(fit_list_sig)) list(fit = fit_list_sig, pooled = pooled_sig, summary = summary_sig) else NULL,
  performance_comparison = performance_comparison,
  rf_comparison = comparison_data,
  significant_predictors = if (!is.null(fit_list_sig)) sig_predictors_clean else NULL
)
saveRDS(logistic_results, "logistic_regression_validation.rds")
cat("✓ Results saved\n\n=== COMPLETE ===\n\n")
cat("SUMMARY:\n")
cat("RF AUC:", round(auc(rf_results$roc_object), 3), "\n")
cat("LR (Top 15) AUC:", round(perf_top15$AUC, 3), "\n")
cat("LR (Top 10) AUC:", round(perf_top10$AUC, 3), "\n")
if (!is.null(fit_list_sig)) {
  cat("LR (Parsimonious) AUC:", round(perf_sig$AUC, 3), "\n")
  cat("\nSignificant predictors (p < 0.10):", length(sig_predictors_clean), "\n")
}
cat("\n✓ Key predictors validated!\n")
```


## Post-Modeling Diagnostics

```{r}
#| label: Post-Modeling Diagnostics

library(mice)
library(dplyr)
library(pROC)
library(caret)
library(ggplot2)
library(gridExtra)
library(car)
library(MASS)

cat("\n=== POST-MODELING DIAGNOSTICS ===\n\n")

# Load results
cat("Loading results...\n")
logistic_results <- readRDS("logistic_regression_validation.rds")
rf_results <- readRDS("enhanced_random_forest_results.rds")
final_imp <- readRDS("final_imputation_with_subscales.rds")

# Recreate data
imputed_long <- complete(final_imp, "long", include = TRUE)
if (exists("SIMOA")) {
  imputed_long <- imputed_long %>%
    group_by(.imp) %>%
    mutate(scrn_stopped_bzra = SIMOA$scrn_stopped_bzra) %>%
    ungroup()
  
  if ("alc_use_men" %in% names(SIMOA) && "alc_use_wmn" %in% names(SIMOA)) {
    imputed_long <- imputed_long %>%
      group_by(.imp) %>%
      mutate(alc_use_men = SIMOA$alc_use_men, alc_use_wmn = SIMOA$alc_use_wmn) %>%
      ungroup() %>%
      mutate(alc_use_combined = coalesce(alc_use_men, alc_use_wmn))
  }
  
  imputed_long$scrn_stopped_bzra <- factor(imputed_long$scrn_stopped_bzra,
                                          levels = c(0, 1),
                                          labels = c("Still_Using", "No_Longer_Taking"))
}

# ===== 1. MULTICOLLINEARITY (VIF) =====
cat("========================================\n")
cat("1. MULTICOLLINEARITY CHECK (VIF)\n")
cat("========================================\n\n")

# Use first imputation for VIF (use dplyr::select to avoid conflict with MASS)
data_imp1 <- imputed_long %>% filter(.imp == 1) %>% dplyr::select(-c(.imp, .id))

# Fit model for VIF (using top 15)
fit_vif <- logistic_results$model_top15$fit[[1]]

# Calculate VIF
cat("Variance Inflation Factors (VIF):\n")
cat("Rule of thumb: VIF > 5 suggests multicollinearity, VIF > 10 is serious\n\n")

# Get VIF (handles both regular VIF and GVIF for categorical variables)
vif_raw <- vif(fit_vif)

# Process VIF output
if (is.matrix(vif_raw)) {
  # GVIF output (categorical variables present)
  cat("Note: Model contains categorical variables with multiple levels\n")
  cat("Using GVIF^(1/(2*Df)) for interpretation\n\n")
  vif_values <- vif_raw[, "GVIF^(1/(2*Df))"]
  names(vif_values) <- rownames(vif_raw)
} else {
  # Regular VIF output (all numeric predictors)
  vif_values <- vif_raw
}

# Create VIF dataframe
vif_df <- data.frame(
  Variable = names(vif_values),
  VIF = as.numeric(vif_values),
  Status = ifelse(vif_values > 10, "Serious",
                 ifelse(vif_values > 5, "Moderate", "OK")),
  row.names = NULL
)
vif_df <- vif_df[order(-vif_df$VIF), ]
print(vif_df, digits = 3, row.names = FALSE)

cat("\nInterpretation:\n")
if (any(vif_df$VIF > 10)) {
  cat("⚠ WARNING: Serious multicollinearity detected!\n")
  cat("  Variables with VIF > 10:\n")
  high_vif <- vif_df$Variable[vif_df$VIF > 10]
  cat(paste("  -", high_vif, collapse = "\n"), "\n")
} else if (any(vif_df$VIF > 5)) {
  cat("⚠ Moderate multicollinearity present\n")
  cat("  Variables with VIF > 5:\n")
  mod_vif <- vif_df$Variable[vif_df$VIF > 5]
  cat(paste("  -", mod_vif, collapse = "\n"), "\n")
} else {
  cat("✓ No concerning multicollinearity detected\n")
}

# VIF plot
p_vif <- ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF, fill = Status)) +
  geom_col() +
  geom_hline(yintercept = 5, linetype = "dashed", color = "orange", linewidth = 1) +
  geom_hline(yintercept = 10, linetype = "dashed", color = "red", linewidth = 1) +
  scale_fill_manual(values = c("OK" = "steelblue", "Moderate" = "orange", "Serious" = "red")) +
  coord_flip() +
  labs(title = "Multicollinearity Assessment (VIF)",
       subtitle = "Dashed lines at VIF = 5 (moderate) and 10 (serious)",
       x = NULL, y = "Variance Inflation Factor") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "top")
print(p_vif)

# ===== 2. CALIBRATION PLOT =====
cat("\n========================================\n")
cat("2. CALIBRATION ANALYSIS\n")
cat("========================================\n\n")

cat("Generating calibration plot across imputations...\n")

calibration_data_list <- list()

for (i in 1:final_imp$m) {
  data_imp <- imputed_long %>% filter(.imp == i) %>% dplyr::select(-c(.imp, .id))
  
  # Use same train/test split as performance evaluation
  set.seed(123 + i)
  train_idx <- createDataPartition(data_imp$scrn_stopped_bzra, p = 0.8, list = FALSE)
  test_data <- data_imp[-train_idx, ]
  
  # Get predictions
  pred_prob <- predict(logistic_results$model_top15$fit[[i]], 
                      newdata = test_data, 
                      type = "response")
  
  # Create bins
  test_data$pred_prob <- pred_prob
  test_data$pred_bin <- cut(pred_prob, 
                           breaks = seq(0, 1, by = 0.1),
                           include.lowest = TRUE,
                           labels = FALSE)
  
  # Calculate observed proportions per bin
  calib_summary <- test_data %>%
    group_by(pred_bin) %>%
    summarise(
      n = n(),
      predicted = mean(pred_prob),
      observed = mean(as.numeric(scrn_stopped_bzra) - 1),
      .groups = "drop"
    ) %>%
    filter(n >= 5)  # Only bins with sufficient data
  
  calib_summary$imputation <- i
  calibration_data_list[[i]] <- calib_summary
}

calibration_data <- bind_rows(calibration_data_list) %>%
  group_by(pred_bin) %>%
  summarise(
    predicted = mean(predicted),
    observed = mean(observed),
    n_total = sum(n),
    .groups = "drop"
  )

cat("Calibration summary:\n")
print(calibration_data, digits = 3)

# Hosmer-Lemeshow-like statistic
cal_chi_sq <- sum((calibration_data$observed - calibration_data$predicted)^2 / 
                 (calibration_data$predicted * (1 - calibration_data$predicted) / calibration_data$n_total))
cat("\nCalibration chi-square:", round(cal_chi_sq, 3), "\n")
cat("(Lower values indicate better calibration)\n")

# Calibration plot
p_calib <- ggplot(calibration_data, aes(x = predicted, y = observed)) +
  geom_point(aes(size = n_total), alpha = 0.6, color = "steelblue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  geom_smooth(method = "loess", se = TRUE, color = "darkblue", fill = "lightblue") +
  scale_size_continuous(name = "N", range = c(3, 10)) +
  coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1)) +
  labs(title = "Calibration Plot: Top 15 Logistic Regression",
       subtitle = "Perfect calibration = dashed red line",
       x = "Predicted Probability",
       y = "Observed Proportion") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "right")
print(p_calib)

# ===== 3. MODEL COMPARISON (DeLong Test) =====
cat("\n========================================\n")
cat("3. STATISTICAL MODEL COMPARISON\n")
cat("========================================\n\n")

cat("Comparing Random Forest vs Logistic Regression (DeLong test)...\n\n")

# Get RF ROC
rf_roc <- rf_results$roc_object

# Get LR ROC (from first imputation for simplicity)
data_imp1 <- imputed_long %>% filter(.imp == 1) %>% dplyr::select(-c(.imp, .id))
set.seed(124)
train_idx <- createDataPartition(data_imp1$scrn_stopped_bzra, p = 0.8, list = FALSE)
test_data <- data_imp1[-train_idx, ]
lr_pred <- predict(logistic_results$model_top15$fit[[1]], 
                   newdata = test_data, 
                   type = "response")
lr_roc <- roc(test_data$scrn_stopped_bzra, lr_pred, quiet = TRUE)

# DeLong test
delong_test <- roc.test(rf_roc, lr_roc, method = "delong")

cat("AUC Comparison:\n")
cat("  Random Forest AUC:", round(auc(rf_roc), 4), "\n")
cat("  Logistic Regression AUC:", round(auc(lr_roc), 4), "\n")
cat("  Difference:", round(auc(lr_roc) - auc(rf_roc), 4), "\n\n")

cat("DeLong Test Results:\n")
cat("  Z-statistic:", round(delong_test$statistic, 4), "\n")
cat("  p-value:", format.pval(delong_test$p.value, digits = 4), "\n")

if (delong_test$p.value < 0.05) {
  cat("\n✓ The difference in AUC is statistically significant (p < 0.05)\n")
  if (auc(lr_roc) > auc(rf_roc)) {
    cat("  Logistic Regression performs significantly better than Random Forest\n")
  } else {
    cat("  Random Forest performs significantly better than Logistic Regression\n")
  }
} else {
  cat("\n  The difference in AUC is not statistically significant (p ≥ 0.05)\n")
}

# ROC comparison plot
roc_comparison <- data.frame(
  FPR = c(1 - rf_roc$specificities, 1 - lr_roc$specificities),
  TPR = c(rf_roc$sensitivities, lr_roc$sensitivities),
  Model = rep(c("Random Forest", "Logistic Regression"), 
              c(length(rf_roc$sensitivities), length(lr_roc$sensitivities)))
)

p_roc_comp <- ggplot(roc_comparison, aes(x = FPR, y = TPR, color = Model)) +
  geom_line(linewidth = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
  annotate("text", x = 0.7, y = 0.3, 
           label = paste0("RF AUC = ", round(auc(rf_roc), 3)), 
           color = "#F8766D", size = 4, fontface = "bold") +
  annotate("text", x = 0.7, y = 0.2, 
           label = paste0("LR AUC = ", round(auc(lr_roc), 3)), 
           color = "#00BFC4", size = 4, fontface = "bold") +
  annotate("text", x = 0.7, y = 0.1,
           label = paste0("p = ", format.pval(delong_test$p.value, digits = 2)),
           size = 4, fontface = "italic") +
  labs(title = "ROC Curve Comparison",
       subtitle = "Random Forest vs Logistic Regression",
       x = "False Positive Rate",
       y = "True Positive Rate") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position.inside = c(0.8, 0.2))
print(p_roc_comp)

# ===== 4. PREDICTED PROBABILITY PLOTS =====
cat("\n========================================\n")
cat("4. PREDICTED PROBABILITY INTERPRETATION\n")
cat("========================================\n\n")

cat("Creating predicted probability plots for top predictors...\n\n")

# Get top 3 significant predictors
top_preds <- logistic_results$significant_predictors[1:min(3, length(logistic_results$significant_predictors))]
cat("Top predictors:", paste(top_preds, collapse = ", "), "\n\n")

prob_plots <- list()

for (pred in top_preds) {
  tryCatch({
    # Get data - include all variables from the model
    data_plot <- imputed_long %>% 
      filter(.imp == 1) %>% 
      dplyr::select(-c(.imp, .id))
    
    # Check if predictor is numeric
    if (is.numeric(data_plot[[pred]])) {
      # Create prediction grid
      pred_range <- seq(min(data_plot[[pred]], na.rm = TRUE),
                       max(data_plot[[pred]], na.rm = TRUE),
                       length.out = 100)
      
      # Get all predictors from the top15 model (not parsimonious)
      model_vars <- names(logistic_results$model_top15$fit[[1]]$model)[-1]  # Exclude outcome
      
      # Create newdata with all required variables
      newdata <- data_plot[1:100, model_vars, drop = FALSE]
      
      # Set the focal predictor to its range
      newdata[[pred]] <- pred_range
      
      # Set other predictors to their means/modes
      for (v in model_vars) {
        if (v != pred) {
          if (is.numeric(data_plot[[v]])) {
            newdata[[v]] <- mean(data_plot[[v]], na.rm = TRUE)
          } else if (is.factor(data_plot[[v]])) {
            # Get most common level
            mode_val <- names(sort(table(data_plot[[v]]), decreasing = TRUE))[1]
            newdata[[v]] <- factor(mode_val, levels = levels(data_plot[[v]]))
          } else {
            newdata[[v]] <- data_plot[[v]][1]
          }
        }
      }
      
      # Get predictions using top15 model
      newdata$pred_prob <- predict(logistic_results$model_top15$fit[[1]], 
                                  newdata = newdata, 
                                  type = "response")
      newdata$focal_var <- newdata[[pred]]
      
      # Create plot
      p <- ggplot(newdata, aes(x = focal_var, y = pred_prob)) +
        geom_line(color = "steelblue", linewidth = 1.2) +
        geom_ribbon(aes(ymin = pmax(pred_prob - 0.1, 0), 
                       ymax = pmin(pred_prob + 0.1, 1)),
                   alpha = 0.2, fill = "steelblue") +
        labs(title = paste("Predicted Probability by", pred),
             x = pred,
             y = "P(Discontinuation)") +
        ylim(0, 1) +
        theme_minimal() +
        theme(plot.title = element_text(hjust = 0.5, face = "bold"))
      
      prob_plots[[pred]] <- p
      
    } else {
      cat("  Skipping", pred, "(not numeric)\n")
    }
  }, error = function(e) {
    cat("  Could not create plot for", pred, ":", e$message, "\n")
  })
}

if (length(prob_plots) > 0) {
  cat("\nGenerating", length(prob_plots), "probability plot(s)...\n")
  do.call(grid.arrange, c(prob_plots, ncol = min(2, length(prob_plots))))
} else {
  cat("\nNo numeric predictors available for probability plots.\n")
}

# ===== 5. SAVE DIAGNOSTIC RESULTS =====
cat("\n========================================\n")
cat("SAVING DIAGNOSTIC RESULTS\n")
cat("========================================\n\n")

diagnostic_results <- list(
  vif = vif_df,
  calibration = calibration_data,
  delong_test = list(
    statistic = delong_test$statistic,
    p.value = delong_test$p.value,
    rf_auc = auc(rf_roc),
    lr_auc = auc(lr_roc)
  )
)

saveRDS(diagnostic_results, "model_diagnostics.rds")

cat("✓ Diagnostic results saved to 'model_diagnostics.rds'\n")
cat("\n=== DIAGNOSTICS COMPLETE ===\n\n")

# Summary
cat("SUMMARY:\n")
cat("1. Multicollinearity:\n")
if (any(vif_df$VIF > 10)) {
  cat("   ⚠ Serious issues detected - consider removing correlated predictors\n")
} else if (any(vif_df$VIF > 5)) {
  cat("   ⚠ Moderate issues - interpret coefficients cautiously\n")
} else {
  cat("   ✓ No major concerns\n")
}
cat("\n2. Calibration:\n")
cat("   Chi-square =", round(cal_chi_sq, 3), 
    ifelse(cal_chi_sq < 15, "(Good)", "(Check calibration)"), "\n")
cat("\n3. Model Comparison:\n")
cat("   LR AUC:", round(auc(lr_roc), 3), "vs RF AUC:", round(auc(rf_roc), 3), "\n")
cat("   p-value:", format.pval(delong_test$p.value, digits = 3), 
    ifelse(delong_test$p.value < 0.05, "(Significant difference)", "(Not significant)"), "\n")
cat("\n✓ All diagnostics complete! Review plots and results.\n")
```


## Cluster Analysis

## DEM+PERS

```{r}
#| label: CLUSTER ANALYSIS: PERSONALITY & DEMOGRAPHICS (POOLED IMPUTATION)
# Comprehensive Cluster Analysis with Multiple Imputation

# Load required libraries
library(tidyverse)
library(cluster)
library(factoextra)
library(NbClust)
library(ggplot2)
library(tableone)
library(mice)  # For handling multiple imputation

# ============================================================================
# STEP 1: DATA PREPARATION WITH MULTIPLE IMPUTATION
# ============================================================================

# Load the imputed dataset (should be a mids or mira object, or list of imputations)
final_imp <- readRDS("final_imputation_with_subscales.rds")

# Check the structure of your imputation object
cat("=== IMPUTATION OBJECT STRUCTURE ===\n")
cat("Class:", class(final_imp), "\n")

# If it's a mids object from mice:
if (inherits(final_imp, "mids")) {
  n_imputations <- final_imp$m
  cat("Number of imputations:", n_imputations, "\n")
  
  # Extract all imputed datasets and add outcome variable
  cat("\n=== ADDING OUTCOME VARIABLE ===\n")
  if (exists("SIMOA") && "scrn_stopped_bzra" %in% names(SIMOA)) {
    cat("✓ Adding scrn_stopped_bzra from SIMOA object (observations in same order)\n")
    cat("Number of observations in SIMOA:", nrow(SIMOA), "\n")
    cat("Outcome variable distribution:\n")
    print(table(SIMOA$scrn_stopped_bzra, useNA = "ifany"))
    
    imputed_list <- lapply(1:n_imputations, function(i) {
      imp_data <- complete(final_imp, action = i)
      # Add scrn_stopped_bzra directly (same order)
      imp_data$scrn_stopped_bzra <- SIMOA$scrn_stopped_bzra
      return(imp_data)
    })
  } else {
    cat("⚠ WARNING: SIMOA object or scrn_stopped_bzra not found\n")
    imputed_list <- lapply(1:n_imputations, function(i) complete(final_imp, action = i))
  }
  cat("\n")
  
} else if (is.list(final_imp) && !inherits(final_imp, "data.frame")) {
  # If it's already a list of data frames
  n_imputations <- length(imputed_list)
  cat("Number of imputations:", n_imputations, "\n")
  
  cat("\n=== ADDING OUTCOME VARIABLE ===\n")
  if (exists("SIMOA") && "scrn_stopped_bzra" %in% names(SIMOA)) {
    cat("✓ Adding scrn_stopped_bzra from SIMOA object (observations in same order)\n")
    imputed_list <- lapply(final_imp, function(imp_data) {
      imp_data$scrn_stopped_bzra <- SIMOA$scrn_stopped_bzra
      return(imp_data)
    })
  } else {
    cat("⚠ WARNING: SIMOA object or scrn_stopped_bzra not found\n")
    imputed_list <- final_imp
  }
  cat("\n")
  
} else {
  # If it's a single data frame, treat as single imputation
  cat("Single imputation detected\n")
  
  cat("\n=== ADDING OUTCOME VARIABLE ===\n")
  if (exists("SIMOA") && "scrn_stopped_bzra" %in% names(SIMOA)) {
    cat("✓ Adding scrn_stopped_bzra from SIMOA object (observations in same order)\n")
    imp_data <- final_imp
    imp_data$scrn_stopped_bzra <- SIMOA$scrn_stopped_bzra
    imputed_list <- list(imp_data)
  } else {
    cat("⚠ WARNING: SIMOA object or scrn_stopped_bzra not found\n")
    imputed_list <- list(final_imp)
  }
  n_imputations <- 1
  cat("\n")
}

# Define all personality variables for clustering
personality_vars <- c(
  # BFI-10 Big Five personality traits
  "Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness",
  # SURPS substance use risk personality
  "SURPS_Impulsivity", "SURPS_Sensation_Seeking", "SURPS_Hopelessness", 
  "SURPS_Anxiety_Sensitivity",
  # DBAS dysfunctional beliefs about sleep
  "DBAS_Expectations", "DBAS_Medications", "DBAS_Worry_Helplessness", "DBAS_Consequences",
  # CISS coping styles
  "CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style"
)

# Define demographic variables
demographic_vars <- c(
  "age", "sex", "gender", "prov_terr",
  "education", "income", "employment", "driving_freq", "med_quant", 
  "osss_3_score", "phq2_score"
)

# ===== SPECIFY OUTCOME VARIABLE =====
# Set the outcome variable name (from SIMOA dataset)
outcome_var <- "scrn_stopped_bzra"
cat("Outcome variable set to:", outcome_var, "\n\n")

# ============================================================================
# STEP 2: PERFORM CLUSTERING ON EACH IMPUTED DATASET
# ============================================================================

cat("=== PERFORMING CLUSTERING ON EACH IMPUTATION ===\n\n")

# Verify outcome variable is in the data
if (outcome_var %in% names(imputed_list[[1]])) {
  cat("✓ Outcome variable '", outcome_var, "' confirmed in imputed data\n\n", sep = "")
} else {
  cat("✗ WARNING: Outcome variable '", outcome_var, "' not found in imputed data\n", sep = "")
  cat("Available variables:", paste(head(names(imputed_list[[1]]), 20), collapse = ", "), "...\n\n")
}

# Function to perform clustering on one imputed dataset
cluster_one_imputation <- function(data, imp_num, optimal_k = NULL) {
  
  cat("Processing imputation", imp_num, "...\n")
  
  # Select clustering variables
  if (!is.null(outcome_var)) {
    clustering_data <- data %>%
      dplyr::select(all_of(c(personality_vars, outcome_var, demographic_vars))) %>%
      drop_na(all_of(personality_vars), all_of(outcome_var))
  } else {
    clustering_data <- data %>%
      dplyr::select(all_of(c(personality_vars, demographic_vars))) %>%
      drop_na(all_of(personality_vars))
  }
  
  # Prepare data for clustering (personality variables only)
  cluster_input <- clustering_data %>%
    dplyr::select(all_of(personality_vars))
  
  # Standardize the data
  cluster_scaled <- scale(cluster_input)
  
  # Determine optimal k if not provided (only for first imputation)
  if (is.null(optimal_k)) {
    cat("  Determining optimal k...\n")
    set.seed(123)
    
    # Use silhouette method (faster than NbClust for multiple imputations)
    sil_results <- sapply(2:8, function(k) {
      km <- kmeans(cluster_scaled, centers = k, nstart = 25)
      ss <- silhouette(km$cluster, dist(cluster_scaled))
      mean(ss[, 3])
    })
    
    optimal_k <- which.max(sil_results) + 1
    cat("  Optimal k =", optimal_k, "\n")
  }
  
  # Perform k-means clustering
  set.seed(123 + imp_num)  # Different seed for each imputation
  kmeans_result <- kmeans(cluster_scaled, centers = optimal_k, nstart = 50, iter.max = 100)
  
  # Calculate quality metrics
  sil <- silhouette(kmeans_result$cluster, dist(cluster_scaled))
  avg_sil <- mean(sil[, 3])
  
  # Return results
  list(
    cluster_assignments = kmeans_result$cluster,
    kmeans_obj = kmeans_result,
    data = clustering_data,
    scaled_data = cluster_scaled,
    optimal_k = optimal_k,
    silhouette = avg_sil,
    between_ss_ratio = kmeans_result$betweenss / kmeans_result$totss
  )
}

# Cluster all imputations
cluster_results <- list()
optimal_k_first <- NULL

for (i in 1:n_imputations) {
  cluster_results[[i]] <- cluster_one_imputation(
    imputed_list[[i]], 
    imp_num = i,
    optimal_k = optimal_k_first
  )
  
  # Use the same k for all imputations
  if (i == 1) {
    optimal_k_first <- cluster_results[[1]]$optimal_k
  }
}

cat("\n=== CLUSTERING QUALITY METRICS (ACROSS IMPUTATIONS) ===\n")
cat("Optimal k:", optimal_k_first, "\n")
cat("Average silhouette width:", 
    round(mean(sapply(cluster_results, function(x) x$silhouette)), 3), "\n")
cat("Average between SS / Total SS:", 
    round(mean(sapply(cluster_results, function(x) x$between_ss_ratio)) * 100, 2), "%\n\n")

# ============================================================================
# STEP 3: POOL CLUSTER ASSIGNMENTS
# ============================================================================

cat("=== POOLING CLUSTER ASSIGNMENTS ===\n\n")

# Create a matrix of cluster assignments (rows = observations, cols = imputations)
n_obs <- nrow(cluster_results[[1]]$data)
cluster_matrix <- matrix(NA, nrow = n_obs, ncol = n_imputations)

for (i in 1:n_imputations) {
  cluster_matrix[, i] <- cluster_results[[i]]$cluster_assignments
}

# Method 1: Most frequent cluster assignment (mode)
pooled_clusters <- apply(cluster_matrix, 1, function(x) {
  as.numeric(names(sort(table(x), decreasing = TRUE)[1]))
})

# Calculate cluster stability (proportion of times assigned to modal cluster)
cluster_stability <- apply(cluster_matrix, 1, function(x) {
  max(table(x)) / length(x)
})

cat("Mean cluster stability:", round(mean(cluster_stability), 3), "\n")
cat("Interpretation: Higher values indicate more consistent assignments\n\n")

# Add pooled clusters to the first imputation's data
pooled_data <- cluster_results[[1]]$data
pooled_data$Cluster <- as.factor(pooled_clusters)
pooled_data$Cluster_Stability <- cluster_stability

cat("Cluster sizes (pooled):\n")
print(table(pooled_clusters))
cat("\n")

# ============================================================================
# STEP 4: PROFILE CLUSTERS - POOLED ESTIMATES
# ============================================================================

cat("=== CLUSTER PROFILING (POOLED) ===\n\n")

# Pool cluster profiles across imputations using Rubin's rules
pool_cluster_profiles <- function(cluster_results, personality_vars, pooled_clusters) {
  
  n_clusters <- length(unique(pooled_clusters))
  profile_list <- list()
  
  for (i in 1:length(cluster_results)) {
    data_temp <- cluster_results[[i]]$data
    data_temp$Cluster <- pooled_clusters  # Use pooled assignments
    
    profile <- data_temp %>%
      group_by(Cluster) %>%
      summarise(
        across(all_of(personality_vars), 
               list(mean = ~mean(., na.rm = TRUE)),
               .names = "{.col}")
      )
    
    profile_list[[i]] <- profile
  }
  
  # Average means across imputations
  pooled_profile <- profile_list[[1]]
  
  for (var in personality_vars) {
    for (k in 1:n_clusters) {
      means <- sapply(profile_list, function(p) p[[var]][k])
      pooled_profile[[var]][k] <- mean(means, na.rm = TRUE)
    }
  }
  
  return(pooled_profile)
}

cluster_profiles <- pool_cluster_profiles(cluster_results, personality_vars, pooled_clusters)
cluster_profiles$N <- table(pooled_clusters)[as.numeric(cluster_profiles$Cluster)]

print(cluster_profiles)

# ============================================================================
# STEP 5: STATISTICAL TESTS (POOLED)
# ============================================================================

cat("\n=== POOLED ANOVA TESTS FOR CLUSTER DIFFERENCES ===\n\n")

# For each variable, pool F-statistics and p-values across imputations
pool_anova <- function(cluster_results, personality_vars, pooled_clusters) {
  
  results_list <- list()
  
  for (var in personality_vars) {
    f_stats <- numeric(length(cluster_results))
    p_values <- numeric(length(cluster_results))
    eta2_values <- numeric(length(cluster_results))
    
    for (i in 1:length(cluster_results)) {
      data_temp <- cluster_results[[i]]$data
      data_temp$Cluster <- as.factor(pooled_clusters)
      
      formula_str <- paste(var, "~ Cluster")
      anova_test <- aov(as.formula(formula_str), data = data_temp)
      anova_summary <- summary(anova_test)
      
      f_stats[i] <- anova_summary[[1]]["Cluster", "F value"]
      p_values[i] <- anova_summary[[1]]["Cluster", "Pr(>F)"]
      
      ss_between <- anova_summary[[1]]["Cluster", "Sum Sq"]
      ss_total <- sum(anova_summary[[1]][, "Sum Sq"])
      eta2_values[i] <- ss_between / ss_total
    }
    
    # Pool results (simple averaging for exploratory analysis)
    results_list[[var]] <- data.frame(
      Variable = var,
      F_statistic = mean(f_stats, na.rm = TRUE),
      p_value = mean(p_values, na.rm = TRUE),
      Effect_size_eta2 = mean(eta2_values, na.rm = TRUE)
    )
  }
  
  do.call(rbind, results_list)
}

anova_results <- pool_anova(cluster_results, personality_vars, pooled_clusters)

# Add significance markers
anova_results$Significance <- case_when(
  anova_results$p_value < 0.001 ~ "***",
  anova_results$p_value < 0.01 ~ "**",
  anova_results$p_value < 0.05 ~ "*",
  TRUE ~ "ns"
)

anova_results$Effect_Size_Interpretation <- case_when(
  anova_results$Effect_size_eta2 >= 0.14 ~ "Large",
  anova_results$Effect_size_eta2 >= 0.06 ~ "Medium",
  anova_results$Effect_size_eta2 >= 0.01 ~ "Small",
  TRUE ~ "Negligible"
)

anova_results <- anova_results %>% arrange(desc(Effect_size_eta2))

cat("=== POOLED ANOVA RESULTS (sorted by effect size) ===\n")
print(anova_results)

# ============================================================================
# STEP 6: VISUALIZATIONS
# ============================================================================

cat("\n=== CREATING VISUALIZATIONS ===\n\n")

# Cluster visualization (PCA projection)
set.seed(123)
cluster_viz <- fviz_cluster(
  list(data = cluster_results[[1]]$scaled_data, cluster = pooled_clusters),
  palette = "jco",
  ellipse.type = "convex",
  repel = TRUE,
  ggtheme = theme_minimal(),
  main = paste("Pooled K-means Clustering (k =", optimal_k_first, ")")
)
print(cluster_viz)

# Cluster profiles by domain
plot_cluster_profiles <- function(data, vars, title) {
  long_data <- data %>%
    dplyr::select(Cluster, all_of(vars)) %>%
    pivot_longer(cols = all_of(vars), names_to = "Variable", values_to = "Value")
  
  ggplot(long_data, aes(x = Variable, y = Value, fill = Cluster)) +
    geom_boxplot() +
    facet_wrap(~ Variable, scales = "free_x") +
    theme_minimal() +
    theme(axis.text.x = element_blank()) +
    labs(title = title, x = "Trait", y = "Score") +
    scale_fill_brewer(palette = "Set2")
}

# NEO-FFI profile
neo_vars <- c("Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness")
print(plot_cluster_profiles(pooled_data, neo_vars, "NEO-FFI Big Five by Cluster"))

# SURPS profile
surps_vars <- c("SURPS_Impulsivity", "SURPS_Sensation_Seeking", 
                "SURPS_Hopelessness", "SURPS_Anxiety_Sensitivity")
print(plot_cluster_profiles(pooled_data, surps_vars, "SURPS by Cluster"))

# DBAS profile
dbas_vars <- c("DBAS_Expectations", "DBAS_Medications", 
               "DBAS_Worry_Helplessness", "DBAS_Consequences")
print(plot_cluster_profiles(pooled_data, dbas_vars, "DBAS by Cluster"))

# CISS profile
ciss_vars <- c("CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style")
print(plot_cluster_profiles(pooled_data, ciss_vars, "CISS by Cluster"))

# ============================================================================
# STEP 7: BENZODIAZEPINE CESSATION ANALYSIS (POOLED)
# ============================================================================

if (!is.null(outcome_var)) {
  cat("\n=== BENZODIAZEPINE CESSATION ANALYSIS (POOLED) ===\n\n")
  
  # Cross-tabulation
  cessation_table <- table(pooled_data$Cluster, pooled_data[[outcome_var]])
  cat("Benzodiazepine Cessation by Cluster:\n")
  print(cessation_table)
  cat("\n")
  
  # Proportions
  cessation_props <- prop.table(cessation_table, margin = 1)
  cat("Proportions (by cluster):\n")
  print(round(cessation_props, 3))
  cat("\n")
  
  # Chi-square test
  chi_test <- chisq.test(cessation_table)
  cat("Chi-square test:\n")
  cat("X-squared =", round(chi_test$statistic, 3), "\n")
  cat("p-value =", format.pval(chi_test$p.value, digits = 3), "\n\n")
  
  # Visualization
  cessation_viz <- pooled_data %>%
    group_by(Cluster, !!sym(outcome_var)) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(Cluster) %>%
    mutate(prop = n / sum(n))
  
  cessation_plot <- ggplot(cessation_viz, aes(x = Cluster, y = prop, fill = as.factor(!!sym(outcome_var)))) +
    geom_bar(stat = "identity", position = "fill") +
    geom_text(aes(label = paste0(round(prop * 100, 1), "%")), 
              position = position_fill(vjust = 0.5), size = 3) +
    scale_y_continuous(labels = scales::percent) +
    labs(title = "Benzodiazepine Cessation by Cluster (Pooled)",
         y = "Percentage", x = "Cluster", fill = "SIMOA Status") +
    theme_minimal() +
    scale_fill_brewer(palette = "Set1")
  print(cessation_plot)
} else {
  cat("\n=== OUTCOME VARIABLE NOT AVAILABLE ===\n")
  cat("Skipping cessation analysis.\n\n")
} +
  labs(title = "Benzodiazepine Cessation by Cluster (Pooled)",
       y = "Percentage", x = "Cluster", fill = "SIMOA Status") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")
print(cessation_plot)

# ============================================================================
# STEP 8: EXPORT RESULTS
# ============================================================================

cat("\n=== EXPORTING RESULTS ===\n")

write.csv(pooled_data, "cluster_assignments_pooled.csv", row.names = FALSE)
write.csv(anova_results, "cluster_anova_results_pooled.csv", row.names = FALSE)
write.csv(cluster_profiles, "cluster_profiles_pooled.csv", row.names = FALSE)

cat("\n=== ANALYSIS COMPLETE ===\n")
cat("Files saved with '_pooled' suffix\n")
```

## Cluster Follow-up

```{r}
#| label: CLUSTER FOLLOW-UP ANALYSIS
# Comprehensive follow-up analyses after cluster analysis

# Load required libraries
library(tidyverse)
library(tableone)
library(ggplot2)
library(patchwork)
library(factoextra)

# ============================================================================
# STEP 1: COMPREHENSIVE COMPARISON TABLE (DEMOGRAPHICS + PERSONALITY)
# ============================================================================

cat("=== COMPREHENSIVE CLUSTER COMPARISON TABLE ===\n\n")

# Combine all variables for comparison
all_comparison_vars <- c(demographic_vars, personality_vars)

# Create comprehensive comparison table
comprehensive_table <- CreateTableOne(
  vars = all_comparison_vars,
  strata = "Cluster",
  data = pooled_data,
  test = TRUE,
  addOverall = TRUE
)

cat("COMPLETE COMPARISON: Demographics + Personality by Cluster\n")
cat("=" %>% rep(80) %>% paste(collapse = ""), "\n\n")
print(comprehensive_table, showAllLevels = TRUE, smd = TRUE, printToggle = TRUE)

cat("\n\n")

# Create a more detailed comparison with means, SDs, and effect sizes
cat("=== DETAILED COMPARISON WITH EFFECT SIZES ===\n\n")

# Function to calculate detailed statistics
calc_detailed_stats <- function(data, var, cluster_var = "Cluster") {
  
  # Check if variable exists and is numeric
  if (!var %in% names(data)) {
    return(NULL)
  }
  
  if (is.numeric(data[[var]])) {
    
    cluster1_data <- data[[var]][data[[cluster_var]] == 1]
    cluster2_data <- data[[var]][data[[cluster_var]] == 2]
    
    # Remove NAs
    cluster1_data <- cluster1_data[!is.na(cluster1_data)]
    cluster2_data <- cluster2_data[!is.na(cluster2_data)]
    
    # Calculate statistics
    stats <- data.frame(
      Variable = var,
      Cluster1_N = length(cluster1_data),
      Cluster1_Mean = mean(cluster1_data),
      Cluster1_SD = sd(cluster1_data),
      Cluster2_N = length(cluster2_data),
      Cluster2_Mean = mean(cluster2_data),
      Cluster2_SD = sd(cluster2_data),
      Difference = mean(cluster2_data) - mean(cluster1_data)
    )
    
    # T-test
    if (length(cluster1_data) > 1 && length(cluster2_data) > 1) {
      t_result <- t.test(cluster2_data, cluster1_data)
      stats$t_statistic <- t_result$statistic
      stats$p_value <- t_result$p.value
      
      # Cohen's d
      pooled_sd <- sqrt(((stats$Cluster1_N - 1) * stats$Cluster1_SD^2 + 
                         (stats$Cluster2_N - 1) * stats$Cluster2_SD^2) / 
                        (stats$Cluster1_N + stats$Cluster2_N - 2))
      stats$Cohens_d <- stats$Difference / pooled_sd
    } else {
      stats$t_statistic <- NA
      stats$p_value <- NA
      stats$Cohens_d <- NA
    }
    
    return(stats)
  } else {
    return(NULL)
  }
}

# Calculate for all numeric variables
detailed_comparison <- lapply(all_comparison_vars, function(v) {
  calc_detailed_stats(pooled_data, v)
}) %>%
  bind_rows()

# Check if we have results
if (nrow(detailed_comparison) > 0) {
  detailed_comparison <- detailed_comparison %>%
    mutate(
      Significance = case_when(
        is.na(p_value) ~ "",
        p_value < 0.001 ~ "***",
        p_value < 0.01 ~ "**",
        p_value < 0.05 ~ "*",
        TRUE ~ "ns"
      ),
      Effect_Size_Interpretation = case_when(
        is.na(Cohens_d) ~ "",
        abs(Cohens_d) >= 0.8 ~ "Large",
        abs(Cohens_d) >= 0.5 ~ "Medium",
        abs(Cohens_d) >= 0.2 ~ "Small",
        TRUE ~ "Negligible"
      )
    ) %>%
    arrange(desc(abs(Cohens_d)))
  
  # Format and print
  cat("\nNUMERIC VARIABLES COMPARISON (sorted by effect size):\n")
  cat("=" %>% rep(120) %>% paste(collapse = ""), "\n\n")
  
  print(
    detailed_comparison %>%
      mutate(
        Cluster1_Mean = round(Cluster1_Mean, 2),
        Cluster1_SD = round(Cluster1_SD, 2),
        Cluster2_Mean = round(Cluster2_Mean, 2),
        Cluster2_SD = round(Cluster2_SD, 2),
        Difference = round(Difference, 2),
        t_statistic = round(t_statistic, 2),
        p_value = ifelse(is.na(p_value), "", format.pval(p_value, digits = 3)),
        Cohens_d = round(Cohens_d, 3)
      ) %>%
      dplyr::select(Variable, 
             Cluster1_Mean, Cluster1_SD, 
             Cluster2_Mean, Cluster2_SD,
             Difference, Cohens_d, Effect_Size_Interpretation,
             t_statistic, p_value, Significance),
    row.names = FALSE
  )
} else {
  cat("\nNo numeric variables found for comparison.\n")
}

cat("\n\n")

# Print categorical variables summary
cat("=== CATEGORICAL VARIABLES SUMMARY ===\n\n")

categorical_vars <- all_comparison_vars[!sapply(pooled_data[all_comparison_vars], is.numeric)]

if (length(categorical_vars) > 0) {
  for (var in categorical_vars) {
    cat("\n", var, ":\n", sep = "")
    cat("-" %>% rep(60) %>% paste(collapse = ""), "\n")
    
    cross_tab <- table(pooled_data$Cluster, pooled_data[[var]])
    prop_tab <- prop.table(cross_tab, 1)
    
    cat("Counts:\n")
    print(cross_tab)
    cat("\nProportions (by cluster):\n")
    print(round(prop_tab, 3))
    
    # Chi-square test if more than 1 level
    if (ncol(cross_tab) > 1) {
      chi_result <- chisq.test(cross_tab)
      cat("\nChi-square: X² =", round(chi_result$statistic, 3), 
          ", p =", format.pval(chi_result$p.value, digits = 3), "\n")
    }
  }
}

# ============================================================================
# STEP 2: LOGISTIC REGRESSION - CLUSTER PREDICTING CESSATION
# ============================================================================

cat("\n\n=== LOGISTIC REGRESSION ANALYSIS ===\n\n")

# Crude model (unadjusted)
cat("--- CRUDE MODEL (Unadjusted) ---\n")
model_crude <- glm(scrn_stopped_bzra ~ Cluster, 
                   data = pooled_data, 
                   family = binomial)
summary(model_crude)

cat("\nOdds Ratios with 95% CI (Crude Model):\n")
crude_or <- exp(cbind(OR = coef(model_crude), confint(model_crude)))
print(round(crude_or, 3))
cat("\n")

# Adjusted model (with demographics)
cat("--- ADJUSTED MODEL (with covariates) ---\n")
model_adjusted <- glm(scrn_stopped_bzra ~ Cluster + age + sex + 
                      phq2_score + osss_3_score, 
                      data = pooled_data, 
                      family = binomial)
summary(model_adjusted)

cat("\nOdds Ratios with 95% CI (Adjusted Model):\n")
adjusted_or <- exp(cbind(OR = coef(model_adjusted), confint(model_adjusted)))
print(round(adjusted_or, 3))
cat("\n")

# Create comparison table
regression_results <- data.frame(
  Model = c("Crude", "Adjusted"),
  OR = c(crude_or["Cluster2", "OR"], adjusted_or["Cluster2", "OR"]),
  CI_Lower = c(crude_or["Cluster2", "2.5 %"], adjusted_or["Cluster2", "2.5 %"]),
  CI_Upper = c(crude_or["Cluster2", "97.5 %"], adjusted_or["Cluster2", "97.5 %"]),
  P_Value = c(
    summary(model_crude)$coefficients["Cluster2", "Pr(>|z|)"],
    summary(model_adjusted)$coefficients["Cluster2", "Pr(>|z|)"]
  )
)

cat("\nREGRESSION SUMMARY TABLE:\n")
print(regression_results, row.names = FALSE)
cat("\n")

# ============================================================================
# STEP 3: POST-HOC TESTS FOR TOP DISCRIMINATING VARIABLES
# ============================================================================

cat("=== POST-HOC TESTS (Tukey HSD) ===\n\n")

# Top variables with large effect sizes
top_vars <- c("CISS_Emotional_Style", "Neuroticism", "DBAS_Worry_Helplessness", 
              "DBAS_Consequences", "SURPS_Hopelessness", "SURPS_Anxiety_Sensitivity",
              "SURPS_Impulsivity")

posthoc_results_list <- list()

for (var in top_vars) {
  if (var %in% names(pooled_data)) {
    cat("\n=== POST-HOC TEST:", var, "===\n")
    formula_str <- paste(var, "~ Cluster")
    aov_model <- aov(as.formula(formula_str), data = pooled_data)
    tukey_result <- TukeyHSD(aov_model)
    print(tukey_result)
    
    # Store results
    posthoc_results_list[[var]] <- data.frame(
      Variable = var,
      Comparison = rownames(tukey_result$Cluster),
      Difference = tukey_result$Cluster[, "diff"],
      CI_Lower = tukey_result$Cluster[, "lwr"],
      CI_Upper = tukey_result$Cluster[, "upr"],
      P_Adjusted = tukey_result$Cluster[, "p adj"]
    )
  }
}

# Combine and export
if (length(posthoc_results_list) > 0) {
  posthoc_results <- do.call(rbind, posthoc_results_list)
  cat("\n=== SUMMARY OF POST-HOC RESULTS ===\n")
  print(posthoc_results, row.names = FALSE)
  cat("\n")
}

# ============================================================================
# STEP 4: CLUSTER STABILITY ANALYSIS
# ============================================================================

cat("=== CLUSTER STABILITY ANALYSIS ===\n\n")

# Distribution of stability scores
cat("Cluster Stability Summary:\n")
print(summary(pooled_data$Cluster_Stability))
cat("\n")

# Create stability histogram
stability_hist <- ggplot(pooled_data, aes(x = Cluster_Stability)) +
  geom_histogram(bins = 20, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = 0.7, linetype = "dashed", color = "red", linewidth = 1) +
  labs(title = "Distribution of Cluster Stability Scores",
       subtitle = "Red line indicates 70% threshold",
       x = "Stability Score (Proportion of Consistent Assignments)",
       y = "Count") +
  theme_minimal()
print(stability_hist)
ggsave("cluster_stability_histogram.png", width = 10, height = 6, dpi = 300)

# Categorize by stability
pooled_data$Stability_Category <- cut(pooled_data$Cluster_Stability,
                                       breaks = c(0, 0.5, 0.7, 0.85, 1.0),
                                       labels = c("Low (<50%)", "Moderate (50-70%)", 
                                                  "High (70-85%)", "Very High (>85%)"))

cat("Stability Categories:\n")
print(table(pooled_data$Stability_Category))
cat("\n")

# Cessation rates by stability category
cat("Cessation rates by stability category:\n")
stability_cessation <- table(pooled_data$Stability_Category, pooled_data$scrn_stopped_bzra)
print(stability_cessation)
cat("\nProportions:\n")
print(round(prop.table(stability_cessation, 1), 3))
cat("\n")

# Compare high vs low stability
pooled_data$High_Stability <- ifelse(pooled_data$Cluster_Stability >= 0.7, "High (≥70%)", "Low (<70%)")
cat("High vs Low Stability:\n")
stab_table <- table(pooled_data$High_Stability, pooled_data$scrn_stopped_bzra)
print(stab_table)
cat("\nProportions:\n")
print(round(prop.table(stab_table, 1), 3))
cat("\n")

# Test if stability moderates cessation
chi_stability <- chisq.test(stab_table)
cat("Chi-square test (Stability × Cessation):\n")
cat("X-squared =", round(chi_stability$statistic, 3), "\n")
cat("p-value =", format.pval(chi_stability$p.value, digits = 3), "\n\n")

# ============================================================================
# STEP 5: PUBLICATION-READY FIGURES
# ============================================================================

cat("=== CREATING PUBLICATION-READY FIGURES ===\n\n")

# Figure 1: Cluster profiles heatmap
cat("Creating cluster profiles heatmap...\n")

cluster_means_long <- cluster_profiles %>%
  dplyr::select(-N) %>%
  pivot_longer(-Cluster, names_to = "Variable", values_to = "Mean")

# Standardize means for better visualization
cluster_means_long <- cluster_means_long %>%
  group_by(Variable) %>%
  mutate(Mean_Std = scale(Mean)[,1]) %>%
  ungroup()

heatmap_plot <- ggplot(cluster_means_long, aes(x = Variable, y = as.factor(Cluster), fill = Mean_Std)) +
  geom_tile(color = "white", linewidth = 0.5) +
  scale_fill_gradient2(low = "#2166AC", mid = "white", high = "#B2182B", 
                       midpoint = 0, name = "Standardized\nMean") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        axis.text.y = element_text(size = 12),
        plot.title = element_text(size = 14, face = "bold")) +
  labs(title = "Personality Profiles by Cluster",
       x = "", y = "Cluster")

print(heatmap_plot)
ggsave("cluster_heatmap.png", width = 14, height = 5, dpi = 300)
cat("✓ Saved: cluster_heatmap.png\n")

# Figure 2: Forest plot of effect sizes
cat("Creating effect size forest plot...\n")

forest_data <- anova_results %>%
  filter(Effect_size_eta2 >= 0.01) %>%  # Only small or larger effects
  mutate(Variable = factor(Variable, levels = Variable[order(Effect_size_eta2)]))

forest_plot <- ggplot(forest_data, aes(x = Effect_size_eta2, y = Variable)) +
  geom_segment(aes(x = 0, xend = Effect_size_eta2, y = Variable, yend = Variable), 
               color = "gray70") +
  geom_point(aes(color = Effect_Size_Interpretation), size = 4) +
  geom_vline(xintercept = c(0.01, 0.06, 0.14), linetype = "dashed", alpha = 0.5) +
  scale_color_manual(values = c("Small" = "#FDB462", "Medium" = "#FB8072", "Large" = "#E31A1C"),
                     name = "Effect Size") +
  labs(title = "Effect Sizes (η²) for Cluster Differences",
       subtitle = "Dashed lines indicate small (0.01), medium (0.06), and large (0.14) effects",
       x = "Eta-squared (η²)", y = "") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"),
        axis.text.y = element_text(size = 10))

print(forest_plot)
ggsave("effect_sizes_forest_plot.png", width = 10, height = 8, dpi = 300)
cat("✓ Saved: effect_sizes_forest_plot.png\n")

# Figure 3: Cessation by cluster with confidence intervals
cat("Creating cessation comparison plot...\n")

cessation_summary <- pooled_data %>%
  group_by(Cluster) %>%
  summarise(
    n = n(),
    successes = sum(scrn_stopped_bzra),
    prop = mean(scrn_stopped_bzra),
    .groups = "drop"
  ) %>%
  rowwise() %>%
  mutate(
    ci_lower = binom.test(successes, n)$conf.int[1],
    ci_upper = binom.test(successes, n)$conf.int[2]
  )

cessation_comparison_plot <- ggplot(cessation_summary, aes(x = Cluster, y = prop, fill = Cluster)) +
  geom_bar(stat = "identity", alpha = 0.7, width = 0.6) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, linewidth = 1) +
  geom_text(aes(label = paste0(round(prop * 100, 1), "%\n(n=", successes, "/", n, ")")),
            vjust = -0.5, size = 5) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 0.4)) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Benzodiazepine Cessation Rates by Cluster",
       subtitle = "Error bars represent 95% confidence intervals",
       x = "Cluster", y = "Cessation Rate") +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12))

print(cessation_comparison_plot)
ggsave("cessation_by_cluster_with_ci.png", width = 8, height = 6, dpi = 300)
cat("✓ Saved: cessation_by_cluster_with_ci.png\n")

# Figure 4: Combined personality domain plots
cat("Creating combined domain profiles...\n")

# Create plots for each domain
create_domain_plot <- function(data, vars, domain_name, palette) {
  long_data <- data %>%
    dplyr::select(Cluster, all_of(vars)) %>%
    pivot_longer(cols = all_of(vars), names_to = "Variable", values_to = "Value")
  
  ggplot(long_data, aes(x = Variable, y = Value, fill = Cluster)) +
    geom_boxplot(alpha = 0.7) +
    scale_fill_brewer(palette = palette) +
    labs(title = domain_name, x = "", y = "Score") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
          plot.title = element_text(size = 11, face = "bold"),
          legend.position = "bottom")
}

bfi_plot <- create_domain_plot(pooled_data, 
                                c("Extraversion", "Agreeableness", "Conscientiousness", "Neuroticism", "Openness"),
                                "Big Five Personality", "Set2")

surps_plot <- create_domain_plot(pooled_data,
                                  c("SURPS_Impulsivity", "SURPS_Sensation_Seeking", 
                                    "SURPS_Hopelessness", "SURPS_Anxiety_Sensitivity"),
                                  "Substance Use Risk", "Set1")

dbas_plot <- create_domain_plot(pooled_data,
                                 c("DBAS_Expectations", "DBAS_Medications", 
                                   "DBAS_Worry_Helplessness", "DBAS_Consequences"),
                                 "Sleep Beliefs", "Pastel1")

ciss_plot <- create_domain_plot(pooled_data,
                                 c("CISS_Avoidance_Style", "CISS_Task_Style", "CISS_Emotional_Style"),
                                 "Coping Styles", "Dark2")

# Combine all domain plots
combined_domains <- (bfi_plot | surps_plot) / (dbas_plot | ciss_plot) +
  plot_annotation(title = "Personality Domain Profiles by Cluster",
                  theme = theme(plot.title = element_text(size = 16, face = "bold")))

print(combined_domains)
ggsave("combined_domain_profiles.png", width = 16, height = 10, dpi = 300)
cat("✓ Saved: combined_domain_profiles.png\n\n")

# ============================================================================
# STEP 6: SENSITIVITY AND INTERACTION ANALYSES
# ============================================================================

cat("=== SENSITIVITY AND INTERACTION ANALYSES ===\n\n")

# Add descriptive cluster labels
cat("Adding descriptive cluster labels...\n")
pooled_data <- pooled_data %>%
  mutate(Cluster_Label = factor(Cluster,
                                levels = c(1, 2),
                                labels = c("Vulnerable/Distressed", "Resilient/Adaptive")))

cat("Cluster labels assigned:\n")
cat("  Cluster 1 = Vulnerable/Distressed\n")
cat("  Cluster 2 = Resilient/Adaptive\n\n")

cat("Distribution:\n")
print(table(pooled_data$Cluster_Label))
cat("\n")

# ============================================================================
# PART A: SENSITIVITY ANALYSES - SUBGROUP ANALYSES
# ============================================================================

cat("=== SENSITIVITY ANALYSES: SUBGROUP ANALYSES ===\n\n")

# Function to run logistic regression in subgroups
run_subgroup_analysis <- function(data, subgroup_var, subgroup_label) {
  
  cat("\n", rep("=", 70), "\n", sep = "")
  cat("SUBGROUP ANALYSIS:", subgroup_label, "\n")
  cat(rep("=", 70), "\n\n", sep = "")
  
  # Get unique levels of subgroup variable
  levels <- unique(data[[subgroup_var]])
  levels <- levels[!is.na(levels)]
  
  results_list <- list()
  
  for (level in levels) {
    cat("\n--- Subgroup:", subgroup_var, "=", level, "---\n")
    
    # Subset data
    subset_data <- data %>% filter(!!sym(subgroup_var) == level)
    
    cat("N =", nrow(subset_data), "\n")
    cat("Cluster 1:", sum(subset_data$Cluster == 1), 
        "| Cluster 2:", sum(subset_data$Cluster == 2), "\n")
    
    # Check if we have enough data
    if (nrow(subset_data) < 30) {
      cat("WARNING: Small sample size, results may be unstable\n\n")
    }
    
    # Run logistic regression
    tryCatch({
      model <- glm(scrn_stopped_bzra ~ Cluster, 
                   data = subset_data, 
                   family = binomial)
      
      # Get OR and CI
      or_ci <- exp(cbind(OR = coef(model), confint(model)))
      
      cat("\nOdds Ratio (95% CI):\n")
      print(round(or_ci["Cluster2", ], 3))
      
      # Get p-value
      p_val <- summary(model)$coefficients["Cluster2", "Pr(>|z|)"]
      cat("p-value:", format.pval(p_val, digits = 3), "\n")
      
      # Cessation rates by cluster
      cess_rates <- subset_data %>%
        group_by(Cluster) %>%
        summarise(
          n = n(),
          n_stopped = sum(scrn_stopped_bzra),
          pct_stopped = mean(scrn_stopped_bzra) * 100,
          .groups = "drop"
        )
      
      cat("\nCessation Rates:\n")
      print(cess_rates)
      
      # Store results
      results_list[[as.character(level)]] <- data.frame(
        Subgroup_Variable = subgroup_var,
        Subgroup_Level = level,
        N = nrow(subset_data),
        OR = or_ci["Cluster2", "OR"],
        CI_Lower = or_ci["Cluster2", "2.5 %"],
        CI_Upper = or_ci["Cluster2", "97.5 %"],
        P_Value = p_val,
        Cluster1_Cessation = cess_rates$pct_stopped[cess_rates$Cluster == 1],
        Cluster2_Cessation = cess_rates$pct_stopped[cess_rates$Cluster == 2]
      )
      
    }, error = function(e) {
      cat("ERROR: Could not fit model -", e$message, "\n")
    })
    
    cat("\n")
  }
  
  return(bind_rows(results_list))
}

# ------------------------------------------------------------------------
# 1. By Sex/Gender
# ------------------------------------------------------------------------
sensitivity_sex <- run_subgroup_analysis(pooled_data, "sex", "SEX")

# ------------------------------------------------------------------------
# 2. By Age Group
# ------------------------------------------------------------------------
cat("\n\nCreating age groups...\n")
pooled_data$age_group <- cut(pooled_data$age,
                               breaks = c(-Inf, 70, 75, Inf),
                               labels = c("Under 70", "70-75", "Over 75"))

cat("Age group distribution:\n")
print(table(pooled_data$age_group))

sensitivity_age <- run_subgroup_analysis(pooled_data, "age_group", "AGE GROUP")

# ------------------------------------------------------------------------
# 3. By Depression Level (PHQ-2)
# ------------------------------------------------------------------------
cat("\n\nCreating depression groups...\n")
pooled_data$depression_level <- cut(pooled_data$phq2_score,
                                      breaks = c(-Inf, 2, Inf),
                                      labels = c("Low (0-2)", "High (3+)"))

cat("Depression level distribution:\n")
print(table(pooled_data$depression_level))

sensitivity_depression <- run_subgroup_analysis(pooled_data, "depression_level", 
                                                 "DEPRESSION LEVEL (PHQ-2)")

# ------------------------------------------------------------------------
# 4. By Social Support Level (OSSS-3)
# ------------------------------------------------------------------------
cat("\n\nCreating social support groups...\n")
pooled_data$social_support_level <- cut(pooled_data$osss_3_score,
                                          breaks = c(-Inf, 9, Inf),
                                          labels = c("Low (3-9)", "High (10+)"))

cat("Social support level distribution:\n")
print(table(pooled_data$social_support_level))

sensitivity_support <- run_subgroup_analysis(pooled_data, "social_support_level", 
                                              "SOCIAL SUPPORT LEVEL (OSSS-3)")

# ------------------------------------------------------------------------
# 5. By Medication Quantity
# ------------------------------------------------------------------------
cat("\n\nCreating medication quantity groups...\n")
pooled_data$med_quantity_group <- cut(pooled_data$med_quant,
                                        breaks = c(-Inf, median(pooled_data$med_quant, na.rm = TRUE), Inf),
                                        labels = c("Low", "High"))

cat("Medication quantity distribution:\n")
print(table(pooled_data$med_quantity_group))

sensitivity_medquant <- run_subgroup_analysis(pooled_data, "med_quantity_group", 
                                               "MEDICATION QUANTITY")

# ------------------------------------------------------------------------
# Combine all sensitivity analyses
# ------------------------------------------------------------------------
cat("\n\n", rep("=", 80), "\n", sep = "")
cat("SUMMARY OF ALL SENSITIVITY ANALYSES\n")
cat(rep("=", 80), "\n\n", sep = "")

all_sensitivity_results <- bind_rows(
  sensitivity_sex,
  sensitivity_age,
  sensitivity_depression,
  sensitivity_support,
  sensitivity_medquant
)

print(all_sensitivity_results %>%
        mutate(
          OR = round(OR, 3),
          CI_Lower = round(CI_Lower, 3),
          CI_Upper = round(CI_Upper, 3),
          P_Value = format.pval(P_Value, digits = 3),
          Cluster1_Cessation = round(Cluster1_Cessation, 1),
          Cluster2_Cessation = round(Cluster2_Cessation, 1)
        ), row.names = FALSE)

# Results available in: all_sensitivity_results

# ============================================================================
# PART B: INTERACTION ANALYSES
# ============================================================================

cat("\n\n", rep("=", 80), "\n", sep = "")
cat("=== INTERACTION ANALYSES ===\n")
cat(rep("=", 80), "\n\n", sep = "")

# Function to test interactions
test_interaction <- function(data, var_name, var_label) {
  
  cat("\n", rep("-", 70), "\n", sep = "")
  cat("INTERACTION:", var_label, "\n")
  cat(rep("-", 70), "\n\n", sep = "")
  
  # Create formula with interaction
  formula_str <- paste0("scrn_stopped_bzra ~ Cluster * ", var_name, 
                       " + age + sex + phq2_score + osss_3_score")
  
  cat("Testing: Cluster ×", var_label, "\n\n")
  
  # Fit model with interaction
  model_interaction <- glm(as.formula(formula_str), 
                           data = data, 
                           family = binomial)
  
  # Fit model without interaction (for comparison)
  formula_main <- paste0("scrn_stopped_bzra ~ Cluster + ", var_name, 
                        " + age + sex + phq2_score + osss_3_score")
  model_main <- glm(as.formula(formula_main), 
                    data = data, 
                    family = binomial)
  
  # Likelihood ratio test
  lr_test <- anova(model_main, model_interaction, test = "Chisq")
  
  cat("Model Summary (with interaction):\n")
  print(summary(model_interaction)$coefficients)
  
  cat("\n\nLikelihood Ratio Test (interaction term):\n")
  print(lr_test)
  
  interaction_p <- lr_test$`Pr(>Chi)`[2]
  
  cat("\n")
  if (!is.na(interaction_p) && interaction_p < 0.05) {
    cat("*** SIGNIFICANT INTERACTION DETECTED (p =", 
        format.pval(interaction_p, digits = 3), ") ***\n")
    
    # Calculate stratified effects if interaction is significant
    cat("\nStratified Effects:\n")
    cat("(Effect of Cluster at different levels of", var_label, ")\n\n")
    
  } else {
    cat("No significant interaction (p =", 
        format.pval(interaction_p, digits = 3), ")\n")
  }
  
  # Return results
  return(data.frame(
    Variable = var_label,
    Interaction_P = interaction_p,
    Significant = ifelse(!is.na(interaction_p) && interaction_p < 0.05, "Yes", "No"),
    AIC_Main = AIC(model_main),
    AIC_Interaction = AIC(model_interaction)
  ))
}

# ------------------------------------------------------------------------
# Test key interactions
# ------------------------------------------------------------------------

interaction_results <- list()

# 1. Cluster × Age
interaction_results[["age"]] <- test_interaction(pooled_data, "age", "Age")

# 2. Cluster × Sex
interaction_results[["sex"]] <- test_interaction(pooled_data, "sex", "Sex")

# 3. Cluster × Depression (PHQ-2)
interaction_results[["phq2"]] <- test_interaction(pooled_data, "phq2_score", "Depression (PHQ-2)")

# 4. Cluster × Social Support (OSSS-3)
interaction_results[["osss"]] <- test_interaction(pooled_data, "osss_3_score", "Social Support (OSSS-3)")

# 5. Cluster × Medication Quantity
interaction_results[["medquant"]] <- test_interaction(pooled_data, "med_quant", "Medication Quantity")

# 6. Cluster × Neuroticism
interaction_results[["neuroticism"]] <- test_interaction(pooled_data, "Neuroticism", "Neuroticism")

# 7. Cluster × Stability
interaction_results[["stability"]] <- test_interaction(pooled_data, "Cluster_Stability", "Cluster Stability")

# ------------------------------------------------------------------------
# Summary of all interactions
# ------------------------------------------------------------------------

cat("\n\n", rep("=", 80), "\n", sep = "")
cat("SUMMARY OF INTERACTION ANALYSES\n")
cat(rep("=", 80), "\n\n", sep = "")

interaction_summary <- bind_rows(interaction_results)

print(interaction_summary %>%
        mutate(
          Interaction_P = format.pval(Interaction_P, digits = 3),
          AIC_Main = round(AIC_Main, 1),
          AIC_Interaction = round(AIC_Interaction, 1),
          AIC_Diff = round(AIC_Main - AIC_Interaction, 1)
        ) %>%
        arrange(Interaction_P), row.names = FALSE)

# Results available in: interaction_summary

# ============================================================================
# PART C: VISUALIZATION OF KEY FINDINGS
# ============================================================================

cat("\n\n=== CREATING SENSITIVITY/INTERACTION VISUALIZATIONS ===\n\n")

# Forest plot of sensitivity analyses
cat("Creating sensitivity analysis forest plot...\n")

sensitivity_plot_data <- all_sensitivity_results %>%
  mutate(
    Subgroup = paste0(Subgroup_Variable, ": ", Subgroup_Level),
    Subgroup = factor(Subgroup, levels = rev(Subgroup))
  )

forest_sensitivity <- ggplot(sensitivity_plot_data, 
                              aes(x = OR, y = Subgroup)) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "gray50") +
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2) +
  geom_point(size = 3, color = "steelblue") +
  geom_text(aes(label = sprintf("%.2f", OR)), 
            hjust = -0.5, size = 3) +
  labs(
    title = "Sensitivity Analysis: Cluster Effect on Cessation Across Subgroups",
    subtitle = "Odds Ratios with 95% Confidence Intervals",
    x = "Odds Ratio (Cluster 2 vs Cluster 1)",
    y = ""
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.text.y = element_text(size = 10)
  )

print(forest_sensitivity)
cat("Forest plot created (stored in: forest_sensitivity)\n")

# Plot cessation rates by subgroups
cat("Creating subgroup comparison plot...\n")

subgroup_comparison <- all_sensitivity_results %>%
  mutate(Subgroup = paste0(Subgroup_Variable, ": ", Subgroup_Level)) %>%
  dplyr::select(Subgroup, Cluster1_Cessation, Cluster2_Cessation) %>%
  pivot_longer(cols = c(Cluster1_Cessation, Cluster2_Cessation),
               names_to = "Cluster",
               values_to = "Cessation_Rate") %>%
  mutate(Cluster = ifelse(Cluster == "Cluster1_Cessation", "Cluster 1", "Cluster 2"))

subgroup_plot <- ggplot(subgroup_comparison, 
                        aes(x = Subgroup, y = Cessation_Rate, fill = Cluster)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  scale_fill_brewer(palette = "Set2") +
  coord_flip() +
  labs(
    title = "Cessation Rates by Cluster Across Subgroups",
    x = "",
    y = "Cessation Rate (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    legend.position = "bottom"
  )

print(subgroup_plot)
cat("Subgroup plot created (stored in: subgroup_plot)\n")

cat("\n\n=== SENSITIVITY AND INTERACTION ANALYSES COMPLETE ===\n")
cat("All results are available in the following objects:\n")
cat("  - all_sensitivity_results\n")
cat("  - interaction_summary\n")
cat("  - forest_sensitivity (plot)\n")
cat("  - subgroup_plot (plot)\n\n")

cat("\n=== ALL FOLLOW-UP ANALYSES COMPLETE ===\n")
cat("All results and figures have been generated.\n")
```


## BZRA Cessation by Cluster

```{r}
#| label: BZRA Cessation Integration and Analysis

cat("\n\n=== ADDING AND ANALYZING BZRA CESSATION BY CLUSTER ===\n\n")

library(dplyr)
library(ggplot2)
library(vcd)        # for Cramér’s V
library(effectsize) # backup effect size functions

# --- Step 1: Add scrn_stopped_bzra from SIMOA ---
if (exists("SIMOA") && "scrn_stopped_bzra" %in% names(SIMOA)) {
  
  cat("Checking dataset alignment...\n")
  cat("SIMOA rows:", nrow(SIMOA), "\n")
  cat("Cluster dataset rows:", nrow(data_with_clusters), "\n\n")
  
  if (nrow(data_with_clusters) == nrow(SIMOA)) {
    data_with_clusters <- data_with_clusters %>%
      mutate(scrn_stopped_bzra = SIMOA$scrn_stopped_bzra)
    
    cat("✅ Added 'scrn_stopped_bzra' successfully by row order.\n")
    cat("Missing values:", sum(is.na(data_with_clusters$scrn_stopped_bzra)), "\n\n")
    
  } else {
    cat("⚠️ Row mismatch between datasets — cannot merge by row safely.\n")
    cat("Please confirm alignment before proceeding.\n\n")
  }
  
} else {
  cat("⚠️ SIMOA dataset or variable 'scrn_stopped_bzra' not found.\n\n")
}


# --- Step 2: Analyze cessation rates by cluster ---
if ("scrn_stopped_bzra" %in% names(data_with_clusters)) {
  
  cat("=== BZRA CESSATION RATES BY CLUSTER ===\n\n")
  
  # 2A. Summary table
  cessation_summary <- data_with_clusters %>%
    group_by(cluster) %>%
    summarise(
      n_total = n(),
      n_stopped = sum(scrn_stopped_bzra == 1, na.rm = TRUE),
      pct_stopped = round(100 * n_stopped / n_total, 1),
      .groups = "drop"
    )
  
  cat("Cessation summary by cluster:\n\n")
  print(cessation_summary)
  
  # 2B. Chi-square test
  cat("\n\nChi-square test of cessation rate differences:\n\n")
  cessation_table <- table(data_with_clusters$cluster, data_with_clusters$scrn_stopped_bzra)
  print(cessation_table)
  
  chi_test <- suppressWarnings(chisq.test(cessation_table))
  print(chi_test)
  
  # 2C. Cramér’s V (effect size)
  cramer_v <- suppressWarnings(assocstats(cessation_table)$cramer)
  cat("\nCramér’s V (effect size):", round(cramer_v, 3), "\n")
  
  # 2D. Visualization
  ggplot(cessation_summary, aes(x = factor(cluster), y = pct_stopped, fill = factor(cluster))) +
    geom_col() +
    geom_text(aes(label = paste0(pct_stopped, "%")), vjust = -0.3, size = 4) +
    scale_fill_brewer(palette = "Set2") +
    labs(
      title = "BZRA Cessation Rates by Cluster",
      x = "Cluster",
      y = "% Stopped BZRA Use",
      fill = "Cluster"
    ) +
    theme_minimal(base_size = 14)
  
} else {
  cat("Variable 'scrn_stopped_bzra' not found in dataset — analysis skipped.\n")
}
```





